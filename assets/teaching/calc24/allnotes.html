<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Sam Fearn Original notes produced by Paul Sutcliffe" />
  <title>Calculus I Michaelmas Term</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="https://samfearn.github.io/latex.min.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <script type="text/x-mathjax-config">
  	MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "ams"} } });
  	// I need to wait until MathJax has finished before running the numbering script
  	MathJax.Hub.Register.StartupHook("End",function(){doNumbering()});
  </script>
</head>
<body>
<header id="title-block-header">
<h1 class="title"><p>Calculus I<br />
Michaelmas Term</p></h1>
<p class="author">Sam Fearn<br />
Original notes produced by Paul Sutcliffe</p>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#functions"><span class="toc-section-number">1</span> Functions</a>
<ul>
<li><a href="#functions-domain-and-range"><span class="toc-section-number">1.1</span> Functions, domain and range</a></li>
<li><a href="#the-graph-of-a-function"><span class="toc-section-number">1.2</span> The graph of a function</a></li>
<li><a href="#even-and-odd-functions"><span class="toc-section-number">1.3</span> Even and odd functions</a></li>
<li><a href="#piecewise-functions"><span class="toc-section-number">1.4</span> Piecewise functions</a></li>
<li><a href="#operations-with-functions"><span class="toc-section-number">1.5</span> Operations with functions</a></li>
<li><a href="#inverse-functions"><span class="toc-section-number">1.6</span> Inverse functions</a></li>
<li><a href="#summary-functions"><span class="toc-section-number">1.7</span> Summary: Functions</a></li>
</ul></li>
<li><a href="#limits-and-continuity"><span class="toc-section-number">2</span> Limits and continuity</a>
<ul>
<li><a href="#definition-of-a-limit-and-continuity"><span class="toc-section-number">2.1</span> Definition of a limit and continuity</a></li>
<li><a href="#facts-about-limits-and-continuity"><span class="toc-section-number">2.2</span> Facts about limits and continuity</a></li>
<li><a href="#the-pinching-theorem"><span class="toc-section-number">2.3</span> The pinching theorem</a></li>
<li><a href="#two-trigonometric-limits"><span class="toc-section-number">2.4</span> Two trigonometric limits</a></li>
<li><a href="#classification-of-discontinuities"><span class="toc-section-number">2.5</span> Classification of discontinuities</a></li>
<li><a href="#limits-as-xrightarrow-infty."><span class="toc-section-number">2.6</span> Limits as <span class="math inline">\(x\rightarrow \infty.\)</span></a></li>
<li><a href="#the-intermediate-value-theorem"><span class="toc-section-number">2.7</span> The intermediate value theorem</a></li>
<li><a href="#summary-limits-and-continuity"><span class="toc-section-number">2.8</span> Summary: Limits and continuity</a></li>
</ul></li>
<li><a href="#differentiation"><span class="toc-section-number">3</span> Differentiation</a>
<ul>
<li><a href="#derivative-as-a-limit"><span class="toc-section-number">3.1</span> Derivative as a limit</a></li>
<li><a href="#the-leibniz-and-chain-rules"><span class="toc-section-number">3.2</span> The Leibniz and chain rules</a></li>
<li><a href="#lhôpitals-rule"><span class="toc-section-number">3.3</span> L’Hôpital’s rule</a></li>
<li><a href="#boundedness-and-monotonicity"><span class="toc-section-number">3.4</span> Boundedness and monotonicity</a></li>
<li><a href="#critical-points"><span class="toc-section-number">3.5</span> Critical points</a></li>
<li><a href="#rolles-theorem"><span class="toc-section-number">3.6</span> Rolle’s theorem</a></li>
<li><a href="#the-mean-value-theorem"><span class="toc-section-number">3.7</span> The mean value theorem</a></li>
<li><a href="#the-inverse-function-rule"><span class="toc-section-number">3.8</span> The inverse function rule</a></li>
<li><a href="#partial-derivatives"><span class="toc-section-number">3.9</span> Partial derivatives</a></li>
<li><a href="#summary-differentiation"><span class="toc-section-number">3.10</span> Summary: Differentiation</a></li>
</ul></li>
<li><a href="#integration"><span class="toc-section-number">4</span> Integration</a>
<ul>
<li><a href="#indefinite-and-definite-integrals"><span class="toc-section-number">4.1</span> Indefinite and definite integrals</a></li>
<li><a href="#the-fundamental-theorem-of-calculus"><span class="toc-section-number">4.2</span> The fundamental theorem of calculus</a></li>
<li><a href="#limits-with-logarithms-powers-and-exponentials"><span class="toc-section-number">4.3</span> Limits with logarithms, powers and exponentials</a></li>
<li><a href="#integration-using-a-recurrence-relation"><span class="toc-section-number">4.4</span> Integration using a recurrence relation</a></li>
<li><a href="#definite-integrals-using-even-and-odd-functions"><span class="toc-section-number">4.5</span> Definite integrals using even and odd functions</a></li>
<li><a href="#summary-integration"><span class="toc-section-number">4.6</span> Summary: Integration</a></li>
</ul></li>
<li><a href="#double-integrals"><span class="toc-section-number">5</span> Double integrals</a>
<ul>
<li><a href="#rectangular-regions"><span class="toc-section-number">5.1</span> Rectangular regions</a></li>
<li><a href="#beyond-rectangular-regions"><span class="toc-section-number">5.2</span> Beyond rectangular regions</a></li>
<li><a href="#integration-using-polar-coordinates"><span class="toc-section-number">5.3</span> Integration using polar coordinates</a></li>
<li><a href="#change-of-variables-and-the-jacobian"><span class="toc-section-number">5.4</span> Change of variables and the Jacobian</a></li>
<li><a href="#the-gaussian-integral"><span class="toc-section-number">5.5</span> The Gaussian integral</a></li>
<li><a href="#summary-double-integration"><span class="toc-section-number">5.6</span> Summary: Double integration</a></li>
</ul></li>
<li><a href="#first-order-differential-equations"><span class="toc-section-number">6</span> First order differential equations</a>
<ul>
<li><a href="#first-order-separable-odes"><span class="toc-section-number">6.1</span> First order separable ODEs</a></li>
<li><a href="#first-order-homogeneous-odes"><span class="toc-section-number">6.2</span> First order homogeneous ODEs</a></li>
<li><a href="#first-order-linear-odes"><span class="toc-section-number">6.3</span> First order linear ODEs</a></li>
<li><a href="#first-order-exact-odes"><span class="toc-section-number">6.4</span> First order exact ODEs</a></li>
<li><a href="#bernoulli-equations"><span class="toc-section-number">6.5</span> Bernoulli equations</a></li>
<li><a href="#summary-first-order-odes"><span class="toc-section-number">6.6</span> Summary: First order ODEs</a></li>
</ul></li>
<li><a href="#second-order-differential-equations"><span class="toc-section-number">7</span> Second order differential equations</a>
<ul>
<li><a href="#linear-constant-coefficient-homogeneous-odes"><span class="toc-section-number">7.1</span> Linear constant coefficient homogeneous ODEs</a></li>
<li><a href="#the-method-of-undetermined-coefficients"><span class="toc-section-number">7.2</span> The method of undetermined coefficients</a></li>
<li><a href="#initial-and-boundary-value-problems"><span class="toc-section-number">7.3</span> Initial and boundary value problems</a></li>
<li><a href="#the-method-of-variation-of-parameters"><span class="toc-section-number">7.4</span> The method of variation of parameters</a></li>
<li><a href="#systems-of-first-order-linear-odes"><span class="toc-section-number">7.5</span> Systems of first order linear ODEs</a></li>
<li><a href="#summary-second-order-odes"><span class="toc-section-number">7.6</span> Summary: Second order ODEs</a></li>
</ul></li>
<li><a href="#taylor-series"><span class="toc-section-number">8</span> Taylor series</a>
<ul>
<li><a href="#taylors-theorem"><span class="toc-section-number">8.1</span> Taylor’s theorem</a></li>
<li><a href="#taylor-polynomials"><span class="toc-section-number">8.2</span> Taylor polynomials</a></li>
<li><a href="#lagrange-form-for-the-remainder"><span class="toc-section-number">8.3</span> Lagrange form for the remainder</a></li>
<li><a href="#calculating-limits-using-taylor-series"><span class="toc-section-number">8.4</span> Calculating limits using Taylor series</a></li>
<li><a href="#summary-taylor-series"><span class="toc-section-number">8.5</span> Summary: Taylor Series</a></li>
</ul></li>
<li><a href="#fourier-series"><span class="toc-section-number">9</span> Fourier series</a>
<ul>
<li><a href="#fourier-coefficients"><span class="toc-section-number">9.1</span> Fourier coefficients</a></li>
<li><a href="#examples-of-fourier-series"><span class="toc-section-number">9.2</span> Examples of Fourier series</a></li>
<li><a href="#parsevals-theorem"><span class="toc-section-number">9.3</span> Parseval’s theorem</a></li>
<li><a href="#half-range-fourier-series"><span class="toc-section-number">9.4</span> Half range Fourier series</a></li>
<li><a href="#fourier-series-in-complex-form"><span class="toc-section-number">9.5</span> Fourier series in complex form</a></li>
<li><a href="#summary-fourier-series"><span class="toc-section-number">9.6</span> Summary: Fourier Series</a></li>
</ul></li>
</ul>
</nav>
<section id="functions" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Functions</h1>
<section id="functions-domain-and-range" class="level2" data-number="1.1">
<h2 data-number="1.1"><span class="header-section-number">1.1</span> Functions, domain and range</h2>
<p><span><strong>Defn:</strong></span> A <span><strong>function</strong></span> <span class="math inline">\(f\)</span> is a correspondence between two sets <span class="math inline">\(D\)</span> (called the <span><em>domain</em></span>) and <span class="math inline">\(C\)</span> (called the <span><em>codomain</em></span>), that assigns to each element of <span class="math inline">\(D\)</span> one and only one element of <span class="math inline">\(C\)</span>. The notation to indicate the domain and codomain is <span class="math inline">\(f:D\mapsto C\)</span>.<br />
For <span class="math inline">\(x\in D\)</span> we write <span class="math inline">\(f(x)\)</span> to denote the assigned element in <span class="math inline">\(C\)</span>, and call this the value of <span class="math inline">\(f\)</span> at <span class="math inline">\(x,\)</span> or the image of <span class="math inline">\(x\)</span> under <span class="math inline">\(f,\)</span> where <span class="math inline">\(x\)</span> is called the argument of the function. Extending the above notation we write <span class="math display">\[f:D\mapsto C:x\mapsto f(x)\]</span> ie. ‘‘<span class="math inline">\(f\)</span> is a function from <span class="math inline">\(D\)</span> to <span class="math inline">\(C\)</span> that associates <span class="math inline">\(x\)</span> in <span class="math inline">\(D\)</span> to <span class="math inline">\(f(x)\)</span> in <span class="math inline">\(C\)</span>’’.<br />
The set of all images is called the <span><strong>range</strong></span> of <span class="math inline">\(f\)</span> and our notation for the domain and range is <span class="math display">\[\mathop{\mathrm{Dom}}{f} \quad\quad \text{and} \quad\quad
\mathop{\mathrm{Ran}}{f}=\{f(x):x\in \mathop{\mathrm{Dom}}{f}\}.\]</span></p>
<figure>
<img src="domain.png" style="width:7cm" alt="" /><figcaption>Illustration of the domain, codomain and range of a function.</figcaption>
</figure>
<p>In (almost all of) this term of the module we shall only deal with real-valued functions of a real variable, meaning that our functions assign real numbers to real numbers ie. both the domain and codomain are subsets of <span class="math inline">\(\mathbb{R}.\)</span><br />
There are various ways of representing a function, but perhaps the most familiar is through an explicit expression.<br />
Eg. <span class="math inline">\(f:\mathbb{R}\rightarrow \mathbb{R}\)</span> given by <span class="math inline">\(f(x)=x^2, \ \forall x\in\mathbb{R}.\)</span></p>
<p>In this case <span class="math inline">\(\mathop{\mathrm{Dom}}{f}=\mathbb{R}\)</span> and <span class="math inline">\(\mathop{\mathrm{Ran}}{f}=[0,\infty).\)</span></p>
<p>We say that <span class="math inline">\(f\)</span> <span><em>maps</em></span> the real line onto <span class="math inline">\([0,\infty).\)</span><br />
Eg. <span class="math inline">\(f(x)=\sqrt{2x+4}, \ x\in[0,6].\)</span> Here <span class="math inline">\(\mathop{\mathrm{Dom}}{f}=[0,6]\)</span> and <span class="math inline">\(\mathop{\mathrm{Ran}}{f}=[2,4].\)</span><br />
If the domain of a function <span class="math inline">\(f\)</span> is not explicitly given, then it is taken to be the maximal set of real numbers <span class="math inline">\(x\)</span> for which <span class="math inline">\(f(x)\)</span> is a real number.<br />
Eg. <span class="math inline">\(f(x)=\sqrt{2x+4}.\)</span> Here <span class="math inline">\(\mathop{\mathrm{Dom}}{f}=[-2,\infty)\)</span> and <span class="math inline">\(\mathop{\mathrm{Ran}}{f}=[0,\infty).\)</span><br />
Eg. <span class="math inline">\(f(x)=1/(1-x).\)</span> Here <span class="math inline">\(\mathop{\mathrm{Dom}}{f}=\mathbb{R}\backslash\{1\}
=(-\infty,1)\cup(1,\infty)\)</span> and <span class="math inline">\(\mathop{\mathrm{Ran}}{f}=\mathbb{R}\backslash\{0\}.\)</span><br />
In addition to explicit expressions, a function <span class="math inline">\(f\)</span> may be represented by other means, for example, as a set of ordered pairs <span class="math inline">\((x,y),\)</span> where <span class="math inline">\(x\in \mathop{\mathrm{Dom}}{f}\)</span> and <span class="math inline">\(y\in \mathop{\mathrm{Ran}}{f}.\)</span><br />
Note: <span class="math inline">\(y(x)\)</span> is another common notation for a function. The element <span class="math inline">\(x\)</span> in the domain is called the <span><strong>independent variable</strong></span> and the element <span class="math inline">\(y\)</span> in the range is called the <span><strong>dependent variable</strong></span>. This notation is often used if the function is defined by an equation in two variables, including differential equations (see later).<br />
The function <span class="math inline">\(f(x)=x^2\)</span> is defined by the equation <span class="math inline">\(y=x^2,\)</span> as we have simply written <span class="math inline">\(y=f(x).\)</span> However, not all equations will define a function.<br />
Eg. The equation <span class="math inline">\(y^2=x\)</span> does <span><em>not</em></span> define a non-trivial function <span class="math inline">\(y(x),\)</span> because for <span class="math inline">\(x&lt;0\)</span> there are no real solutions for <span class="math inline">\(y,\)</span> and for <span class="math inline">\(x&gt;0\)</span> there are two solutions for <span class="math inline">\(y,\)</span> whereas a function must assign only one element of the range for each element of the domain.<br />
</p>
</section>
<section id="the-graph-of-a-function" class="level2" data-number="1.2">
<h2 data-number="1.2"><span class="header-section-number">1.2</span> The graph of a function</h2>
<p><span><strong>Defn:</strong></span> The <span><strong>graph</strong></span> of a function <span class="math inline">\(f\)</span> is the set of all points <span class="math inline">\((x,y)\)</span> in the <span class="math inline">\(xy\)</span>-plane with <span class="math inline">\(x\in \mbox{Dom}\,f\)</span> and <span class="math inline">\(y=f(x),\)</span> ie. <span class="math display">\[\mbox{graph f}=\{(x,y):x\in \mbox{Dom}\,f \ \mbox{and \ } y=f(x)\}.\]</span> The graph of a function over the interval <span class="math inline">\([a,b]\)</span> is the portion of the graph where the argument is restricted to this interval.<br />
</p>
<figure>
<img src="new_cos.png" style="width:6cm" alt="" /><figcaption>The graph of <span class="math inline">\(f(x)=\cos x\)</span> over <span class="math inline">\([-2\pi,2\pi].\)</span></figcaption>
</figure>
<p>Note: If you are asked to graph a function, but no interval is given, then try to choose an appropriate interval that includes all the interesting behaviour eg. turning points.<br />
To indicate on a graph exactly which points are included we use a closed circle to denote an included point, so if it is at the end of a curve segment this denotes that this end is a closed interval. We use an open circle to denote an excluded point associated with an open interval.</p>
<figure>
<img src="new_open2.png" style="width:5cm" alt="" /><figcaption>A graph illustating the use of open (white) and closed (black) circles.</figcaption>
</figure>
<p>The graph of a function is a curve in the plane, but not every curve is the graph of a function. The following simple test determines whether a curve is the graph of a function.<br />
<span><strong>The vertical line test.</strong></span></p>
<p>If any vertical line intersects the curve more than once then the curve is not the graph of a function, otherwise it is.<br />
The proof is obvious, given the defining property of a function that only one element in the range is associated with an element in the domain.</p>
<figure>
<img src="new_vertical12.png" style="width:12cm" alt="" /><figcaption>The vertical line test applied to a cubic curve and a circle.</figcaption>
</figure>
<p>In the figure the first curve is the graph of a function: in fact the cubic function <span class="math inline">\(f(x)=x^3-x^2-1.\)</span> The second curve is not the graph of a function as the vertical line shown intersects the curve twice. In fact the curve is given by the equation <span class="math inline">\(y^2=4-(x-1)^2\)</span> ie. the circle of radius 2 with centre <span class="math inline">\((x,y)=(1,0).\)</span> Note that even when a curve is not the graph of a function, some sections of the curve may be graphs of functions. For the above circle example the section given by <span class="math inline">\(y\ge 0\)</span> is the graph of the function <span class="math inline">\(f(x)=\sqrt{4-(x-1)^2}\)</span> with <span class="math inline">\(\mbox{Dom}\,f=[-1,3].\)</span></p>
</section>
<section id="even-and-odd-functions" class="level2" data-number="1.3">
<h2 data-number="1.3"><span class="header-section-number">1.3</span> Even and odd functions</h2>
<p><span><strong>Defn</strong></span>. A function <span class="math inline">\(f\)</span> is <span><strong>even</strong></span> if <span class="math inline">\(f(x)=f(-x)\ \forall \pm x\in \mbox{Dom\,}f.\)</span></p>
<p><span><strong>Defn</strong></span>. A function <span class="math inline">\(f\)</span> is <span><strong>odd</strong></span> if <span class="math inline">\(f(x)=-f(-x)\ \forall \pm x\in \mbox{Dom\,}f.\)</span><br />
The graph of an even function is symmetric under a reflection about the <span class="math inline">\(y\)</span>-axis.</p>
<p>The graph of an odd function is symmetric under a rotation by <span class="math inline">\(180^\circ\)</span> about the origin (equivalent to a reflection in the <span class="math inline">\(y\)</span>-axis followed by a reflection in the <span class="math inline">\(x\)</span>-axis).</p>
<figure>
<img src="new_evenodd" style="width:9cm" alt="" /><figcaption>Graphs of the even function <span class="math inline">\(x^2\)</span> and the odd function <span class="math inline">\(x^3.\)</span> </figcaption>
</figure>
<p>All functions <span class="math inline">\(f:\mathbb{R}\mapsto \mathbb{R}\)</span> can be written as the sum of an even and an odd function <span class="math display">\[f(x)=f_{even}(x)+f_{odd}(x),\]</span> <span class="math display">\[\ \mbox{where} \ \ 
f_{even}(x)=\frac{1}{2}f(x)+\frac{1}{2}f(-x) \ \ \mbox{and} \ \ 
f_{odd}(x)=\frac{1}{2}f(x)-\frac{1}{2}f(-x).\]</span> This decomposition is often useful, as is the ability to spot an even or odd function, as it can simplify some calculations, as we shall see in later sections.<br />
Eg. <span class="math inline">\(f(x)=(1+x)\sin x\)</span> with <span class="math inline">\(f_{even}(x)=x\sin x\)</span> and <span class="math inline">\(f_{odd}(x)=\sin x.\)</span><br />
Eg. <span class="math inline">\(f(x)=e^x\)</span> with <span class="math inline">\(f_{even}(x)=\frac{1}{2}(e^x+e^{-x})=\cosh x\)</span> and <span class="math inline">\(f_{odd}(x)=\frac{1}{2}(e^x-e^{-x})=\sinh x.\)</span></p>
</section>
<section id="piecewise-functions" class="level2" data-number="1.4">
<h2 data-number="1.4"><span class="header-section-number">1.4</span> Piecewise functions</h2>
<p>Some functions are defined <span><strong>piecewise</strong></span> ie. different expressions are given for different intervals in the domain.<br />
</p>
<p>Eg. The absolute value (or modulus) function <span class="math display">\[f(x)=|x|=
\begin{cases}
\ \ x &amp; \mbox{if\ } x\ge 0\\
-x &amp; \mbox{if\ } x&lt;0.
\end{cases}\]</span></p>
<figure>
<img src="new_modulus.png" style="width:50.0%" alt="" /><figcaption>The graph of <span class="math inline">\(|x|\)</span> over <span class="math inline">\([-1,1].\)</span></figcaption>
</figure>
<p>Eg. <span class="math display">\[f(x)=
\begin{cases}
\ \ x &amp; \mbox{if\ } 0\le x&lt;1\\
x-1 &amp; \mbox{if\ } 1\le x\le 2.
\end{cases}\]</span> In this example <span class="math inline">\(\mbox{Dom}\,f=[0,2]\)</span> but the function has a discontinuity at <span class="math inline">\(x=1\)</span> (more about this later).</p>
<figure>
<img src="new_piecewise.png" style="width:50.0%" alt="" /><figcaption>The graph of a piecewise function.</figcaption>
</figure>
<p>A <span><strong>step function</strong></span> is a piecewise function which is constant on each piece. An example is the Heaviside step function <span class="math inline">\(H(x)\)</span> defined by <span class="math display">\[H(x)=
\begin{cases}
0 &amp; \mbox{if\ } x&lt;0\\
1 &amp; \mbox{if\ } x&gt;0.
\end{cases}\]</span> Note that with this definition <span class="math inline">\(\mbox{Dom}\,H=\mathbb{R}\backslash\{0\}.\)</span> It is sometimes convenient to extend the domain to <span class="math inline">\(\mathbb{R}\)</span> by defining the value of <span class="math inline">\(H(0)\)</span> (some obvious candidates are <span class="math inline">\(0,\frac{1}{2},1\)</span>).</p>
<figure>
<img src="new_heaviside.png" style="width:70.0%" alt="" /><figcaption>The Heaviside step function.</figcaption>
</figure>
</section>
<section id="operations-with-functions" class="level2" data-number="1.5">
<h2 data-number="1.5"><span class="header-section-number">1.5</span> Operations with functions</h2>
<p>Given two functions <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> we can define the following:<br />
<span class="math inline">\(\bullet\)</span> the <span><strong>sum</strong></span> is <span class="math inline">\((f+g)(x)=f(x)+g(x)\)</span>, with domain <span class="math inline">\(\mbox{Dom}\,f\cap\mbox{Dom}\,g.\)</span><br />
<span class="math inline">\(\bullet\)</span> the <span><strong>difference</strong></span> is <span class="math inline">\((f-g)(x)=f(x)-g(x)\)</span>, with domain <span class="math inline">\(\mbox{Dom}\,f\cap\mbox{Dom}\,g.\)</span><br />
<span class="math inline">\(\bullet\)</span> the <span><strong>product</strong></span> is <span class="math inline">\((fg)(x)=f(x)g(x)\)</span>, with domain <span class="math inline">\(\mbox{Dom}\,f\cap\mbox{Dom}\,g.\)</span><br />
<span class="math inline">\(\bullet\)</span> the <span><strong>ratio</strong></span> is <span class="math inline">\(({f}/{g})(x)=f(x)/{g(x)}\)</span>, with domain <span class="math inline">\((\mbox{Dom}\,f\cap\mbox{Dom}\,g)\backslash\{x:g(x)=0\}.\)</span><br />
<span class="math inline">\(\bullet\)</span> the <span><strong>composition</strong></span> is <span class="math inline">\((f\circ g)(x)=f(g(x))\)</span>, with domain <span class="math inline">\(\{x\in\mbox{Dom}\,g:g(x)\in\mbox{Dom}\,f\}.\)</span><br />
Note that <span class="math inline">\(f\circ g\)</span> and <span class="math inline">\(g \circ f\)</span> are usually different functions.</p>
<p>Eg. <span class="math inline">\(f(x)=\sin x, \ g(x)=x^2\)</span> then <span class="math inline">\((f\circ g)(x)=\sin(x^2)\)</span> but <span class="math inline">\((g\circ f)(x)=\sin^2x.\)</span><br />
Note that the sum and difference, along with <span><strong>scalar multiplication</strong></span> <span class="math inline">\((cf)(x) = c \times f(x)\)</span> for any constant <span class="math inline">\(c\)</span> are special case of <span><strong>linear combinations</strong></span> of functions. The most general linear combination of <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> is <span class="math inline">\((af + bg)(x) = a \times f(x) + b \times g(x)\)</span> for some constants <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, with domain <span class="math inline">\(\mbox{Dom}\,f\cap\mbox{Dom}\,g.\)</span>.</p>
</section>
<section id="inverse-functions" class="level2" data-number="1.6">
<h2 data-number="1.6"><span class="header-section-number">1.6</span> Inverse functions</h2>
<p><span><strong>Defn</strong></span>. A function <span class="math inline">\(f:D\mapsto C\)</span> is <span><strong>surjective</strong></span> (or onto) if <span class="math inline">\(\mbox{Ran}\,f=C,\)</span></p>
<p>ie. if <span class="math inline">\(\forall\  y\in C \ \exists \ x\in D\)</span>  s.t.  <span class="math inline">\(f(x)=y.\)</span><br />
Eg. <span class="math inline">\(f:\mathbb{R}\mapsto \mathbb{R}\)</span> given by <span class="math inline">\(f(x)=2x+1\)</span> is surjective.<br />
Eg. <span class="math inline">\(f:\mathbb{R}\mapsto \mathbb{R}\)</span> given by <span class="math inline">\(f(x)=x^2\)</span> is not surjective, since any negative number in the codomain is not the image of an element in the domain.<br />
<span><strong>Defn</strong></span>. A function <span class="math inline">\(f:D\mapsto C\)</span> is <span><strong>injective</strong></span> (or one-to-one) if <span class="math inline">\(\forall \ x_1,x_2\in D\)</span> with <span class="math inline">\(x_1\neq x_2\)</span> then <span class="math inline">\(f(x_1)\neq f(x_2).\)</span><br />
Eg. <span class="math inline">\(f(x)=2x+1\)</span> is injective since <span class="math inline">\(f(x_1)=f(x_2)\)</span> implies <span class="math inline">\(x_1=x_2.\)</span><br />
Eg. <span class="math inline">\(f(x)=x^2\)</span> is not injective since <span class="math inline">\(f(x)=f(-x)\)</span> and <span class="math inline">\(x\neq -x\)</span> if <span class="math inline">\(x\neq 0.\)</span><br />
The following simple test can be applied to see if a function is injective from its graph.<br />
<span><strong>The horizontal line test</strong></span>.</p>
<p>If no horizontal line intersects the graph of <span class="math inline">\(f\)</span> more than once then <span class="math inline">\(f\)</span> is injective, otherwise it is not.<br />
Eg. The function <span class="math inline">\(f(x)=x^3-3x\)</span> is surjective as <span class="math inline">\(\mbox{Ran}\,f=\mathbb{R}\)</span> but it is not injective as the horizontal line <span class="math inline">\(y=1\)</span> intersects the graph of <span class="math inline">\(f\)</span> at 3 points (see the figure).</p>
<figure>
<img src="new_horizontal.png" id="fig-horizontal" style="width:6cm" alt="" /><figcaption>Graph of <span class="math inline">\(f(x)=x^3-3x\)</span> and the horizontal line <span class="math inline">\(y=1.\)</span></figcaption>
</figure>
<p><br />
<span><strong>Defn</strong></span>. A function <span class="math inline">\(f:D\mapsto C\)</span> is <span><strong>bijective</strong></span> if it is both surjective and injective.<br />
Eg. From above we have seen that the function <span class="math inline">\(f(x)=2x+1\)</span> is bijective.<br />
<span><strong>Theorem of inverse functions</strong></span>.</p>
<p>A bijective function <span class="math inline">\(f\)</span> admits a unique inverse, denoted <span class="math inline">\(f^{-1},\)</span> such that <span class="math display">\[(f^{-1}\circ f)(x)=x=(f \circ f^{-1})(x).\]</span> It is clear from the definition that <span class="math inline">\(\mbox{Dom}\,f^{-1}=\mbox{Ran}\,f\)</span> and <span class="math inline">\(\mbox{Ran}\,f^{-1}=\mbox{Dom}\,f.\)</span><br />
As the inverse undoes the effect of the function an equivalent definition is <span class="math display">\[f(x)=y \quad \mbox{iff} \quad f^{-1}(y)=x.\]</span></p>
<p>This second definition is the same as the fact that the graph of the inverse function <span class="math inline">\(f^{-1}\)</span> is given by reflecting the graph of <span class="math inline">\(f\)</span> in the line <span class="math inline">\(y = x\)</span>. However, note that in general the curve given by such a reflection is not the graph of a function – in particular it will not be single-valued if <span class="math inline">\(f\)</span> is not injective.<br />
Eg. We have seen that <span class="math inline">\(f(x)=2x+1\)</span> is bijective, so lets find its inverse. To simplify notation first write <span class="math inline">\(y=f^{-1}(x).\)</span> Using the property <span class="math inline">\(x=f(f^{-1}(x)),\)</span> we have <span class="math inline">\(x=f(y)=2y+1\)</span> and hence <span class="math inline">\(y=\frac{1}{2}(x-1)=f^{-1}(x).\)</span><br />
Note that given an injective function which is not surjective, we can make a bijective function by taking the codomain equal to the range (this automatically makes a function surjective), and then an inverse exists. This is essentially a harmless modification of the function since the function does not really care what its codomain is, the only requirement is that the range is a subset of the codomain.<br />
Eg. We have seen that <span class="math inline">\(f(x)=x^2\)</span> is not an injective function if <span class="math inline">\(\mbox{Dom}\,f=\mathbb{R},\)</span> but it is injective if we take <span class="math inline">\(\mbox{Dom}\,f=[0,\infty).\)</span> With this choice we can take the codomain equal to <span class="math inline">\(\mbox{Ran}\,f=[0,\infty)\)</span> and <span class="math inline">\(f\)</span> is now a bijective function. The inverse is <span class="math inline">\(f^{-1}(x)=\sqrt{x}\)</span> with <span class="math inline">\(\mbox{Dom}\,f^{-1}=\mbox{Ran}\,f=[0,\infty).\)</span><br />
Note that here we made the function injective by restricting its domain. While we can always do this, in general doing so loses information about the function since the original non-injective function would have given values for other inputs values. However, in special cases such as even functions or periodic functions, we can restrict the domain and have a simple description of how to generate the original function (say with domain <span class="math inline">\(\mathbb R\)</span>) from the function with the restricted domain. We used this above to find an inverse for <span class="math inline">\(f(x) = x^2\)</span> and this is also how we define an inverse for <span class="math inline">\(f(x) = \sin x\)</span> etc.<br />
<span><em>Warning:</em></span> Don’t confuse the notation for the inverse with the same notation for the reciprocal.<br />
</p>
</section>
<section id="summary-functions" class="level2" data-number="1.7">
<h2 data-number="1.7"><span class="header-section-number">1.7</span> Summary: Functions</h2>
<p>You should have a good and precise mathematical understanding of functions and various definitions, particularly focussing on real-valued functions of a single real variable. Here are some key points:</p>
<ul>
<li><p>A function <span class="math inline">\(f\)</span> is a mapping from its <span><em>domain</em></span>, <span class="math inline">\(\mbox{Dom}\, f\)</span>, to a <span><em>codomain</em></span>. Its <span><em>range</em></span>, <span class="math inline">\(\mbox{Ran}\, f\)</span>, is the image of <span class="math inline">\(\mbox{Dom}\, f\)</span>, i.e. the set of all values that <span class="math inline">\(f(x)\)</span> can actually take for <span class="math inline">\(x \in \mbox{Dom}\, f\)</span>.</p></li>
<li><p>Functions are single-valued, i.e. <span class="math inline">\(f(x)\)</span> must have a unique value for all <span class="math inline">\(x \in \mbox{Dom}\, f\)</span>. This can be checked graphically by the <span><em>vertical line test</em></span>.</p></li>
<li><p>Functions can be <span><em>even</em></span> – symmetric under reflection in the <span class="math inline">\(y\)</span>-axis.</p></li>
<li><p>Functions can be <span><em>odd</em></span> – symmetric under rotation by <span class="math inline">\(180^\circ\)</span> around the origin, or equivalently by two reflections, in the <span class="math inline">\(x\)</span>- and <span class="math inline">\(y\)</span>-axes (in either order).</p></li>
<li><p>Typical functions are neither even nor odd, but can be uniquely written as a sum of an even and an odd function, i.e. <span class="math inline">\(f(x) = f_{even}(x) + f_{odd}(x)\)</span>. You should know how to define <span class="math inline">\(f_{even}\)</span> and <span class="math inline">\(f_{odd}\)</span> in terms of <span class="math inline">\(f\)</span>.</p></li>
<li><p>We can define <span><em>piecewise</em></span> functions using different expressions for different parts of the domain. At boundaries of intervals we use filled or empty circles to indicate that a point is or is not included.</p></li>
<li><p>You should be familiar with the operations on functions: <span><em>linear combinations</em></span>, <span><em>product</em></span>, <span><em>ratio</em></span> and <span><em>composition</em></span>, and know what the domain of the resulting functions is in terms of the domains of the original functions.</p></li>
<li><p>You should know the conditions for the <span><em>inverse</em></span> of a function to exist. You should know the definitions of <span><em>surjective</em></span>, <span><em>injective</em></span> and <span><em>bijective</em></span>.</p></li>
</ul>
</section>
</section>
<section id="limits-and-continuity" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Limits and continuity</h1>
<section id="definition-of-a-limit-and-continuity" class="level2" data-number="2.1">
<h2 data-number="2.1"><span class="header-section-number">2.1</span> Definition of a limit and continuity</h2>
<p><span><em>Rough idea #1:</em></span></p>
<p>A function <span class="math inline">\(f(x)\)</span> has a <span><strong>limit</strong></span> <span class="math inline">\(L\)</span> at <span class="math inline">\(x=a\)</span> if <span class="math inline">\(f(x)\)</span> is close to <span class="math inline">\(L\)</span> whenever <span class="math inline">\(x\)</span> is close to <span class="math inline">\(a.\)</span><br />
<span><em>Rough idea #2:</em></span> Lets think about the function <span class="math inline">\(f(x)\)</span> near <span class="math inline">\(x=a.\)</span></p>
<p>If you approximate <span class="math inline">\(f(x)\)</span> by a constant <span class="math inline">\(L\)</span> then you will make an error given by <span class="math inline">\(|f(x)-L|.\)</span> Suppose <span class="math inline">\(\varepsilon&gt;0\)</span> is the <span class="math inline">\(\varepsilon\)</span>rror at which you become unhappy with your approximation, that is, you are happy as long as <span class="math inline">\(|f(x)-L|&lt;\varepsilon.\)</span> The important issue for a limit is whether I can keep you happy simply by making sure that <span class="math inline">\(x\)</span> stays within a <span class="math inline">\(\delta\)</span>istance <span class="math inline">\(\delta&gt;0\)</span> of <span class="math inline">\(a,\)</span> that is by restricting to <span class="math inline">\(0&lt;|x-a|&lt;\delta.\)</span> Note that we dont even care about what happens exactly at <span class="math inline">\(x=a.\)</span> If I can always find a <span class="math inline">\(\delta\)</span>istance <span class="math inline">\(\delta\)</span> that keeps you happy, no matter how small you choose your <span class="math inline">\(\varepsilon\)</span>rror <span class="math inline">\(\varepsilon,\)</span> then we say that <span class="math inline">\(f(x)\)</span> has a <span><strong>limit</strong></span> <span class="math inline">\(L\)</span> as <span class="math inline">\(x\)</span> tends to <span class="math inline">\(a.\)</span><br />
</p>
<figure>
<img src="new_limit.png" style="width:5cm" alt="" /><figcaption>The idea of a limit.</figcaption>
</figure>
<p><span><strong>Defn</strong></span>: <span class="math inline">\(f(x)\)</span> has a <span><strong>limit</strong></span> <span class="math inline">\(L\)</span> as <span class="math inline">\(x\)</span> tends to <span class="math inline">\(a\)</span> if <span class="math display">\[\forall \ \ \varepsilon&gt;0 \ \ \exists \ \ \delta&gt;0 \ \ \mbox{s.t} \ \
|f(x)-L|&lt;\varepsilon\ \ \mbox{when} \ \ 0&lt;|x-a|&lt;\delta.\]</span> We then write <span class="math display">\[\lim_{x\rightarrow a}f(x)=L \quad \mbox{or equivalently}\quad 
f(x)\rightarrow L \ \ \mbox{as} \ \ x\rightarrow a.\]</span> If there is no such <span class="math inline">\(L\)</span> then we say that <span><em>no limit exists</em></span>.<br />
The limit does not require that <span class="math inline">\(f(a)\)</span> is equal to <span class="math inline">\(L\)</span> or even that <span class="math inline">\(f(a)\)</span> exists. This is because of the inequality <span class="math inline">\(0&lt;|x-a|\)</span> in the definition.<br />
There is a lot more of this <span class="math inline">\(\varepsilon\)</span> and <span class="math inline">\(\delta\)</span> stuff in Analysis I, where proofs concerning limits are considered. In this course we shall be less formal and deal only with methods to calculate limits or see that no limit exists.<br />
<span><em>Rough idea #3:</em></span></p>
<p>If <span class="math inline">\(f(a)\)</span> exists then it would seem that this is a good candidate for the limit <span class="math inline">\(L.\)</span> This naive view turns out to be correct only if the graph of <span class="math inline">\(f(x)\)</span> is a single unbroken curve with no holes or jumps, at least in a small region around <span class="math inline">\(x=a.\)</span><br />
<span><strong>Defn</strong></span>. A function <span class="math inline">\(f(x)\)</span> is <span><strong>continuous at the point <span class="math inline">\(x=a\)</span></strong></span> if the following three properties all hold:<br />
<span class="math inline">\(\bullet\)</span> <span class="math inline">\(f(a)\)</span> exists.<br />
<span class="math inline">\(\bullet\)</span> <span class="math inline">\(\lim_{x\rightarrow a}f(x)\)</span> exists.<br />
<span class="math inline">\(\bullet\)</span> <span class="math inline">\(\lim_{x\rightarrow a}f(x)\)</span> is equal to <span class="math inline">\(f(a)\)</span>.<br />
<span><strong>Defn</strong></span>. A function <span class="math inline">\(f(x)\)</span> is <span><strong>continuous on a subset</strong></span> <span class="math inline">\(S\)</span> of its domain if it is continuous at every point in <span class="math inline">\(S\)</span>.<br />
 <span><strong>Defn</strong></span>. A function <span class="math inline">\(f(x)\)</span> is <span><strong>continuous</strong></span> if it is continuous at every point in its domain. </p>
<p> </p>
<p>Eg. <span class="math inline">\(f(x)=x^2\)</span> is continuous and <span class="math inline">\(\lim_{x\rightarrow 2}x^2=f(2)=4.\)</span><br />
Eg. The following function has a discontinuity at <span class="math inline">\(x=0\)</span> <span class="math display">\[f(x)=
\begin{cases}
x^2 &amp; \mbox{if\ } -1\le x&lt; 0\\
1 &amp; \mbox{if\ } x=0\\
x^2 &amp; \mbox{if\ } 0&lt;x\le 1\\
\end{cases}\]</span></p>
<figure>
<img src="new_open1.png" id="fig-open1" style="width:4cm" alt="" /><figcaption>A graph illustrating the use of open and closed circles. The limit exists at <span class="math inline">\(x=0.\)</span></figcaption>
</figure>
<p>As mentioned earlier, to indicate on a graph exactly which points are included we use a closed circle to denote an included point, so if it is at the end of a curve segment this denotes that this end is a closed interval. We use an open circle to denote an excluded point associated with an open interval. This notation is demonstrated in Figure <a href="#fig-open1" data-reference-type="ref" data-reference="fig-open1">2</a> where the graph of the above function is presented. This function is not continuous at <span class="math inline">\(x=0\)</span> but the limit exists at this point and <span class="math inline">\(\lim_{x\rightarrow 0}f(x)=0\neq 1=f(0).\)</span><br />
Eg. The following function also has a discontinuity at <span class="math inline">\(x=0\)</span> (see Figure <a href="#fig-open2" data-reference-type="ref" data-reference="fig-open2">3</a> for its graph) <span class="math display">\[f(x)=
\begin{cases}
1 &amp; \mbox{if\ } x\le 0\\
x^2 &amp; \mbox{if\ } x&gt;0\\
\end{cases}\]</span></p>
<figure>
<img src="new_open22.png" id="fig-open2" style="width:5cm" alt="" /><figcaption>A graph illustrating the use of open and closed circles. No limit exists at <span class="math inline">\(x=0.\)</span></figcaption>
</figure>
<p>In this case no limit exists at <span class="math inline">\(x=0.\)</span> This is clear because if we consider <span class="math inline">\(x&lt;0\)</span> then to get arbitrarily close to the function for <span class="math inline">\(x\)</span> arbitrarily close to 0 would require the limit to be 1. However, if we consider <span class="math inline">\(x&gt;0\)</span> then to get arbitrarily close to the function for <span class="math inline">\(x\)</span> arbitrarily close to 0 would require the limit to be 0. These two requirements are incompatible and so no limit exists at <span class="math inline">\(x=0.\)</span><br />
Eg. For the function <span class="math inline">\(f(x)=\sin(1/x)\)</span> no limit exists at <span class="math inline">\(x=0\)</span> because as <span class="math inline">\(x\)</span> approaches zero this function oscillates between 1 and -1 over smaller and smaller intervals. In particular, in any given interval <span class="math inline">\(0&lt;x&lt;\delta\)</span> it is always possible to find values <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> s.t. <span class="math inline">\(f(x_1)=1\)</span> and <span class="math inline">\(f(x_2)=-1,\)</span> thus <span class="math inline">\(f(x)\)</span> cannot remain close to any given constant <span class="math inline">\(L.\)</span></p>
<figure>
<img src="new_sin1overx.png" id="fig-sin1overx" style="width:7cm" alt="" /><figcaption>A graph of the function <span class="math inline">\(\sin(1/x)\)</span>.</figcaption>
</figure>
</section>
<section id="facts-about-limits-and-continuity" class="level2" data-number="2.2">
<h2 data-number="2.2"><span class="header-section-number">2.2</span> Facts about limits and continuity</h2>
<p>There are some simple <span><strong>facts about limits</strong></span> that follow from the definition:<br />
<span class="math inline">\(\bullet\)</span> The limit is unique.<br />
<span class="math inline">\(\bullet\)</span> If <span class="math inline">\(f(x)=g(x)\)</span> (except possibly at <span class="math inline">\(x=a\)</span>) on some open interval containing <span class="math inline">\(a\)</span> then <span class="math inline">\(\lim_{x\rightarrow a}f(x)=\lim_{x\rightarrow a}g(x).\)</span><br />
<span class="math inline">\(\bullet\)</span> If <span class="math inline">\(f(x)\ge K\)</span> on either an interval <span class="math inline">\((a,b)\)</span> or an interval <span class="math inline">\((c,a)\)</span></p>
<p>and if <span class="math inline">\(\lim_{x\rightarrow a}f(x)=L\)</span> then <span class="math inline">\(L\ge K.\)</span></p>
<p>(A similar result holds by replacing all <span class="math inline">\(\ge\)</span> with <span class="math inline">\(\le\)</span>).<br />
<span class="math inline">\(\bullet\)</span> If <span class="math inline">\(\lim_{x\rightarrow a}f(x)=L\)</span> and <span class="math inline">\(\lim_{x\rightarrow a}g(x)=M\)</span> then</p>
<p>(i) <span class="math inline">\(\lim_{x\rightarrow a}(f(x)+g(x))=L+M\)</span></p>
<p>(ii) <span class="math inline">\(\lim_{x\rightarrow a}(f(x)g(x))=LM\)</span></p>
<p>(iii) if <span class="math inline">\(M\ne 0\)</span> then <span class="math inline">\(\lim_{x\rightarrow a}(f(x)/g(x))=L/M.\)</span></p>
<p>Note: In Durham the results (i),(ii),(iii) are sometimes known as the</p>
<p><span><strong>Calculus Of Limits Theorem (COLT)</strong></span>. However, this seems to be a rather grand name for these results and you will not find this name in any books.<br />
There are also some simple <span><strong>facts about continuous functions</strong></span> that follow from the definition and the above results:<br />
<span class="math inline">\(\bullet\)</span> If <span class="math inline">\(f(x)\)</span> and <span class="math inline">\(g(x)\)</span> are continuous functions then so are <span class="math inline">\(f(x)+g(x),\)</span>  <span class="math inline">\(f(x)g(x)\)</span> and <span class="math inline">\(f(x)/g(x).\)</span><br />
<span class="math inline">\(\bullet\)</span> All polynomial, rational, trigonometric and hyperbolic functions are continuous.<br />
<span class="math inline">\(\bullet\)</span> If <span class="math inline">\(f(x)\)</span> is continuous then so is <span class="math inline">\(|f(x)|.\)</span><br />
<span class="math inline">\(\bullet\)</span> If <span class="math inline">\(\lim_{x\to a}g(x)=L\)</span> exists and <span class="math inline">\(f(x)\)</span> is continuous at <span class="math inline">\(x=L\)</span> then <span class="math inline">\(\lim_{x\to a}(f\circ g)(x)=f(L).\)</span><br />
Eg. All the following functions are continuous:</p>
<p><span class="math inline">\(2x^3+x+7,\)</span> <span class="math inline">\(3x/(x-1),\)</span> <span class="math inline">\(|(1+x^2)/\sin x|,\)</span> <span class="math inline">\(\tan x.\)</span><br />
Note: Although <span class="math inline">\(\tan x\)</span> is continuous, it is not continuous on the interval <span class="math inline">\([0,\pi],\)</span> because this interval includes the point <span class="math inline">\(x=\pi/2\)</span> which is not in the domain of <span class="math inline">\(\tan x.\)</span><br />
Eg. <span class="math inline">\(\lim_{x\rightarrow \pi/2} x^2\sin x=(\pi/2)^2\sin(\pi/2)= \pi^2/4.\)</span><br />
Eg. <span class="math inline">\(\lim_{x\rightarrow 0} \frac{1}{x}\)</span> does not exist. The value of <span class="math inline">\(f(x)\)</span> can be made greater than any finite constant by taking <span class="math inline">\(x\)</span> sufficiently close to zero, so no limit exists.<br />
Eg. Calculate <span class="math inline">\(\lim_{x\rightarrow 3} \frac{2x^2-18}{x-3}.\)</span> <span class="math display">\[\frac{2x^2-18}{x-3}=\frac{2(x+3)(x-3)}{x-3}=2(x+3) 
\ \mbox{if} \ x\ne 3.\]</span> The value of the function at <span class="math inline">\(x=3\)</span> is irrelevant in defining the limit as <span class="math inline">\(x\rightarrow 3\)</span> so <span class="math display">\[\lim_{x\rightarrow 3} \frac{2x^2-18}{x-3}=\lim_{x\rightarrow 3} 2(x+3)=12.\]</span></p>
<p> </p>
<p>Eg. Calculate <span class="math inline">\(\lim_{x\rightarrow 25} \frac{\sqrt{x}-5}{x-25}.\)</span> <span class="math display">\[\frac{\sqrt{x}-5}{x-25}
=\frac{(\sqrt{x}-5)(\sqrt{x}+5)}{(x-25)(\sqrt{x}+5)}
=\frac{x-25}{(x-25)(\sqrt{x}+5)}
=\frac{1}{\sqrt{x}+5}
\ \mbox{if} \ x\ne 25.\]</span> <span class="math display">\[\lim_{x\rightarrow 25} 
\frac{\sqrt{x}-5}{x-25}
=\lim_{x\rightarrow 25} \frac{1}{\sqrt{x}+5}=\frac{1}{10}.\]</span><br />
</p>
</section>
<section id="the-pinching-theorem" class="level2" data-number="2.3">
<h2 data-number="2.3"><span class="header-section-number">2.3</span> The pinching theorem</h2>
<p><span>The pinching (squeezing) theorem: </span> If <span class="math inline">\(g(x)\le f(x) \le h(x)\)</span> for all <span class="math inline">\(x\ne a\)</span> in some open interval containing <span class="math inline">\(a\)</span> and <span class="math inline">\(\lim_{x\rightarrow a}g(x)=\lim_{x\rightarrow a}h(x)=L\)</span> then <span class="math inline">\(\lim_{x\rightarrow a}f(x)=L.\)</span><br />
Eg. Calculate <span class="math inline">\(\lim_{x\rightarrow 0} x^2\sin(\frac{1}{x}).\)</span><br />
As <span class="math inline">\(-1\le \sin(\frac{1}{x})\le 1\)</span> then <span class="math inline">\(-x^2\le x^2\sin(\frac{1}{x}) \le x^2.\)</span> Also <span class="math inline">\(\lim_{x\rightarrow 0} -x^2=0=\lim_{x\rightarrow 0} x^2.\)</span></p>
<p>Hence by the pinching theorem <span class="math inline">\(\lim_{x\rightarrow 0} x^2\sin(\frac{1}{x})=0.\)</span></p>
<figure>
<img src="new_pinching.png" style="width:7cm" alt="" /><figcaption>Graphs of <span class="math inline">\(f(x)=x^2\sin(1/x)\)</span> and the bounding functions <span class="math inline">\(g(x)=-x^2\)</span> and <span class="math inline">\(h(x)=x^2.\)</span></figcaption>
</figure>
</section>
<section id="two-trigonometric-limits" class="level2" data-number="2.4">
<h2 data-number="2.4"><span class="header-section-number">2.4</span> Two trigonometric limits</h2>
<p>Two important trigonometric limits that you may assume to be true and use are: <span class="math display">\[\lim_{x\rightarrow 0}\frac{\sin x}{x}=1 \qquad\mbox{and}\qquad
\lim_{x\rightarrow 0}\frac{1-\cos x}{x}=0.\]</span> The graphs in Figure <a href="#fig-twolimits" data-reference-type="ref" data-reference="fig-twolimits">5</a> provide some evidence to support these results.</p>
<figure>
<img src="new_twolimits.png" id="fig-twolimits" style="width:6cm" alt="" /><figcaption>Graphs of <span class="math inline">\(\frac{\sin x}{x}\)</span> and <span class="math inline">\(\frac{1-\cos x}{x}.\)</span></figcaption>
</figure>
<p>The first of these limits can be proved by applying the pinching theorem but to do this we will need to prove the inequalities <span class="math inline">\(\sin x &lt; x &lt; \tan x\)</span> for <span class="math inline">\(0&lt;x&lt;\pi/2.\)</span></p>
<figure>
<img src="trig1.png" style="width:5cm" alt="" /><figcaption>Some geometry to prove some inequalities</figcaption>
</figure>
<p>Consider the geometry illustrated in the above figure, where <span class="math inline">\(0&lt;\theta&lt;\pi/2.\)</span></p>
<p>Let <span class="math inline">\(T_1\)</span> be the area of the triangle with two black sides and a solid green side.</p>
<p>Let <span class="math inline">\(S\)</span> be the area of the sector with two black sides and a red arc of the unit circle.</p>
<p>Let <span class="math inline">\(T_2\)</span> be the area of the triangle with two black sides and a blue side.</p>
<p>Clearly we have the inequalities <span class="math inline">\(T_1&lt;S&lt;T_2.\)</span></p>
<p>Now   <span class="math inline">\(T_1=\frac{1}{2}\sin\theta, \qquad S=\pi\frac{\theta}{2\pi}=\frac{1}{2}\theta, \qquad T_2=\frac{1}{2}\tan\theta\)</span>  hence  <span class="math inline">\(\sin \theta &lt; \theta &lt; \tan \theta\)</span>  as required.</p>
<p>Next consider upper and lower bounding functions for <span class="math inline">\(\frac{x}{\sin x}\)</span> where <span class="math inline">\(x\in(0,\pi/2).\)</span> Using the above inequalities for <span class="math inline">\(x\)</span> we have <span class="math display">\[1=\frac{\sin x}{\sin x}&lt;\frac{x}{\sin x}&lt;\frac{\tan x}{\sin x}=\frac{1}{\cos x}.\]</span> As all the combinations of functions in this inequality produce even functions then the result extends to <span class="math inline">\(x\in(-\pi/2,0)\cup(0,\pi/2).\)</span> The limits of the bounding functions are <span class="math inline">\(\lim_{x\to 0}1=1\)</span> and <span class="math inline">\(\lim_{x\to 0}(1/\cos x)=1\)</span> hence by the pinching theorem <span class="math inline">\(\lim_{x\to 0}(x/\sin x)=1\)</span> and therefore <span class="math inline">\(\lim_{x\to 0}((\sin x)/x)=1.\)</span><br />
Now that we have proved the first trigonometric limit we can use it to prove the second, <span class="math display">\[\lim_{x\rightarrow 0}\frac{1-\cos x}{x}=
\lim_{x\rightarrow 0}\frac{(1-\cos x)(1+\cos x)}{x(1+\cos x)}=
\lim_{x\rightarrow 0}\frac{\sin^2 x}{x(1+\cos x)}=
\lim_{x\rightarrow 0}\bigg(\frac{\sin x}{x}\bigg)^2\frac{x}{(1+\cos x)}=
0.\]</span></p>
<p>Here are some more examples that use the first trigonometric limit.<br />
Eg. Calculate <span class="math inline">\(\lim_{x\rightarrow 0} \frac{\sin(2x)}{x}.\)</span> <span class="math display">\[\lim_{x\rightarrow 0} \frac{\sin(2x)}{x}
=\lim_{x\rightarrow 0} \frac{2\sin(2x)}{2x}
=\lim_{u\rightarrow 0} \frac{2\sin(u)}{u}=2\cdot 1=2.\]</span> The above used the change of variable <span class="math inline">\(u=2x\)</span> and then the first of the two important trigonometric limits given above.<br />
Eg. Calculate <span class="math inline">\(\lim_{x\rightarrow 0} \frac{\tan x}{x}.\)</span> <span class="math display">\[\lim_{x\rightarrow 0} \frac{\tan x}{x}=
\lim_{x\rightarrow 0} \frac{\sin x}{x\cos x}=
\bigg(\lim_{x\rightarrow 0} \frac{\sin x}{x}\bigg)
\bigg(\lim_{x\rightarrow 0} \frac{1}{\cos x}\bigg)
=1\cdot 1=1.\]</span></p>
<p> </p>
<p>Eg. Calculate <span class="math inline">\(\lim_{x\rightarrow 0} \frac{1-\cos x}{x^2}.\)</span></p>
<p>For <span class="math inline">\(-\pi&lt;x&lt;\pi\)</span> <span class="math display">\[\frac{1-\cos x}{x^2}= 
\frac{(1-\cos x)(1+\cos x)}{x^2(1+\cos x)}
=\bigg(\frac{\sin x}{x}\bigg)^2\frac{1}{1+\cos x}\]</span> Hence by using the first important trigonometric limit we have that <span class="math display">\[\lim_{x\rightarrow 0} \frac{1-\cos x}{x^2}
=\lim_{x\rightarrow 0}\bigg\{ \bigg(\frac{\sin x}{x}\bigg)^2\frac{1}{1+\cos x}
\bigg\}
=(1)^2\cdot\frac{1}{1+1}=\frac{1}{2}.\]</span></p>
<p> </p>
</section>
<section id="classification-of-discontinuities" class="level2" data-number="2.5">
<h2 data-number="2.5"><span class="header-section-number">2.5</span> Classification of discontinuities</h2>
<p>If a function <span class="math inline">\(f(x)\)</span> is not continuous at a point <span class="math inline">\(x=a\)</span> then we say it has a discontinuity at <span class="math inline">\(x=a.\)</span> There are different types of discontinuity and these are best classified by considering how the function behaves on each side of the point <span class="math inline">\(x=a.\)</span> This motivates the definition of the following one-sided limits.<br />
<span><strong>Defn:</strong></span> <span class="math inline">\(f(x)\)</span> has a <span><strong>right-sided limit</strong></span> <span class="math inline">\(L^+=\lim_{x\rightarrow a^+} f(x)\)</span> as <span class="math inline">\(x\)</span> tends to <span class="math inline">\(a\)</span> from above if <span class="math display">\[\forall \ \ \varepsilon&gt;0 \ \ \exists \ \ \delta&gt;0 \ \ \mbox{s.t} \ \
|f(x)-L^+|&lt;\varepsilon\ \ \mbox{when} \ \ 0&lt;x-a&lt;\delta.\]</span> Note that the difference between this definition and the definition of the limit is the removal of the modulus sign in <span class="math inline">\(|x-a|.\)</span> This means that we only need to worry about points to the right of <span class="math inline">\(a\)</span> when requiring the function to be close to <span class="math inline">\(L^+.\)</span><br />
Similarly, we have the definition</p>
<p><span><strong>Defn:</strong></span> <span class="math inline">\(f(x)\)</span> has a <span><strong>left-sided limit</strong></span> <span class="math inline">\(L^-=\lim_{x\rightarrow a^-} f(x)\)</span> as <span class="math inline">\(x\)</span> tends to <span class="math inline">\(a\)</span> from below if <span class="math display">\[\forall \ \ \varepsilon&gt;0 \ \ \exists \ \ \delta&gt;0 \ \ \mbox{s.t} \ \
|f(x)-L^-|&lt;\varepsilon\ \ \mbox{when} \ \ 0&lt;a-x&lt;\delta.\]</span> Here we only need to worry about points to the left of <span class="math inline">\(a\)</span> when requiring the function to be close to <span class="math inline">\(L^-.\)</span><br />
It should be obvious that <span class="math inline">\(L=\lim_{x\rightarrow a} f(x)\)</span> exists iff <span class="math inline">\(L^+\)</span> and <span class="math inline">\(L^-\)</span> both exist and are equal. In which case <span class="math inline">\(L=L^+=L^-.\)</span><br />
There are 3 types of discontinuity:<br />
(i) <span><strong>Removable discontinuity</strong></span>.</p>
<p>In this case <span class="math inline">\(L\)</span> exists but <span class="math inline">\(f(a)\ne L.\)</span></p>
<p>The discontinuity can be removed to make the continuous function <span class="math display">\[g(x)=\begin{cases}
f(x) &amp; \mbox{if \ } x\ne a \\
L &amp; \mbox{if \ } x=a.
\end{cases}\]</span></p>
<p>Eg. The following function (Figure <a href="#fig-open3" data-reference-type="ref" data-reference="fig-open3">8</a>i) has a removable discontinuity at <span class="math inline">\(x=0,\)</span> <span class="math display">\[f(x)=\begin{cases}
x^2 &amp; \mbox{if \ } x\ne 0 \\
1 &amp; \mbox{if \ } x=0.
\end{cases}\]</span> Removing this discontinuity yields the continuous function <span class="math inline">\(g(x)=x^2.\)</span></p>
<p><img src="new_open3.png" title="fig:" id="fig-open3" style="width:5cm" alt="3 types of discontinuities at x=0: (i) removable; (ii) jump; (iii) infinite. " /> <img src="new_open22.png" title="fig:" id="fig-open3" style="width:5cm" alt="3 types of discontinuities at x=0: (i) removable; (ii) jump; (iii) infinite. " /> <img src="new_infdis.png" title="fig:" id="fig-open3" style="width:5cm" alt="3 types of discontinuities at x=0: (i) removable; (ii) jump; (iii) infinite. " /></p>
<p><br />
(ii) <span><strong>Jump discontinuity.</strong></span></p>
<p>In this case both <span class="math inline">\(L^+\)</span> and <span class="math inline">\(L^-\)</span> exist but <span class="math inline">\(L^+\ne L^-.\)</span><br />
Eg. The following function (Figure <a href="#fig-open3" data-reference-type="ref" data-reference="fig-open3">8</a>ii) has a jump discontinuity at <span class="math inline">\(x=0,\)</span> <span class="math display">\[f(x)=\begin{cases}
1 &amp; \mbox{if \ } x\le 0 \\
x^2 &amp; \mbox{if \ } x&gt;0.
\end{cases}\]</span> In this example <span class="math inline">\(L^+=0\ne 1=L^-.\)</span><br />
Eg. The signum function <span class="math display">\[\mbox{sgn}(x)=\begin{cases}
-1 &amp; \text{if $x&lt;0$} \\
\ 0 &amp; \text{if $x=0$} \\
\ 1 &amp; \text{if $x&gt;0$} \\
\end{cases}\]</span> has a jump discontinuity at <span class="math inline">\(x=0.\)</span> In this example <span class="math inline">\(L^+=1\ne -1=L^-.\)</span><br />
(iii) <span><strong>Infinite discontinuity.</strong></span></p>
<p>In this case at least one of <span class="math inline">\(L^+\)</span> or <span class="math inline">\(L^-\)</span> does not exist.<br />
Eg. The function <span class="math inline">\(f(x)=1/x\)</span> (Figure <a href="#fig-open3" data-reference-type="ref" data-reference="fig-open3">8</a>iii) has an infinite discontinuity at <span class="math inline">\(x=0.\)</span> In this example neither <span class="math inline">\(L^+\)</span> nor <span class="math inline">\(L^-\)</span> exist.<br />
</p>
</section>
<section id="limits-as-xrightarrow-infty." class="level2" data-number="2.6">
<h2 data-number="2.6"><span class="header-section-number">2.6</span> Limits as <span class="math inline">\(x\rightarrow \infty.\)</span></h2>
<p>So far we have only been concerned with the limit of a function <span class="math inline">\(f(x)\)</span> as <span class="math inline">\(x\)</span> approaches a finite point <span class="math inline">\(a.\)</span> However, it is also possible to define a limit as <span class="math inline">\(x\rightarrow\infty.\)</span><br />
<span><em>Rough idea #4:</em></span></p>
<p>A function <span class="math inline">\(f(x)\)</span> has a limit <span class="math inline">\(L\)</span> as <span class="math inline">\(x\rightarrow\infty\)</span> if <span class="math inline">\(f(x)\)</span> can be kept arbitrarily close to <span class="math inline">\(L\)</span> by making <span class="math inline">\(x\)</span> sufficiently large.<br />
<span><strong>Defn</strong></span>: <span class="math inline">\(f(x)\)</span> has a <span><strong>limit <span class="math inline">\(L\)</span> as <span class="math inline">\(x\)</span> tends to <span class="math inline">\(\infty\)</span></strong></span> if <span class="math display">\[\forall \ \ \varepsilon&gt;0 \ \ \exists \ \ S&gt;0 \ \ \mbox{s.t} \ \
|f(x)-L|&lt;\varepsilon\ \ \mbox{when} \ \ x&gt;S.\]</span></p>
<p>We then write <span class="math display">\[\lim_{x\rightarrow \infty}f(x)=L \quad \mbox{or equivalently}\quad 
f(x)\rightarrow L \ \ \mbox{as} \ \ x\rightarrow \infty.\]</span> If there is no such <span class="math inline">\(L\)</span> then we say that <span><em>no limit exists</em></span>.<br />
The corresponding definition associated with <span class="math inline">\(\lim_{x\rightarrow -\infty}f(x)=L\)</span> should be obvious</p>
<p><span><strong>Defn</strong></span>: <span class="math inline">\(f(x)\)</span> has a <span><strong>limit <span class="math inline">\(L\)</span> as <span class="math inline">\(x\)</span> tends to <span class="math inline">\(-\infty\)</span></strong></span> if <span class="math display">\[\forall \ \ \varepsilon&gt;0 \ \ \exists \ \ S&lt;0 \ \ \mbox{s.t} \ \
|f(x)-L|&lt;\varepsilon\ \ \mbox{when} \ \ x&lt;S.\]</span></p>
<p>Eg. <span class="math inline">\(\lim_{x\rightarrow \infty}\frac{1}{x}=0.\)</span> This should be clear because <span class="math inline">\(\frac{1}{x}\)</span> can be made as close to zero as required by making <span class="math inline">\(x\)</span> sufficiently large. An easy way to calculate limits as <span class="math inline">\(x\to\infty\)</span> is to first make the substitution <span class="math inline">\(u=1/x\)</span> and then use the fact that if <span class="math inline">\(\lim_{x\rightarrow\infty}f(x)\)</span> exists then <span class="math inline">\(\lim_{x\rightarrow\infty}f(x)=\lim_{u\to 0^+}f(1/u)\)</span>. This has transformed the limit into one that we are already familiar with.</p>
<p>Eg. <span class="math inline">\(\lim_{x\rightarrow \infty}\frac{1}{x}=
\lim_{u\rightarrow 0^+} u=0.\)</span><br />
Eg. Calculate <span class="math inline">\(\lim_{x\rightarrow \infty}\frac{x\cos(1/x)+2}{x}.\)</span> By using the substitution <span class="math inline">\(u=1/x\)</span> we have that <span class="math display">\[\lim_{x\rightarrow \infty}\frac{x\cos(1/x)+2}{x}=
\lim_{u\rightarrow 0^+} \frac{\frac{1}{u}\cos u+2}{\frac{1}{u}}=
\lim_{u\rightarrow 0^+} (\cos u+2u)=\cos(0)+0=1.\]</span><br />
Our earlier discussion of a horizontal asymptote can now be made more precise, in that the graph of a function <span class="math inline">\(f(x)\)</span> will have a horizontal asymptote <span class="math inline">\(y=L\)</span> if <span class="math inline">\(\lim_{x\rightarrow \infty} f(x)=L.\)</span> <span class="math display">\[\mbox{Eg.} \quad \lim_{x\rightarrow \infty}\frac{2x+3}{x+5}=
\lim_{x\rightarrow \infty}\frac{2+\frac{3}{x}}{1+\frac{5}{x}}=
\frac{2+0}{1+0}=2.
\quad
\mbox{\ \hskip 5cm}\]</span> Here we have used the result that <span class="math inline">\(\lim_{x\rightarrow \infty}\frac{1}{x}=0,\)</span> together with the earlier facts about limits. We see that calculating this limit shows that the graph of this rational function has the horizontal asymptote <span class="math inline">\(y=2,\)</span> reproducing our earlier observations about the horizontal asymptotes of rational functions.</p>
</section>
<section id="the-intermediate-value-theorem" class="level2" data-number="2.7">
<h2 data-number="2.7"><span class="header-section-number">2.7</span> The intermediate value theorem</h2>
<p><span><strong>The intermediate value theorem</strong></span> states that if <span class="math inline">\(f(x)\)</span> is continuous on <span class="math inline">\([a,b]\)</span> and <span class="math inline">\(u\)</span> is any number between <span class="math inline">\(f(a)\)</span> and <span class="math inline">\(f(b)\)</span> (ie. either <span class="math inline">\(f(a)&lt;u&lt;f(b)\)</span> or <span class="math inline">\(f(b)&lt;u&lt;f(a)\)</span>) then <span class="math inline">\(\exists\)</span> (at least one) <span class="math inline">\(c\in(a,b)\)</span>  s.t.  <span class="math inline">\(f(c)=u.\)</span></p>
<figure>
<img src="new_ivt.png" style="width:6cm" alt="" /><figcaption>An illustration of the intermediate value theorem.</figcaption>
</figure>
<p>Eg. <span class="math inline">\(f(x)=\sin x\)</span> is continuous on <span class="math inline">\([0,\pi/2]\)</span> and <span class="math inline">\(f(0)=0&lt;\frac{1}{2}&lt;1=f(\pi/2)\)</span> so by the intermediate value theorem there is (at least) one point <span class="math inline">\(x\)</span> in <span class="math inline">\((0,\pi/2)\)</span> s.t. <span class="math inline">\(\sin x=\frac{1}{2}.\)</span><br />
It is important that <span class="math inline">\(f(x)\)</span> is continuous throughout the interval, otherwise the theorem does not apply.<br />
Eg. <span class="math inline">\(f(x)=\frac{\mbox{sgn}(x) }{1+x^2}\)</span> has <span class="math inline">\(f(-1)=-\frac{1}{2}&lt;\frac{1}{5}&lt;\frac{1}{2}=f(1)\)</span> but there is no <span class="math inline">\(x\)</span> in <span class="math inline">\((-1,1)\)</span>  s.t. <span class="math inline">\(f(x)=\frac{1}{5}.\)</span> The intermediate value theorem does not apply because <span class="math inline">\(f(x)\)</span> is not continuous at <span class="math inline">\(x=0.\)</span> There is a jump discontinuity at <span class="math inline">\(x=0\)</span> with <span class="math inline">\(\lim_{x\rightarrow 0^+}f(x)=1\ne -1
=\lim_{x\rightarrow 0^-}f(x).\)</span><br />
An application of the intermediate value theorem is locating the zeros of a function. If the function <span class="math inline">\(f(x)\)</span> is continuous on <span class="math inline">\([a,b]\)</span> and we know that either <span class="math inline">\(f(a)&lt;0&lt;f(b)\)</span> or <span class="math inline">\(f(b)&lt;0&lt;f(a)\)</span> then by the intermediate value theorem the equation <span class="math inline">\(f(x)=0\)</span> has at least one root between <span class="math inline">\(a\)</span> and <span class="math inline">\(b.\)</span><br />
Eg. The function <span class="math inline">\(f(x)=x^2-2\)</span> is continuous on <span class="math inline">\([1,2]\)</span> with <span class="math inline">\(f(1)=-1&lt;0\)</span> and <span class="math inline">\(f(2)=2&gt;0,\)</span> so there is at least one root of the equation <span class="math inline">\(x^2-2=0\)</span> in <span class="math inline">\((1,2)\)</span> (of course the root is <span class="math inline">\(x=\sqrt{2}=1.4142...\)</span>).<br />
A repeated iterated application of this approach gives the <span><em>bisection method</em></span>, which can be used to locate the roots of a wide variety of equations to any desired accuracy.<br />
</p>
</section>
<section id="summary-limits-and-continuity" class="level2" data-number="2.8">
<h2 data-number="2.8"><span class="header-section-number">2.8</span> Summary: Limits and continuity</h2>
<p>You should have a good understanding of the concept of a limit as well as knowing the precise definition of a limit, and how continuity is defined in terms of limits. You should be familiar with methods to calculate limits. Here are some key points:</p>
<ul>
<li><p>You should know the <span class="math inline">\(\varepsilon\)</span>-<span class="math inline">\(\delta\)</span> definition of a limit <span class="math inline">\(\lim_{x \to a} f(x)\)</span> and understand the concept of taking <span class="math inline">\(x\)</span> closer and closer to <span class="math inline">\(a\)</span> but not reaching <span class="math inline">\(a\)</span> (so the limit does not depend in any way on <span class="math inline">\(f(a)\)</span>).</p></li>
<li><p>A function <span class="math inline">\(f(x)\)</span> is <span><em>continuous</em></span> at <span class="math inline">\(x=a\)</span> if <span class="math inline">\(\lim_{x \to a} f(x) = f(a)\)</span>.</p></li>
<li><p>Any algebraic combination of continuous functions gives a continuous function assuming the combination does to involve division by zero since limits of algebraic combinations of functions can be evaluated as the algebraic combinations of the limits (assuming they exist and don’t involve dividing by zero).</p></li>
<li><p>Indeterminate limits of the form <span class="math inline">\(0/0\)</span> or <span class="math inline">\(\infty/\infty\)</span> may be well-defined, and if so can be calculated by cancelling common factors in the numerator and denominator.</p></li>
<li><p>You should know how to use the <span><em>Pinching (Squeezing) theorem</em></span>.</p></li>
<li><p><span class="math inline">\(\lim_{x \to 0} \frac{\sin x}{x} = 1\)</span> and <span class="math inline">\(\lim_{x \to 0} \frac{1 - \cos x}{x} = 0\)</span>.</p></li>
<li><p>You should know the definitions of <span><em>left-sided</em></span> and <span><em>right-sided limits</em></span> and how these are used to classify <span><em>discontinuities</em></span> at <span class="math inline">\(x=a\)</span>.</p></li>
<li><p>You should understand the concept of limits as <span class="math inline">\(x \to \pm \infty\)</span> and that they are equivalent to one-sided limits <span class="math inline">\(u \to 0^{\pm}\)</span> by changing variable to <span class="math inline">\(u = 1/x\)</span>.</p></li>
<li><p>You should know what the <span><em>Intermediate Value Theorem (IVT)</em></span> is and how it can be used to prove the existence of, and numerically approximate, zeros of continuous functions.</p></li>
</ul>
</section>
</section>
<section id="differentiation" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Differentiation</h1>
<section id="derivative-as-a-limit" class="level2" data-number="3.1">
<h2 data-number="3.1"><span class="header-section-number">3.1</span> Derivative as a limit</h2>
<p>Geometrically the derivative <span class="math inline">\(f&#39;(a)\)</span> of a function <span class="math inline">\(f(x)\)</span> at <span class="math inline">\(x=a\)</span> is equal to the slope of the tangent to the graph of <span class="math inline">\(f(x)\)</span> at <span class="math inline">\(x=a.\)</span></p>
<figure>
<img src="new_derivative.png" id="fig-derivative" style="width:8cm" alt="" /><figcaption>The graph of a function <span class="math inline">\(f(x)\)</span>, the tangent at <span class="math inline">\(x=a\)</span> and the secant through the points on the graph at <span class="math inline">\(x=a\)</span> and <span class="math inline">\(x=a+h.\)</span></figcaption>
</figure>
<p>A secant is a line that intersects a curve at two points (the part of the secant that is between the two intersection points is called a chord).</p>
<p>Consider a secant that intersects the graph of <span class="math inline">\(f(x)\)</span> at the two <span class="math inline">\((x,y)\)</span> points <span class="math inline">\((a,f(a))\)</span> and <span class="math inline">\((a+h,f(a+h)).\)</span> The slope of this secant is given by the difference quotient <span class="math inline">\((f(a+h)-f(a))/h.\)</span> As the two points approach each other ie. as <span class="math inline">\(|h|\)</span> decreases, the secant approaches the tangent at <span class="math inline">\(x=a.\)</span> The tangent is obtained in the limit as <span class="math inline">\(h\rightarrow 0\)</span> and the derivative at <span class="math inline">\(a\)</span> is the slope of the secant in this limit ie. <span class="math display">\[f&#39;(a)=\lim_{h\rightarrow 0}\frac{f(a+h)-f(a)}{h}\]</span> providing this limit exists.</p>
<p>If this limit exists then we say that <span><strong><span class="math inline">\(f(x)\)</span> is differentiable at <span class="math inline">\(x=a.\)</span></strong></span></p>
<p>Eg. Use the limit definition of the derivative to calculate <span class="math inline">\(f&#39;(a)\)</span> for <span class="math inline">\(f(x)=x^2.\)</span> <span class="math display">\[f&#39;(a)=
\lim_{h\rightarrow 0}
\frac{f(a+h)-f(a)}{h}
=\lim_{h\rightarrow 0}
\frac{(a+h)^2-a^2}{h}
=\lim_{h\rightarrow 0}\frac{2ah+h^2}{h}
=\lim_{h\rightarrow 0}(2a+h)=2a.\]</span> This is, of course, the expected result from the knowledge that <span class="math inline">\(f&#39;(x)=2x.\)</span><br />
Eg. Use the limit definition of the derivative to calculate <span class="math inline">\(f&#39;(\pi)\)</span> for <span class="math inline">\(f(x)=\sin x.\)</span> <span class="math display">\[f&#39;(\pi)=
\lim_{h\rightarrow 0}
\frac{f(\pi+h)-f(\pi)}{h}
=\lim_{h\rightarrow 0}
\frac{\sin(\pi+h)-\sin\pi}{h}
=\lim_{h\rightarrow 0}\frac{\sin\pi\cos h+\cos\pi\sin h}{h}\]</span> <span class="math display">\[=\lim_{h\rightarrow 0}\frac{-\sin h}{h}=-1\]</span> where the final equality uses the earlier important trigonometric limit result.</p>
<p>This is, of course, the expected answer from the knowledge that <span class="math inline">\(f&#39;(x)=\cos x\)</span> giving <span class="math inline">\(f&#39;(\pi)=\cos\pi=-1.\)</span><br />
If <span class="math inline">\(f&#39;(a)\)</span> exists for all <span class="math inline">\(a\)</span> in <span class="math inline">\(\mbox{Dom}\,f\)</span> we say that <span><strong><span class="math inline">\(f(x)\)</span> is differentiable</strong></span> and then <span class="math inline">\(f&#39;(a)\)</span> defines a function <span class="math inline">\(f&#39;(x)\)</span> called the derivative.<br />
Eg. Use the limit definition of the derivative to calculate the derivative of the function <span class="math inline">\(f(x)=x\cos x.\)</span> <span class="math display">\[f&#39;(x)
=\lim_{h\rightarrow 0}
\frac{f(x+h)-f(x)}{h}
=\lim_{h\rightarrow 0}\frac{(x+h)\cos(x+h)-x\cos x}{h}\]</span> <span class="math display">\[=\lim_{h\rightarrow 0}\frac{(x+h)(\cos x\cos h-\sin x\sin h)-x\cos x}{h}\]</span> <span class="math display">\[=\lim_{h\rightarrow 0} \bigg(x\cos x\frac{\cos h-1}{h}-x\sin x \frac{\sin h}{h}
+\cos x\cos h-\sin x\sin h\bigg)
=-x\sin x+\cos x\]</span> where we have used both of the earlier important trigonometric limit results.<br />
The fact that the derivative is equal to the slope of the tangent of the graph allows us to determine a Cartesian equation for the tangent by calculating the derivative. Explicitly, the tangent line at the point <span class="math inline">\((a,f(a))\)</span> is given by <span class="math inline">\(y=f(a)+f&#39;(a)(x-a).\)</span><br />
Eg. For the function <span class="math inline">\(f(x)=4x^3-x,\)</span> find a Cartesian equation for the tangent to the graph at the point <span class="math inline">\((1,3).\)</span></p>
<p><span class="math inline">\(f&#39;(x)=12x^2-1\)</span> so <span class="math inline">\(f&#39;(1)=11.\)</span> The tangent line is given by</p>
<p><span class="math inline">\(y=f(1)+f&#39;(1)(x-1)=3+11(x-1)=11x-8\)</span><br />
A necessary condition for a function to be differentiable at a point is that it is continuous at that point, but this is not a sufficient condition.<br />
Geometrically, there are two ways that a function can fail to be differentiable at a point where it is continuous:<br />
(i). The tangent line is vertical at that point.<br />
Eg. The function <span class="math inline">\(f(x)=x^{1/3}\)</span> is continuous in <span class="math inline">\(\mathbb{R}\)</span> but it is not differentiable at <span class="math inline">\(x=0.\)</span> The difference quotient at <span class="math inline">\(x=0\)</span> is <span class="math display">\[\frac{f(0+h)-f(0)}{h}=\frac{h^{1/3}}{h}=\frac{1}{h^{2/3}}\]</span> and no limit exists as <span class="math inline">\(h\rightarrow 0\)</span> because the above grows without bound.<br />
(ii). There is no tangent line at that point.<br />
Eg. The function <span class="math inline">\(f(x)=|x|\)</span> is continuous in <span class="math inline">\(\mathbb{R}\)</span> but it is not differentiable at <span class="math inline">\(x=0.\)</span> The difference quotient at <span class="math inline">\(x=0\)</span> is <span class="math display">\[\frac{f(0+h)-f(0)}{h}=\frac{|h|}{h}
=\begin{cases} 
-1 &amp; \text{if}\ h&lt;0\\
1 &amp; \text{if}\ h&gt;0\\
\end{cases}\]</span> The left and right limits therefore both exist <span class="math display">\[\lim_{h\rightarrow 0^+}\frac{f(0+h)-f(0)}{h}=1\]</span> and <span class="math display">\[\lim_{h\rightarrow 0^-}\frac{f(0+h)-f(0)}{h}=-1\]</span> but these are not equal, so <span class="math display">\[\lim_{h\rightarrow 0}\frac{f(0+h)-f(0)}{h}\]</span> does not exist.</p>
</section>
<section id="the-leibniz-and-chain-rules" class="level2" data-number="3.2">
<h2 data-number="3.2"><span class="header-section-number">3.2</span> The Leibniz and chain rules</h2>
<p>If <span class="math inline">\(f(x)\)</span> is differentiable then its derivative <span class="math inline">\(f&#39;(x)\)</span> may also be differentiable, in which case we denote its derivative by <span class="math inline">\(f&#39;&#39;(x)\)</span> ie. the <span><strong>second derivative</strong></span> of <span class="math inline">\(f(x).\)</span> Similarly the third derivative is <span class="math inline">\(f&#39;&#39;&#39;(x)\)</span> and in general the <span class="math inline">\(n^{th}\)</span> derivative is <span class="math inline">\(f^{(n)}(x)\)</span> so that <span class="math inline">\(f^{(3)}(x)=f&#39;&#39;&#39;.\)</span> This notation is due to Lagrange (1736-1813), but other notations are also common.<br />
<span class="math inline">\(f&#39;(x)=\frac{df}{dx}, \ f&#39;&#39;(x)=\frac{d^2 f}{dx^2}, \ f^{(n)}(x)=\frac{d^n f}{dx^n}\)</span> is due to Leibniz (1646-1716).</p>
<p> </p>
<p><span class="math inline">\(f&#39;(x)=Df(x), \ f&#39;&#39;(x)=D^2f(x), \ f^{(n)}(x)=D^nf(x)\)</span> is due to Euler (1707-1783).</p>
<p> </p>
<p>Finally, if the independent variable represents time, say <span class="math inline">\(f(t),\)</span> then <span class="math inline">\(f&#39;(t)=\dot f\)</span> and <span class="math inline">\(f&#39;&#39;(t)=\ddot f\)</span> is due to Newton (1642-1727). As we have seen, the derivative <span class="math inline">\(\frac{df}{dx}\)</span> is the slope of the tangent to the graph of <span class="math inline">\(f(x).\)</span> This means that the derivative <span class="math inline">\(\frac{df}{dx}\)</span> measures the rate of change of the dependent variable <span class="math inline">\(f\)</span> with respect to changes in the independent variable <span class="math inline">\(x\)</span>. In the case that the independent variable is time <span class="math inline">\(t,\)</span> the derivative measures the rate of change with time, so if the dependent variable, say <span class="math inline">\(X(t)\)</span> represents the position of an object confined to a line then <span class="math inline">\(\dot X\)</span> is the velocity of the object, with <span class="math inline">\(|\dot X|\)</span> the speed, and <span class="math inline">\(\ddot X\)</span> is the acceleration of the object.<br />
The product rule for differentiation is just the first case of the more general <span><strong>Leibniz rule</strong></span>:</p>
<p>If <span class="math inline">\(f(x)\)</span> and <span class="math inline">\(g(x)\)</span> are both differentiable <span class="math inline">\(n\)</span> times then so is the product <span class="math inline">\(f(x)g(x)\)</span> with <span class="math display">\[D^n(fg)=\sum_{k=0}^n\binom{n}{k}(D^kf)(D^{n-k}g)\]</span> where <span class="math inline">\(\binom{n}{k}=\frac{n!}{k!(n-k)!}\)</span> is the binomial coefficient familiar from Pascal’s triangle</p>
<figure>
<img src="new_pas.png" alt="" /><figcaption>The binomial coefficients arranged into Pascal’s triangle.</figcaption>
</figure>
<p>Eg. Use the Leibniz rule to calculate <span class="math inline">\(D^3(x^2\sin x)\)</span> using</p>
<p><span class="math inline">\(D^3(fg)=f(D^3g)+3(Df)(D^2g)+3(D^2f)(Dg)+(D^3f)g.\)</span></p>
<p><span class="math inline">\(f=x^2,\quad Df=2x, \quad D^2f=2, \quad D^3f=0.\)</span></p>
<p><span class="math inline">\(g=\sin x,\quad Dg=\cos x, \quad D^2g=-\sin x, \quad D^3g=-\cos x.\)</span></p>
<p><span class="math inline">\(D^3(x^2\sin x)=-x^2\cos x-(3)2x\sin x+(3)2\cos x+0\sin x
=(6-x^2)\cos x-6x\sin x.\)</span></p>
<p>To handle the differentiation of composite functions <span class="math inline">\((f\circ g)(x)=f(g(x))\)</span> we turn to the following theorem:<br />
The <span><strong>chain rule theorem</strong></span> states that if <span class="math inline">\(g(x)\)</span> is differentiable at <span class="math inline">\(x\)</span> and <span class="math inline">\(f(x)\)</span> is differentiable at <span class="math inline">\(g(x)\)</span> then the composition <span class="math inline">\((f\circ g)(x)\)</span> is differentiable at <span class="math inline">\(x\)</span> with <span class="math display">\[(f\circ g)&#39;(x)=f&#39;(g(x))g&#39;(x).\]</span></p>
<p>Recall that prime denotes differentiation with respect to the argument so in Leibniz notation the above formula may be written more crudely as <span class="math display">\[\frac{d}{dx}f(g(x))=\frac{df}{dg}\ \frac{dg}{dx}\]</span> where we need to be aware that on the right hand side the argument of the first factor is <span class="math inline">\(g(x)\)</span> and the argument of the second factor is <span class="math inline">\(x.\)</span></p>
<p>This form is useful as a mnemonic (think of ‘cancelling’ the <span class="math inline">\(dg\)</span> factor) but it is no more than this.</p>
<p><span class="math display">\[\mbox{Eg.}\ \mbox{Calculate} \
\frac{d}{dx}\bigg(\bigg(x+\frac{1}{x}\bigg)^{-3}\bigg).
\hskip 9cm\]</span> In terms of the above notation <span class="math inline">\(g(x)=x+\frac{1}{x}\)</span> and <span class="math inline">\(f(x)=x^{-3}\)</span></p>
<p>giving <span class="math inline">\(g&#39;(x)=1-\frac{1}{x^2}\)</span> and <span class="math inline">\(f&#39;(x)=-3x^{-4}\)</span> thus <span class="math display">\[\frac{d}{dx}\bigg(\bigg(x+\frac{1}{x}\bigg)^{-3}\bigg)
=f&#39;(g(x))g&#39;(x)=-3\bigg(x+\frac{1}{x}\bigg)^{-4}\bigg(1-\frac{1}{x^2}\bigg).\]</span><br />
Eg. <span class="math inline">\(\frac{d}{dt}\cos(t^2)=-2t\sin(t^2).\)</span><br />
</p>
</section>
<section id="lhôpitals-rule" class="level2" data-number="3.3">
<h2 data-number="3.3"><span class="header-section-number">3.3</span> L’Hôpital’s rule</h2>
<p><span><strong>Only use this method in assignments/exam questions when told to do so *</strong></span><br />
Recall that if <span class="math inline">\(\lim_{x\rightarrow a} f(x)=L\)</span> and <span class="math inline">\(\lim_{x\rightarrow a} g(x)=M\ne 0\)</span> then <span class="math inline">\(\lim_{x\rightarrow a} {f(x)}/{g(x)}={L}/{M}\)</span>.</p>
<p>Clearly this result is not applicable to the situation where <span class="math inline">\(L=M=0,\)</span> which is called an <span><strong>indeterminant form</strong></span>. We have already seen how to deal with situations like this directly, but an alternative (and often easier) approach is sometimes available by making use of the following.<br />
<span><strong>L’Hôpital’s rule</strong></span></p>
<p>Let <span class="math inline">\(f(x)\)</span> and <span class="math inline">\(g(x)\)</span> be differentiable on <span class="math inline">\(I=(a-h,a)\cup(a,a+h)\)</span> for some <span class="math inline">\(h&gt;0,\)</span> with <span class="math inline">\(\lim_{x\rightarrow a} f(x)=\lim_{x\rightarrow a} g(x)=0.\)</span></p>
<p>If <span class="math inline">\(\lim_{x\rightarrow a} \frac{f&#39;(x)}{g&#39;(x)}\)</span> exists and <span class="math inline">\(g&#39;(x)\ne 0 \ \forall \
x\in I\)</span> then <span class="math display">\[\lim_{x\rightarrow a} \frac{f(x)}{g(x)}=
\lim_{x\rightarrow a} \frac{f&#39;(x)}{g&#39;(x)}.\]</span></p>
<p>Proof: We shall only consider the proof for the slightly easier situation in which <span class="math inline">\(f(x)\)</span> and <span class="math inline">\(g(x)\)</span> are both differentiable at <span class="math inline">\(x=a\)</span> and <span class="math inline">\(g&#39;(a)\ne 0.\)</span></p>
<p>In this case <span class="math display">\[\lim_{x\rightarrow a} \frac{f(x)}{g(x)}=
\lim_{x\rightarrow a} \frac{f(x)-f(a)}{g(x)-g(a)}=
\lim_{x\rightarrow a} \frac{\frac{f(x)-f(a)}{x-a}}{\frac{g(x)-g(a)}{x-a}}=
\frac{\lim_{x\rightarrow a} {\frac{f(x)-f(a)}{x-a}}}
{\lim_{x\rightarrow a}{\frac{g(x)-g(a)}{x-a}}}=\frac{f&#39;(a)}{g&#39;(a)}
=\lim_{x\rightarrow a}\frac{f&#39;(x)}{g&#39;(x)}.\]</span></p>
<p>We can apply L’Hôpital’s rule to calculate the two important trigonometric limits from earlier.<br />
Eg. Calculate <span class="math inline">\(\lim_{x\rightarrow 0}\frac{\sin x}{x}.\)</span></p>
<p><span class="math inline">\(f(x)=\sin x\)</span> and <span class="math inline">\(g(x)=x\)</span> are both differentiable. Also <span class="math inline">\(\lim_{x\rightarrow 0}{\sin x}=\sin 0=0\)</span> and <span class="math inline">\(\lim_{x\rightarrow 0}{x}=0.\)</span> Furthermore, <span class="math inline">\(f&#39;(x)=\cos x\)</span> and <span class="math inline">\(g&#39;(x)=1\ne 0.\)</span> Thus L’Hôpital’s rule applies to give <span class="math display">\[\lim_{x\rightarrow 0}\frac{\sin x}{x}=
\lim_{x\rightarrow 0}\frac{\cos x}{1}={\cos 0}=1.\]</span><br />
Eg. Calculate <span class="math inline">\(\lim_{x\rightarrow 0}\frac{1-\cos x}{x}.\)</span></p>
<p><span class="math inline">\(f(x)=1-\cos x\)</span> and <span class="math inline">\(g(x)=x\)</span> are both differentiable. Also <span class="math inline">\(\lim_{x\rightarrow 0}(1-\cos x)=1-\cos 0=0\)</span> and <span class="math inline">\(\lim_{x\rightarrow 0}{x}=0.\)</span> Furthermore, <span class="math inline">\(f&#39;(x)=\sin x\)</span> and <span class="math inline">\(g&#39;(x)=1\ne 0.\)</span> Thus by L’Hôpital’s rule <span class="math display">\[\lim_{x\rightarrow 0}\frac{1-\cos x}{x}=
\lim_{x\rightarrow 0}\frac{\sin x}{1}={\sin 0}=0.\]</span><br />
If applying L’Hôpital’s rule yields another indeterminant form then L’Hôpital’s rule can be reapplied to this form and so on.<br />
Eg. Calculate <span class="math inline">\(\lim_{x\rightarrow 0}\frac{2\sin x-\sin(2x)}{x-\sin x}.\)</span></p>
<p><span class="math display">\[\lim_{x\rightarrow 0}\frac{2\sin x-\sin(2x)}{x-\sin x}
=\lim_{x\rightarrow 0}\frac{2\cos x-2\cos(2x)}{1-\cos x}
=\lim_{x\rightarrow 0}\frac{-2\sin x+4\sin(2x)}{\sin x}\]</span> <span class="math display">\[=\lim_{x\rightarrow 0}\frac{-2\cos x+8\cos(2x)}{\cos x}
=\frac{-2+8}{1}=6.\]</span></p>
</section>
<section id="boundedness-and-monotonicity" class="level2" data-number="3.4">
<h2 data-number="3.4"><span class="header-section-number">3.4</span> Boundedness and monotonicity</h2>
<p>The following definitions apply to a function <span class="math inline">\(f(x)\)</span> defined in some interval <span class="math inline">\(I.\)</span><br />
<span><strong>Defn:</strong></span> If <span class="math inline">\(\exists\)</span> a constant <span class="math inline">\(k_1\)</span> s.t. <span class="math inline">\(f(x)\le k_1\)</span>  <span class="math inline">\(\forall\)</span>  <span class="math inline">\(x\)</span> in <span class="math inline">\(I\)</span> we say that <span class="math inline">\(f(x)\)</span> is <span><strong>bounded above in <span class="math inline">\(I\)</span></strong></span> and we call <span class="math inline">\(k_1\)</span> an <span><strong>upper bound</strong></span> of <span class="math inline">\(f(x)\)</span> in <span class="math inline">\(I.\)</span><br />
Furthermore, if <span class="math inline">\(\exists\)</span> a point <span class="math inline">\(x_1\)</span> in <span class="math inline">\(I\)</span> s.t. <span class="math inline">\(f(x_1)=k_1\)</span> we say that the upper bound <span class="math inline">\(k_1\)</span> is <span><strong>attained</strong></span> and we call <span class="math inline">\(k_1\)</span> the <span><strong>global maximum value</strong></span> of <span class="math inline">\(f(x)\)</span> in <span class="math inline">\(I.\)</span><br />
Similarly, we have the following:<br />
<span><strong>Defn:</strong></span> If <span class="math inline">\(\exists\)</span> a constant <span class="math inline">\(k_2\)</span> s.t. <span class="math inline">\(f(x)\ge k_2\)</span>  <span class="math inline">\(\forall\)</span>  <span class="math inline">\(x\)</span> in <span class="math inline">\(I\)</span> we say that <span class="math inline">\(f(x)\)</span> is <span><strong>bounded below in <span class="math inline">\(I\)</span></strong></span> and we call <span class="math inline">\(k_2\)</span> a <span><strong>lower bound</strong></span> of <span class="math inline">\(f(x)\)</span> in <span class="math inline">\(I.\)</span><br />
Furthermore, if <span class="math inline">\(\exists\)</span> a point <span class="math inline">\(x_2\)</span> in <span class="math inline">\(I\)</span> s.t. <span class="math inline">\(f(x_2)=k_2\)</span> we say that the lower bound <span class="math inline">\(k_2\)</span> is <span><strong>attained</strong></span> and we call <span class="math inline">\(k_2\)</span> the <span><strong>global minimum value</strong></span> of <span class="math inline">\(f(x)\)</span> in <span class="math inline">\(I.\)</span><br />
<span><strong>Defn:</strong></span> <span class="math inline">\(f(x)\)</span> is <span><strong>bounded in <span class="math inline">\(I\)</span></strong></span> if it is both bounded above and bounded below in <span class="math inline">\(I\)</span> ie. if <span class="math inline">\(\exists\)</span> a constant <span class="math inline">\(k\)</span> s.t. <span class="math inline">\(|f(x)|\le k\)</span>  <span class="math inline">\(\forall\)</span>  <span class="math inline">\(x\)</span> in <span class="math inline">\(I.\)</span><br />
If no interval <span class="math inline">\(I\)</span> is specified then it is taken to be the domain of the function.</p>
<p> </p>
<p>Eg. <span class="math inline">\(\cos x\)</span> is bounded (in <span class="math inline">\(\mathbb{R}\)</span>) because <span class="math inline">\(|\cos x|\le 1\)</span> <span class="math inline">\(\forall
x\in\mathbb{R}.\)</span> Both these upper and lower bounds are attained as <span class="math inline">\(\cos 0=1\)</span> and <span class="math inline">\(\cos \pi=-1.\)</span> The global maximum value in <span class="math inline">\(\mathbb{R}\)</span> is <span class="math inline">\(1\)</span> and the global minimum value in <span class="math inline">\(\mathbb{R}\)</span> is <span class="math inline">\(-1\)</span>.<br />
Eg. Consider <span class="math inline">\(f(x)=\frac{\mbox{sgn}(x) }{1+x^2}\)</span> for <span class="math inline">\(-1\le x\le 1.\)</span> Then <span class="math inline">\(f(x)\)</span> is bounded in <span class="math inline">\([-1,1]\)</span> because <span class="math inline">\(|f(x)|\le 1\)</span> for all <span class="math inline">\(x\)</span> in <span class="math inline">\([-1,1]\)</span> but neither of the bounds is attained, so it has no global maximum value and no global minimum value in <span class="math inline">\([-1,1].\)</span><br />
Eg. On <span class="math inline">\([0,\pi/2)\)</span> the function <span class="math inline">\(\tan x\)</span> is bounded below but not bounded above.<br />
A condition that guarantees the existence of both a global maximum and minimum value (called <span><strong>extreme values</strong></span>) is provided by the following:<br />
<span><strong>The extreme value theorem</strong></span> states that if <span class="math inline">\(f\)</span> is a continuous function on a <span><em>closed</em></span> interval <span class="math inline">\([a,b]\)</span> then it is bounded on that interval and has upper and lower bounds that are attained ie. <span class="math inline">\(\exists\)</span> points <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> in <span class="math inline">\([a,b]\)</span> such that <span class="math inline">\(f(x_2)\le f(x)\le f(x_1) \ \forall \ x\in[a,b].\)</span><br />
<span><strong>Defn:</strong></span> <span class="math inline">\(f(x)\)</span> is <span><strong>monotonic increasing</strong></span> in <span class="math inline">\([a,b]\)</span> if <span class="math inline">\(f(x_1)\le f(x_2)\)</span> for all pairs <span class="math inline">\(x_1,x_2\)</span> with <span class="math inline">\(a\le x_1&lt;x_2\le b.\)</span><br />
<span><strong>Defn:</strong></span> <span class="math inline">\(f(x)\)</span> is <span><strong>strictly monotonic increasing</strong></span> in <span class="math inline">\([a,b]\)</span> if <span class="math inline">\(f(x_1)&lt; f(x_2)\)</span> for all pairs <span class="math inline">\(x_1,x_2\)</span> with <span class="math inline">\(a\le x_1&lt;x_2\le b.\)</span><br />
Obvious definitions apply with increasing replaced by decreasing.<br />
Eg. <span class="math inline">\(\mbox{sgn}(x)\)</span> is monotonic increasing in <span class="math inline">\([-1,1]\)</span> but not strictly.<br />
Eg. <span class="math inline">\(x^2\)</span> is strictly monotonic increasing in <span class="math inline">\([0,b]\)</span> for any <span class="math inline">\(b&gt;0.\)</span><br />
</p>
</section>
<section id="critical-points" class="level2" data-number="3.5">
<h2 data-number="3.5"><span class="header-section-number">3.5</span> Critical points</h2>
<p><span><strong>Defn:</strong></span> We say that <span class="math inline">\(f(x)\)</span> has a <span><strong>local maximum</strong></span> at <span class="math inline">\(x=a\)</span> if  <span class="math inline">\(\exists \ h&gt;0\)</span> s.t. <span class="math inline">\(f(a)\ge f(x) \ \ \forall \ x\in(a-h,a+h).\)</span><br />
Remark: If <span class="math inline">\(f(x)\)</span> has a local maximum at <span class="math inline">\(x=a\)</span> and is differentiable at this point then <span class="math inline">\(f&#39;(a)=0.\)</span><br />
Proof: As <span class="math inline">\(f(x)\)</span> is differentiable at <span class="math inline">\(a\)</span> then <span class="math display">\[\lim_{x\rightarrow a^-}\frac{f(x)-f(a)}{x-a}
=\lim_{x\rightarrow a^+}
\frac{f(x)-f(a)}{x-a}
=f&#39;(a).\]</span> <span class="math inline">\(f(x)\)</span> has a local maximum at <span class="math inline">\(a\)</span> implies <span class="math display">\[\frac{f(x)-f(a)}{x-a}\ge 0 \quad \mbox{for} \ x\in(a-h,a)\]</span> <span class="math display">\[\mbox{hence \ }
f&#39;(a)=\lim_{x\rightarrow a^-}\frac{f(x)-f(a)}{x-a}\ge 0.\]</span> Similarly, <span class="math inline">\(f(x)\)</span> has a local maximum at <span class="math inline">\(a\)</span> also implies <span class="math display">\[\frac{f(x)-f(a)}{x-a}\le 0 \quad \mbox{for} \ x\in(a,a+h)\]</span> <span class="math display">\[\mbox{hence \ }
f&#39;(a)=\lim_{x\rightarrow a^+}\frac{f(x)-f(a)}{x-a}\le 0.\]</span> Putting these two together gives <span class="math inline">\(f&#39;(a)\le 0\le f&#39;(a)\)</span> and thus <span class="math inline">\(f&#39;(a)=0.\)</span><br />
<span><strong>Defn:</strong></span> We say that <span class="math inline">\(f(x)\)</span> has a <span><strong>local minimum</strong></span> at <span class="math inline">\(x=a\)</span> if  <span class="math inline">\(\exists \ h&gt;0\)</span> s.t. <span class="math inline">\(f(x)\ge f(a) \ \ \forall \ x\in(a-h,a+h).\)</span><br />
Remark: If <span class="math inline">\(f(x)\)</span> has a local minimum at <span class="math inline">\(x=a\)</span> and is differentiable at this point then <span class="math inline">\(f&#39;(a)=0.\)</span><br />
<span><strong>Defn:</strong></span> <span class="math inline">\(f(x)\)</span> has a <span><strong>stationary point</strong></span> at <span class="math inline">\(x=a\)</span> if it is differentiable at <span class="math inline">\(x=a\)</span> with <span class="math inline">\(f&#39;(a)=0.\)</span><br />
<span><strong>Defn:</strong></span> An interior point <span class="math inline">\(x=a\)</span> of the domain of <span class="math inline">\(f(x)\)</span> is called a <span><strong>critical point</strong></span> if either <span class="math inline">\(f&#39;(a)=0\)</span> or <span class="math inline">\(f&#39;(a)\)</span> does not exist.<br />
Every local maximum and local minimum of a differentiable function is a stationary point but there may be other stationary points too.<br />
Eg. <span class="math inline">\(f(x)=x^3\)</span> has <span class="math inline">\(f&#39;(0)=0\)</span> so <span class="math inline">\(x=0\)</span> is a stationary point but it is neither a local maximum nor a local minimum because <span class="math inline">\(f(x)&gt;f(0)\)</span> for <span class="math inline">\(x\in(0,h)\)</span> but <span class="math inline">\(f(x)&lt;f(0)\)</span> for <span class="math inline">\(x\in(-h,0).\)</span><br />
<span><strong>Defn:</strong></span> If <span class="math inline">\(f(x)\)</span> is twice differentiable in an open interval around <span class="math inline">\(x=a\)</span> with <span class="math inline">\(f&#39;&#39;(a)=0\)</span> and if <span class="math inline">\(f&#39;&#39;(x)\)</span> changes sign at <span class="math inline">\(x=a\)</span> then we say that <span class="math inline">\(x=a\)</span> is a <span><strong>point of inflection.</strong></span><br />
</p>
<figure>
<img src="new_inflection.png" style="width:5cm" alt="" /><figcaption>The graph of <span class="math inline">\(f(x)=x^3\)</span> indicating the point of inflection at <span class="math inline">\(x=0.\)</span></figcaption>
</figure>
<p>Eg. <span class="math inline">\(f(x)=x^3\)</span> has <span class="math inline">\(f&#39;&#39;(x)=6x\)</span> so <span class="math inline">\(f&#39;&#39;(0)=0.\)</span> As <span class="math inline">\(f&#39;&#39;(x)&lt;0\)</span> for <span class="math inline">\(x&lt;0\)</span> and <span class="math inline">\(f&#39;&#39;(x)&gt;0\)</span> for <span class="math inline">\(x&gt;0\)</span> then <span class="math inline">\(f&#39;&#39;(x)\)</span> changes sign at <span class="math inline">\(x=0\)</span> so it is a point of inflection.<br />
<span><strong>The first derivative test</strong></span></p>
<p>Suppose <span class="math inline">\(f(x)\)</span> is continuous at a critical point <span class="math inline">\(x=a.\)</span><br />
(i). If <span class="math inline">\(\exists\ h&gt;0\)</span> s.t. <span class="math inline">\(f&#39;(x)&lt;0 \ \forall \ x\in(a-h,a)\)</span> and <span class="math inline">\(f&#39;(x)&gt;0 \ \forall \ x\in(a,a+h)\)</span> then <span class="math inline">\(x=a\)</span> is a local minimum.<br />
(ii). If <span class="math inline">\(\exists\ h&gt;0\)</span> s.t. <span class="math inline">\(f&#39;(x)&gt;0 \ \forall \ x\in(a-h,a)\)</span> and <span class="math inline">\(f&#39;(x)&lt;0 \ \forall \ x\in(a,a+h)\)</span> then <span class="math inline">\(x=a\)</span> is a local maximum.<br />
(iii). If <span class="math inline">\(\exists\ h&gt;0\)</span> s.t. <span class="math inline">\(f&#39;(x)\)</span> has a constant sign  <span class="math inline">\(\forall \ x\ne a\)</span> in <span class="math inline">\((a-h,a+h)\)</span> then <span class="math inline">\(x=a\)</span> is a not a local extreme value (minimum/maximum).<br />
Eg. <span class="math inline">\(f(x)=|x|\)</span> is continuous but <span class="math inline">\(f&#39;(x)\ne 0\)</span> so there are no stationary points. The derivative does not exist at <span class="math inline">\(x=0\)</span> so this is a critical point. <span class="math inline">\(f&#39;(x)&lt;0\)</span> for <span class="math inline">\(x\in (-1,0)\)</span> and <span class="math inline">\(f&#39;(x)&gt;0\)</span> for <span class="math inline">\(x\in (0,1)\)</span> so by the first derivative test <span class="math inline">\(x=0\)</span> is a local minimum. In fact <span class="math inline">\(f(0)=0\)</span> is a global minimum as <span class="math inline">\(|x|\ge 0.\)</span><br />
Eg. <span class="math inline">\(f(x)=x^4-2x^3\)</span> has <span class="math inline">\(f&#39;(x)=4x^3-6x^2=2x^2(2x-3).\)</span> The only critical points are <span class="math inline">\(x=0,3/2.\)</span> Now <span class="math inline">\(f&#39;(x)&lt;0\)</span> for <span class="math inline">\(x&lt;3/2\)</span> and <span class="math inline">\(f&#39;(x)&gt;0\)</span> for <span class="math inline">\(x&gt;3/2.\)</span> Thus <span class="math inline">\(f&#39;(x)\)</span> has constant sign on both (sufficiently close) sides of <span class="math inline">\(x=0\)</span> so this is not a local extreme value. However, <span class="math inline">\(f&#39;(x)\)</span> changes sign from negative to positive as <span class="math inline">\(x\)</span> passes through <span class="math inline">\(x=3/2\)</span> so this is a local minimum.<br />
<span><strong>The second derivative test</strong></span></p>
<p>Suppose <span class="math inline">\(f(x)\)</span> is twice differentiable at <span class="math inline">\(x=a\)</span> with <span class="math inline">\(f&#39;(a)=0.\)</span></p>
<p>(i).  If <span class="math inline">\(f&#39;&#39;(a)&gt;0\)</span> then <span class="math inline">\(x=a\)</span> is a local minimum.</p>
<p>(ii). If <span class="math inline">\(f&#39;&#39;(a)&lt;0\)</span> then <span class="math inline">\(x=a\)</span> is a local maximum.<br />
Note that the theorem doesn’t say anything about the case <span class="math inline">\(f&#39;&#39;(a)=0.\)</span><br />
Eg. <span class="math inline">\(f(x)=2x^3-9x^2+12x\)</span> has <span class="math inline">\(f&#39;(x)=6x^2-18x+12=6(x^2-3x+2)=6(x-1)(x-2)\)</span> giving stationary points at <span class="math inline">\(x=1\)</span> and <span class="math inline">\(x=2.\)</span> Furthermore, <span class="math inline">\(f&#39;&#39;(x)=6(2x-3)\)</span> giving <span class="math inline">\(f&#39;&#39;(1)=-6&lt;0\)</span> and <span class="math inline">\(f&#39;&#39;(2)=6&gt;0\)</span> so by the second derivative test <span class="math inline">\(x=1\)</span> is a local maximum and <span class="math inline">\(x=2\)</span> is a local minimum.<br />
Note that the first derivative test is more general than the second derivative test as it does not require the function to be differentiable at the critical point.<br />
Determining all critical points and asymptotes is the key to sketching the graph of a function. Eg. Sketch the graph of the function <span class="math inline">\(f(x)=\frac{4x-5}{x^2-1}.\)</span></p>
<figure>
<img src="new_sketch.png" style="width:6cm" alt="" /><figcaption>Graph of <span class="math inline">\(f(x)=\frac{4x-5}{x^2-1}.\)</span></figcaption>
</figure>
<p><span class="math inline">\(y=0\)</span> is a horizontal asymptote along both the positive and negative <span class="math inline">\(x\)</span>-axis because <span class="math display">\[\lim_{x\rightarrow\pm \infty}
\frac{4x-5}{x^2-1}=
\lim_{x\rightarrow\pm \infty}
\frac{1}{x}\bigg(\frac{4-5/x}{1-\frac{1}{x^2}}\bigg)=
0\bigg(\frac{4-0}{1-0^2}\bigg)=0\]</span> There are vertical asymptotes at <span class="math inline">\(x=\pm 1.\)</span> Also <span class="math display">\[f&#39;(x)=\frac{4(x^2-1)-2x(4x-5)}{(x^2-1)^2}
=\frac{-4x^2+10x-4}{(x^2-1)^2}
=\frac{-(4x-2)(x-2)}{(x^2-1)^2}\]</span> so there are stationary points at <span class="math inline">\(x=\frac{1}{2},2\)</span> with <span class="math inline">\(f(\frac{1}{2})=4\)</span> and <span class="math inline">\(f(2)=1.\)</span></p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(x\)</span></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">-1</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"><span class="math inline">\(\frac{1}{2}\)</span></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">1</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">2</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(f&#39;\)</span></td>
<td style="text-align: center;"><span class="math inline">\(-\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><span class="math inline">\(-\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">+</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">+</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><span class="math inline">\(-\)</span></td>
</tr>
</tbody>
</table>
<p>As <span class="math inline">\(x\)</span> passes through <span class="math inline">\(\frac{1}{2}\)</span> then <span class="math inline">\(f&#39;(x)\)</span> changes sign from negative to positive so this is a local minimum. As <span class="math inline">\(x\)</span> passes through <span class="math inline">\(2\)</span> then <span class="math inline">\(f&#39;(x)\)</span> changes sign from positive to negative so this is a local maximum.</p>
<p> </p>
<p>If a function is defined on an interval then extreme values can occur at the endpoints of the interval. Here an <span><strong>endpoint</strong></span> <span class="math inline">\(x=c\)</span> is a point at which the function is defined but where the function is undefined either to the left or right of this point. For example, if the domain of a function is <span class="math inline">\([a,b]\)</span> then <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are both endpoints.<br />
<span><strong>Defn:</strong></span> If <span class="math inline">\(c\)</span> is an endpoint of <span class="math inline">\(f(x)\)</span> then <span class="math inline">\(f\)</span> has an <span><strong>endpoint maximum</strong></span> at <span class="math inline">\(x=c\)</span> if <span class="math inline">\(f(x)\le f(c)\)</span> for <span class="math inline">\(x\)</span> sufficiently close to <span class="math inline">\(c.\)</span><br />
The obvious similar definition applies for an <span><strong>endpoint minimum</strong></span>.<br />
If a function is differentiable sufficiently close to an endpoint then examining the sign of the derivative can determine if there is an endpoint maximum or minimum.<br />
If <span class="math inline">\(f(x)\)</span> is continuous on an interval <span class="math inline">\([a,b]\)</span> then the global extreme values in this interval are attained at either critical points or endpoints, so we can determine them by examining all the possibilities.<br />
Eg. Find the global extreme values of <span class="math inline">\(f(x)=1+4x^2-\frac{1}{2}x^4\)</span> for <span class="math inline">\(x\in[-1,3].\)</span></p>
<figure>
<img src="new_extreme1.png" style="width:4cm" alt="" /><figcaption>Graph of <span class="math inline">\(f(x)=1+4x^2-\frac{1}{2}x^4\)</span></figcaption>
</figure>
<p><span class="math inline">\(f&#39;(x)=8x-2x^3=2x(4-x^2)\)</span> which is zero at <span class="math inline">\(x=0,2\)</span>; recall we only consider <span class="math inline">\(x\in[-1,3].\)</span></p>
<p>Critical point:  <span class="math inline">\(f(0)=1\)</span> and <span class="math inline">\(f(2)=9\)</span></p>
<p>End points:  <span class="math inline">\(f(-1)=\frac{9}{2}\)</span> and <span class="math inline">\(f(3)=-\frac{7}{2}.\)</span></p>
<p>The smallest of these four values is <span class="math inline">\(-\frac{7}{2},\)</span> which is the global minimum, whereas the largest is <span class="math inline">\(9\)</span> which is the global maximum.<br />
Eg. Find the global extreme values of <span class="math inline">\(x^2-2|x|+2\)</span> for <span class="math inline">\(x\in[-\frac{1}{2},2].\)</span></p>
<p>First of all we can write <span class="math display">\[f(x)=\begin{cases}
x^2+2x+2 &amp; \text{if \ } -\frac{1}{2}\le x&lt;0\\
x^2-2x+2 &amp; \text{if \ } \ \ \ \ 0 \le x\le 2
\end{cases}\]</span> <span class="math inline">\(f&#39;(x)=2x+2\)</span> for <span class="math inline">\(x\in[-\frac{1}{2},0)\)</span> so no critical points here.</p>
<p><span class="math inline">\(f&#39;(x)=2x-2\)</span> for <span class="math inline">\(x\in(0,2]\)</span> so a critical point at <span class="math inline">\(x=1\)</span> with <span class="math inline">\(f(1)=1.\)</span></p>
<p><span class="math inline">\(\lim_{x\rightarrow 0^+}f&#39;(x)=-2
\ne 2 =\lim_{x\rightarrow 0^-}f&#39;(x)\)</span> hence <span class="math inline">\(f&#39;(x)\)</span> does not exist at <span class="math inline">\(x=0,\)</span> making this a critical point with <span class="math inline">\(f(0)=2.\)</span></p>
<p>Endpoints: <span class="math inline">\(f(-\frac{1}{2})=\frac{5}{4}\)</span> and <span class="math inline">\(f(2)=2.\)</span></p>
<p>Thus the global minimum is 1 and the global maximum is 2.<br />
</p>
<figure>
<img src="new_extreme2.png" id="fig-extreme2" style="width:5cm" alt="" /><figcaption>Graph of a piecewise function with two quadratic pieces.</figcaption>
</figure>
</section>
<section id="rolles-theorem" class="level2" data-number="3.6">
<h2 data-number="3.6"><span class="header-section-number">3.6</span> Rolle’s theorem</h2>
<p><span><strong>Rolle’s theorem</strong></span> states that if <span class="math inline">\(f\)</span> is differentiable on the open interval <span class="math inline">\((a,b)\)</span> and continuous on the closed interval <span class="math inline">\([a,b],\)</span> with <span class="math inline">\(f(a)=f(b),\)</span> then there is at least one <span class="math inline">\(c\in(a,b)\)</span> for which <span class="math inline">\(f&#39;(c)=0.\)</span><br />
Proof: By the extreme value theorem <span class="math inline">\(\exists\)</span>  <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> in <span class="math inline">\([a,b]\)</span> s.t.</p>
<p><span class="math inline">\(f(x_1)\le f(x)\le f(x_2) \ \forall \ x\in[a,b].\)</span></p>
<p>If <span class="math inline">\(x_1\in (a,b)\)</span> then <span class="math inline">\(x_1\)</span> is a local minimum and <span class="math inline">\(f&#39;(x_1)=0\)</span> so we are done.</p>
<p>If <span class="math inline">\(x_2\in (a,b)\)</span> then <span class="math inline">\(x_2\)</span> is a local maximum and <span class="math inline">\(f&#39;(x_2)=0\)</span> so we are done.</p>
<p>The only case that is left is if both <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are endpoints, <span class="math inline">\(a,b.\)</span> But since <span class="math inline">\(f(a)=f(b)\)</span> then in this case <span class="math inline">\(f(x_1)=f(x_2)=f(a)\)</span> so the above bound becomes <span class="math inline">\(f(a)\le f(x)\le f(a) \ \forall \ x\in[a,b].\)</span> Thus <span class="math inline">\(f(x)=f(a)\)</span> is constant in the interval and <span class="math inline">\(f&#39;(x)=0 \ 
\forall \ x\in[a,b].\)</span><br />
</p>
<figure>
<img src="new_rolles.png" style="width:6cm" alt="" /><figcaption>Illustration of Rolle’s theorem.</figcaption>
</figure>
<p>An obvious corollary of Rolle’s theorem is that if <span class="math inline">\(f(x)\)</span> is differentiable at every point of an open interval <span class="math inline">\(I\)</span> then each pair of zeros of the function in <span class="math inline">\(I\)</span> is separated by at least one zero of <span class="math inline">\(f&#39;(x).\)</span> This is simply the special case of Rolle’s theorem with <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> taken to be the the zeros of <span class="math inline">\(f(x)\)</span> so that <span class="math inline">\(f(a)=f(b)=0.\)</span><br />
An application of the above result is to provide a limit on the number of distinct real zeros of a function.<br />
Eg. Show that <span class="math inline">\(f(x)=\frac{1}{7}x^7-\frac{1}{5}x^6+x^3-3x^2-x\)</span> has no more than 3 distinct real roots.</p>
<p>Suppose the required result is false and there are (at least) 4 distinct real roots of <span class="math inline">\(f(x).\)</span> Then by Rolle’s theorem there are (at least) 3 distinct real roots of <span class="math inline">\(f&#39;(x).\)</span> Then by applying Rolle’s theorem to <span class="math inline">\(f&#39;(x)\)</span> there are (at least) 2 distinct real roots of <span class="math inline">\(f&#39;&#39;(x).\)</span> However, <span class="math inline">\(f&#39;&#39;(x)=6x^5-6x^4+6x-6=6(x-1)(x^4+1)\)</span> has only one real root (at <span class="math inline">\(x=1\)</span>). This contradiction proves the required result.<br />
</p>
</section>
<section id="the-mean-value-theorem" class="level2" data-number="3.7">
<h2 data-number="3.7"><span class="header-section-number">3.7</span> The mean value theorem</h2>
<p><span><strong>The mean value theorem</strong></span> states that if <span class="math inline">\(f\)</span> is differentiable on the open interval <span class="math inline">\((a,b)\)</span> and continuous on the closed interval <span class="math inline">\([a,b],\)</span> then there is at least one <span class="math inline">\(c\in(a,b)\)</span> for which <span class="math display">\[f&#39;(c)=\frac{f(b)-f(a)}{b-a}.\]</span></p>
<figure>
<img src="new_mvt.png" style="width:4.6cm" alt="" /><figcaption>Illustration of the mean value theorem.</figcaption>
</figure>
<p> </p>
<p>Geometrically this theorem states that there is at least one point in the interval at which the tangent to the curve is parallel to the line joining the two points <span class="math inline">\((b,f(b))\)</span> and <span class="math inline">\((a,f(a))\)</span> at the ends of the interval. The geometry makes the result clear but here is the proof.</p>
<p>Proof: Define the function <span class="math display">\[g(x)=(b-a)(f(x)-f(a))-(x-a)(f(b)-f(a)).\]</span> Then <span class="math inline">\(g(a)=g(b)=0\)</span> and as <span class="math inline">\(g(x)\)</span> satisfies the requirements of Rolle’s theorem then <span class="math inline">\(\exists \ c\in(a,b)\)</span> for which <span class="math inline">\(g&#39;(c)=0.\)</span> As <span class="math inline">\(g&#39;(x)=(b-a)f&#39;(x)-(f(b)-f(a))\)</span> then setting <span class="math inline">\(x=c\)</span> yields the required result <span class="math inline">\(f&#39;(c)=\frac{f(b)-f(a)}{b-a}.\)</span><br />
Note that Rolle’s theorem is just a special case of the mean value theorem with <span class="math inline">\(f(a)=f(b).\)</span><br />
The mean value theorem can be used to prove some obvious results relating monotonicity to the sign of the derivative. Here is an example:<br />
Suppose <span class="math inline">\(f(x)\)</span> is continuous in <span class="math inline">\([a,b]\)</span> and differentiable in <span class="math inline">\((a,b)\)</span> with <span class="math inline">\(f&#39;(x)\ge 0\)</span> throughout this interval. Then <span class="math inline">\(f(x)\)</span> is monotonic increasing in <span class="math inline">\((a,b).\)</span></p>
<p>Proof: If <span class="math inline">\(a\le x_1&lt;x_2\le b\)</span> then by the mean value theorem <span class="math inline">\(\exists \ 
c\in(a,b)\)</span> s.t. <span class="math inline">\(f&#39;(c)=\frac{f(x_2)-f(x_1)}{x_2-x_1}.\)</span> However, since <span class="math inline">\(f&#39;(x)\ge 0\)</span> in <span class="math inline">\((a,b)\)</span> then <span class="math inline">\(f&#39;(c)\ge 0\)</span> which imples that <span class="math inline">\(f(x_2)\ge f(x_1)\)</span> ie. <span class="math inline">\(f\)</span> is monotonic increasing.<br />
Similar obvious results and proofs follow for the cases of monotonic decreasing and strictly monotonic increasing/decreasing.<br />
</p>
</section>
<section id="the-inverse-function-rule" class="level2" data-number="3.8">
<h2 data-number="3.8"><span class="header-section-number">3.8</span> The inverse function rule</h2>
<p>The derivative of the inverse of a function can be obtained from the following:<br />
<span><strong>The inverse function rule</strong></span> states that if <span class="math inline">\(f(x)\)</span> is continuous in <span class="math inline">\([a,b]\)</span> and differentiable in <span class="math inline">\((a,b)\)</span> with <span class="math inline">\(f&#39;(x)&gt;0\)</span> throughout this interval then its inverse function <span class="math inline">\(g(y)\)</span> (recall <span class="math inline">\(g(f(x))=x\)</span>) is differentiable for all <span class="math inline">\(f(a)&lt;y&lt;f(b)\)</span> with <span class="math inline">\(g&#39;(y)=1/f&#39;(g(y)).\)</span><br />
Note: A similar theorem exists for the case <span class="math inline">\(f&#39;(x)&lt;0.\)</span><br />
Eg. <span class="math inline">\(f(x)=\sin x\)</span> has <span class="math inline">\(f&#39;(x)=\cos x&gt;0\)</span> for <span class="math inline">\(x\in(-\pi/2,\pi/2).\)</span></p>
<p>Its inverse function <span class="math inline">\(g(y)=\sin^{-1}y\)</span> is therefore differentiable in <span class="math inline">\((-1,1)\)</span> with <span class="math display">\[g&#39;(y)=\frac{1}{f&#39;(g(y))}=\frac{1}{\cos g(y)}
=\frac{1}{\sqrt{1-\sin^2g(y)}}\]</span> but <span class="math inline">\(y=f(g(y))=\sin(g(y))\)</span> hence <span class="math inline">\(g&#39;(y)=\frac{1}{\sqrt{1-y^2}}.\)</span> Thus we have shown that <span class="math display">\[\frac{d}{dx}\sin^{-1}x=\frac{1}{\sqrt{1-x^2}}.\]</span></p>
<p> </p>
<p>Eg. <span class="math inline">\(f(x)=\tan x\)</span> has <span class="math inline">\(f&#39;(x)=\sec^2x&gt;0\)</span> for <span class="math inline">\(x\in(-\pi/2,\pi/2).\)</span></p>
<p>With this domain then <span class="math inline">\(\mbox{Ran\,}f=\mathbb{R}\)</span> hence the domain of the inverse function <span class="math inline">\(g(y)=\tan^{-1}(y)\)</span> is <span class="math inline">\(\mathbb{R}.\)</span></p>
<p>By the inverse function rule <span class="math display">\[g&#39;(y)=\frac{1}{f&#39;(g(y))}=\frac{1}{\sec^2(g(y))}
=\frac{1}{1+\tan^2(g(y))}=\frac{1}{1+y^2}\]</span> where we have used <span class="math inline">\(y=f(g(y))=\tan(g(y)).\)</span></p>
<p>Thus we have shown that <span class="math display">\[\frac{d}{dx}\tan^{-1}x=\frac{1}{1+x^2}.\]</span></p>
</section>
<section id="partial-derivatives" class="level2" data-number="3.9">
<h2 data-number="3.9"><span class="header-section-number">3.9</span> Partial derivatives</h2>
<p>So far we have only considered functions of a single variable eg. <span class="math inline">\(f(x).\)</span> Later we shall study functions of two variables eg. <span class="math inline">\(f(x,y).\)</span> For this situation we shall need the concept of a <span><strong>partial derivative</strong></span>. The partial derivative of <span class="math inline">\(f\)</span> with respect to <span class="math inline">\(x\)</span> is written as <span class="math inline">\(\frac{\partial f}{\partial x}\)</span> and is obtained by differentiating <span class="math inline">\(f\)</span> with respect to <span class="math inline">\(x,\)</span> keeping <span class="math inline">\(y\)</span> fixed ie. <span class="math inline">\(y\)</span> may be treated as a constant in performing the partial differentiation with respect to <span class="math inline">\(x.\)</span> <span class="math display">\[\mbox{Eg.} \quad f(x,y)=x^2y^3-\sin x \cos y\,+y \quad \mbox{has}\quad \frac{\partial f}{\partial x}=2xy^3-\cos x\cos y.\]</span> Similarly, the partial derivative of <span class="math inline">\(f\)</span> with respect to <span class="math inline">\(y\)</span> is written as <span class="math inline">\(\frac{\partial f}{\partial y}\)</span> and is obtained by differentiating <span class="math inline">\(f\)</span> with respect to <span class="math inline">\(y,\)</span> keeping <span class="math inline">\(x\)</span> fixed. <span class="math display">\[\mbox{Eg.} \quad f(x,y)=x^2y^3-\sin x \cos y\,+y \quad \mbox{has}\quad 
\frac{\partial f}{\partial y}=3x^2y^2+\sin x\sin y\,+1.\]</span> Partial derivatives are defined in terms of the following limits (which we assume exist) <span class="math display">\[\frac{\partial f}{\partial x}(x,y)=\lim_{h\rightarrow 0}\frac{f(x+h,y)-f(x,y)}{h}, \quad
\frac{\partial f}{\partial y}(x,y)=\lim_{h\rightarrow 0}\frac{f(x,y+h)-f(x,y)}{h}. \quad\]</span> An alternative notation for partial derivatives is to write <span class="math inline">\(f_x\)</span> for <span class="math inline">\(\frac{\partial f}{\partial x}\)</span> etc.<br />
By applying partial differentiation to these partial derivatives we may obtain the second order partial derivatives <span class="math display">\[\frac{\partial^2 f}{\partial x^2}=\frac{\partial}{\partial x}\bigg(\frac{\partial f}{\partial x}\bigg),\quad
\frac{\partial^2 f}{\partial y^2}=\frac{\partial}{\partial y}\bigg(\frac{\partial f}{\partial y}\bigg),\quad
\frac{\partial^2 f}{\partial y\partial x}=\frac{\partial}{\partial y}\bigg(\frac{\partial f}{\partial x}\bigg),\quad
\frac{\partial^2 f}{\partial x\partial y}=\frac{\partial}{\partial x}\bigg(\frac{\partial f}{\partial y}\bigg).\]</span> For the earlier example <span class="math inline">\(f(x,y)=x^2y^3-\sin x \cos y\,+y\)</span> we obtain <span class="math display">\[\frac{\partial^2 f}{\partial x^2}=2y^3+\sin x\cos y, \quad
\frac{\partial^2 f}{\partial y^2}=6x^2y+\sin x\cos y, \quad\]</span> <span class="math display">\[\frac{\partial^2 f}{\partial y\partial x}=6xy^2+\cos x\sin y, \quad
\frac{\partial^2 f}{\partial x\partial y}=6xy^2+\cos x\sin y.\]</span> Note the equality, in this example, of the two mixed partial derivatives <span class="math display">\[\frac{\partial^2 f}{\partial x\partial y}
=\frac{\partial^2 f}{\partial y\partial x}.\]</span> It can be shown that this result is true in general, if <span class="math inline">\(f\)</span> and all first and second order partial derivatives are continuous.<br />
An alternative notation for partial derivatives is <span class="math display">\[\frac{\partial^2 f}{\partial x^2}=f_{xx}\]</span> etc</p>
</section>
<section id="summary-differentiation" class="level2" data-number="3.10">
<h2 data-number="3.10"><span class="header-section-number">3.10</span> Summary: Differentiation</h2>
<p>You should have a good understanding of the definition of the derivative, the general Leibnitz rule, L’Hôpital’s rule, local and global extreme values and how to find them, the Mean Value Theorem (MVT) and the equivalent Rolle’s theorem, the inverse function rule and partial derivatives. Here are some key points:</p>
<ul>
<li><p>The <span><em>derivative</em></span> of <span class="math inline">\(f(x)\)</span> at <span class="math inline">\(x=a\)</span> is (if it exists) <span class="math inline">\(f&#39;(a) = \lim_{h \to 0} \frac{f(a+h) - f(a)}{h}\)</span>.</p></li>
<li><p>The <span><em>Leibniz rule</em></span> is <span class="math inline">\((fg)&#39; = f&#39; g + f g&#39;\)</span> and extends in an obvious way to products of more than two functions, e.g. <span class="math inline">\((fgh)&#39; = f&#39; gh + f g&#39; h + fg h&#39;\)</span>.</p></li>
<li><p>The <span><em>general Leibniz rule</em></span> gives an efficient way to calculate higher order derivatives of a product of two functions, specifically <span class="math inline">\(D^n(fg) = \sum_{k=0}^n \left( \begin{array}{c} n \\ k \end{array} \right) (D^k f)(D^{n-k} g)\)</span>.</p></li>
<li><p>The <span><em>chain rule</em></span> tells us how to differentiate a function of a function, <span class="math inline">\((f \circ g)&#39;(x) = f&#39;(g(x)) g&#39;(x)\)</span>.</p></li>
<li><p>It may be possible to evaluate an indeterminate limit <span class="math inline">\(0/0\)</span> or <span class="math inline">\(\infty/\infty\)</span> by <span><em>L’Hôpital’s rule</em></span> <span class="math inline">\(\lim_{x \to a} f(x)/g(x) = \lim_{x \to a} f&#39;(x)/g&#39;(x)\)</span>.</p></li>
<li><p>The <span><em>extreme value theorem</em></span> states that continuous functions on closed intervals always attain upper and lower bounds (<span><em>global maxima and minima</em></span>).</p></li>
<li><p>A <span><em>monotonically increasing/decreasing</em></span> function <span class="math inline">\(f(x)\)</span> on an interval is a function which never decreases/increases as <span class="math inline">\(x\)</span> increases on that interval. <span><em>Strictly monotonic</em></span> excludes the possibility that the function may be constant on some subinterval.</p></li>
<li><p>A function <span class="math inline">\(f(x)\)</span> has a <span><em>local maximum/minimum</em></span> at <span class="math inline">\(x=a\)</span> if <span class="math inline">\(f(a)\)</span> is a global maximum/minimum on some open interval containing <span class="math inline">\(a\)</span>.</p></li>
<li><p>If <span class="math inline">\(f\)</span> is differentiable and has a local max/min at <span class="math inline">\(x=a\)</span> then it has a <span><em>stationary point</em></span> at <span class="math inline">\(x=a\)</span>, i.e. <span class="math inline">\(f&#39;(a) = 0\)</span>. You can test whether a stationary point is a local max or local min or neither with the <span><em>first derivative test</em></span>, or often with the <span><em>second derivative test</em></span>.</p></li>
<li><p>All <span><em>extreme values</em></span> (maxima and minima) of a function on an interval will be at <span><em>critical points</em></span> (stationary points or points where the function is not differentiable) or at the <span><em>endpoints</em></span> of the interval. If you are looking for the global extreme values, just evaluate the function at all those points – no need to identify whether each point is a local max or min.</p></li>
<li><p>If <span class="math inline">\(f\)</span> is continuous on <span class="math inline">\([a,b]\)</span> and differentiable on <span class="math inline">\((a,b)\)</span> then the <span><em>Mean Value Theorem (MVT)</em></span> says that <span class="math inline">\(\exists c \in (a,b)\)</span> s.t. <span class="math inline">\(f&#39;(c)\)</span> equals the gradient of the straight line from <span class="math inline">\((a, f(a))\)</span> to <span class="math inline">\((b, f(b))\)</span>. Rolle’s theorem is the MVT in the case where <span class="math inline">\(f(a) = f(b)\)</span> so <span class="math inline">\(f&#39;(c) = 0\)</span>.</p></li>
<li><p>If <span class="math inline">\(f\)</span> is continuous on <span class="math inline">\([a,b]\)</span> and differentiable on <span class="math inline">\((a,b)\)</span> with <span class="math inline">\(f&#39;(x) \ne 0\)</span> on <span class="math inline">\((a,b)\)</span> then the <span><em>inverse function rule</em></span> tells that the derivative of <span class="math inline">\(f^{-1}\)</span> exists on <span class="math inline">\((a,b)\)</span> and tells us how to relate it to the derivative of <span class="math inline">\(f\)</span>. Letting <span class="math inline">\(g = f^{-1}\)</span> we have <span class="math inline">\(g&#39;(x) = 1 / f&#39;(g(x))\)</span>.</p></li>
<li><p>If we have a function of more than one variable we can define <span><em>partial derivatives</em></span> with respect to one of the variables as the ordinary derivative when we treat all the other variables as constants. E.g. for <span class="math inline">\(f(x,y)\)</span> we have the partial derivative of <span class="math inline">\(f\)</span> wrt. <span class="math inline">\(x\)</span> at <span class="math inline">\((x,y)\)</span>: <span class="math inline">\(f_x = \frac{\partial f}{\partial x} = \lim_{h \to 0} \frac{f(x+h, y) - f(x,y)}{h}\)</span> etc.</p></li>
</ul>
</section>
</section>
<section id="integration" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Integration</h1>
<section id="indefinite-and-definite-integrals" class="level2" data-number="4.1">
<h2 data-number="4.1"><span class="header-section-number">4.1</span> Indefinite and definite integrals</h2>
<p><span><strong>Defn:</strong></span> A function <span class="math inline">\(F(x)\)</span> is called an <span><strong>indefinite integral</strong></span> or <span><strong>antiderivative</strong></span> of a function <span class="math inline">\(f(x)\)</span> in the interval <span class="math inline">\((a,b)\)</span> if <span class="math inline">\(F(x)\)</span> is differentiable with</p>
<p><span class="math inline">\(F&#39;(x)=f(x)\)</span> throughout <span class="math inline">\((a,b).\)</span> We then write <span class="math inline">\(F(x)=\int f(x)\, dx.\)</span><br />
Eg. <span class="math inline">\(\int \cos x\, dx=\sin x\)</span> in <span class="math inline">\(\mathbb{R}.\)</span><br />
Eg. <span class="math inline">\(\int \frac{1}{x^2}\, dx=-\frac{1}{x}\)</span> in <span class="math inline">\(\mathbb{R}\backslash\{0\}.\)</span><br />
Eg. <span class="math inline">\(\int \mbox{sgn} x\, dx=|x|\)</span> in <span class="math inline">\(\mathbb{R}\backslash\{0\}.\)</span><br />
Note1: If <span class="math inline">\(F(x)\)</span> is an <span> indefinite integral</span> of <span class="math inline">\(f(x)\)</span> in <span class="math inline">\((a,b)\)</span> then so is <span class="math inline">\(F(x)+c\)</span> for any constant <span class="math inline">\(c.\)</span> In applications of integration it is important to include this arbitrary constant. We therefore write eg. <span class="math inline">\(\int \cos x\, dx=\sin x+c.\)</span><br />
Note2: If <span class="math inline">\(F_1(x)\)</span> and <span class="math inline">\(F_2(x)\)</span> are both indefinite integrals of <span class="math inline">\(f(x)\)</span> in <span class="math inline">\((a,b)\)</span> then <span class="math inline">\(F_1(x)-F_2(x)=c\)</span> for some constant <span class="math inline">\(c.\)</span><br />
<span><strong>Defn:</strong></span> We say that <span class="math inline">\(f(x)\)</span> is <span><strong>integrable in <span class="math inline">\((a,b)\)</span></strong></span> if it has an indefinite integral <span class="math inline">\(F(x)\)</span> in <span class="math inline">\((a,b)\)</span> that is continuous in <span class="math inline">\([a,b].\)</span><br />
Eg. <span class="math inline">\(\cos x\)</span> is integrable in any finite interval <span class="math inline">\((a,b)\)</span> because <span class="math inline">\(\sin x\)</span> is continuous in <span class="math inline">\(\mathbb{R}.\)</span><br />
Eg. <span class="math inline">\(\frac{1}{x^2}\)</span> is not integrable in <span class="math inline">\((0,1)\)</span> because its indefinite integral <span class="math inline">\(-\frac{1}{x}\)</span> is not continuous at <span class="math inline">\(x=0.\)</span><br />
Eg. <span class="math inline">\(\mbox{sgn\,}x\)</span> is integrable in <span class="math inline">\((0,1)\)</span> because its indefinite integral <span class="math inline">\(|x|\)</span> is continuous in <span class="math inline">\([0,1].\)</span><br />
<span><strong>Defn:</strong></span> A <span><strong>subdivision</strong></span> <span class="math inline">\(S\)</span> of <span class="math inline">\([a,b]\)</span> is a partition into a finite number of subintervals <span class="math display">\[[a,x_1],[x_1,x_2],...,[x_{n-1},b]\]</span> where <span class="math inline">\(a=x_0&lt;x_1&lt;x_2&lt;...&lt;x_n=b.\)</span> The <span><strong>norm</strong></span> <span class="math inline">\(|S|\)</span> of the subdivision is the maximum of the subinterval lengths <span class="math inline">\(|a-x_1|,|x_1-x_2|,..,|x_{n-1}-b|.\)</span> (Thus a small value of <span class="math inline">\(|S|\)</span> means that the interval <span class="math inline">\([a,b]\)</span> has been chopped up into small pieces.) The numbers <span class="math inline">\(z_1,z_2,...,z_n\)</span> form a set of <span><strong>sample points</strong></span> from <span class="math inline">\(S\)</span> if <span class="math inline">\(z_j\in [x_{j-1},x_j]\)</span> for <span class="math inline">\(j=1,..,n.\)</span><br />
<span><strong>Defn:</strong></span> Suppose that <span class="math inline">\(f(x)\)</span> is a function defined for <span class="math inline">\(x\in[a,b].\)</span> The <span><strong>Riemann sum</strong></span> is <span class="math display">\[{\cal R}=\sum_{j=1}^n (x_j-x_{j-1})f(z_j).\]</span></p>
<figure>
<img src="riemann1.jpg" style="width:8cm" alt="" /><figcaption>An illustration of a Riemann sum.</figcaption>
</figure>
<p>The Riemann sum is equal to the sum of the (signed) areas of rectangles of height <span class="math inline">\(f(z_j)\)</span> and width <span class="math inline">\(x_j-x_{j-1}.\)</span> Here signed means that the areas of rectangles below the <span class="math inline">\(x\)</span>-axis are counted negatively. If <span class="math inline">\(f(x)\)</span> is continuous in <span class="math inline">\([a,b]\)</span> and <span class="math inline">\(|S|\)</span> is small then we expect <span class="math inline">\({\cal R}\)</span> to be a good approximation to the (signed) area under the graph of <span class="math inline">\(f(x)\)</span> above the interval <span class="math inline">\([a,b].\)</span> This turns out to be correct and the error in the approximation can be reduced to zero by taking the limit in which <span class="math inline">\(|S|\)</span> tends to zero. This leads to the definition of the <span><strong>definite integral</strong></span> as <span class="math display">\[\int_a^b f(x)\,dx=\lim_{|S|\rightarrow 0}{\cal R}\]</span> and it can be shown that this limit exists if <span class="math inline">\(f(x)\)</span> is continuous in <span class="math inline">\([a,b].\)</span></p>
<figure>
<img src="new_area.png" id="fig-area" style="width:6cm" alt="" /><figcaption>The definite integral is the signed area under the curve: <span class="math inline">\(\int_a^b f(x)\,dx=A_1-A_2+A_3.\)</span> </figcaption>
</figure>
<p>By definition we set <span class="math inline">\(\int_b^a f(x)\,dx=-\int_a^b f(x)\,dx\)</span> and therefore <span class="math inline">\(\int_a^a f(x)\,dx=0.\)</span></p>
<p>There are a number of fairly obvious properties of the definite integral that are not too hard to prove. In the following let <span class="math inline">\(f(x)\)</span> and <span class="math inline">\(g(x)\)</span> both be integrable in <span class="math inline">\((a,b).\)</span><br />
<span class="math inline">\((i)\)</span> <span>Linearity.</span> If <span class="math inline">\(\lambda,\mu\)</span> are any constants then <span class="math inline">\(\lambda f(x)+\mu g(x)\)</span> is integrable in <span class="math inline">\((a,b)\)</span> with <span class="math display">\[\int_a^b\bigg(
\lambda f(x)+\mu g(x)\bigg)\,dx=
\lambda \int_a^b f(x)\,dx+
\mu \int_a^b g(x)\,dx.\]</span></p>
<p> </p>
<p><span class="math inline">\((ii)\)</span> If <span class="math inline">\(c\in[a,b]\)</span> then <span class="math inline">\(\int_a^b f(x)\,dx
=
\int_a^c f(x)\,dx + \int_c^b f(x)\,dx.\)</span><br />
<span class="math inline">\((iii)\)</span> If <span class="math inline">\(f(x)\ge g(x) \ \forall \ x\in(a,b)\)</span> then <span class="math inline">\(\int_a^b f(x)\,dx\ge \int_a^b g(x)\,dx.\)</span><br />
<span class="math inline">\((iv)\)</span> If <span class="math inline">\(m\le f(x)\le M \ \forall \ x\in[a,b]\)</span> then <span class="math display">\[m(b-a)\le \int_a^b f(x)\,dx\le M(b-a).\]</span></p>
</section>
<section id="the-fundamental-theorem-of-calculus" class="level2" data-number="4.2">
<h2 data-number="4.2"><span class="header-section-number">4.2</span> The fundamental theorem of calculus</h2>
<p>So far, we don’t have any connection between indefinite and definite integrals. This is provided by the following theorem:<br />
<span><strong>The fundamental theorem of calculus</strong></span></p>
<p>If <span class="math inline">\(f(x)\)</span> is continuous on <span class="math inline">\([a,b]\)</span> then the function <span class="math display">\[F(x)=\int_a^x f(t)\,dt\]</span> defined for <span class="math inline">\(x\in[a,b]\)</span> is continuous on <span class="math inline">\([a,b]\)</span> and differentiable on <span class="math inline">\((a,b)\)</span> and is an indefinite integral of <span class="math inline">\(f(x)\)</span> on <span class="math inline">\((a,b)\)</span> ie. <span class="math display">\[F&#39;(x)=\frac{d}{dx}\int_a^x f(t)\,dt=f(x)\]</span> throughout <span class="math inline">\((a,b).\)</span> Furthermore if <span class="math inline">\(\widetilde F(x)\)</span> is any indefinite integral of <span class="math inline">\(f(x)\)</span> on <span class="math inline">\([a,b]\)</span> then <span class="math display">\[\int_a^b f(t)\,dt=\widetilde F(b)-\widetilde F(a)
=[\widetilde F(x)]^b_a.\]</span></p>
<p> <br />
We shall sketch the important points of the proof.</p>
<p>For <span class="math inline">\(a\le x&lt;x+h&lt;b\)</span> we have that <span class="math display">\[F(x+h)-F(x)=\int_a^{x+h} f(t)\,dt-\int_a^{x} f(t)\,dt
=\int_x^{x+h} f(t)\,dt\]</span> where we have used property <span class="math inline">\((ii).\)</span></p>
<p>Let <span class="math inline">\(m(h)\)</span> and <span class="math inline">\(M(h)\)</span> denote the minimum and maximum values of <span class="math inline">\(f(x)\)</span> on the interval <span class="math inline">\([x,x+h].\)</span> Then by property <span class="math inline">\((iv)\)</span> we have that <span class="math display">\[m(h)h\le \int_x^{x+h} f(t)\,dt\le M(h)h.\]</span> Thus <span class="math display">\[m(h)\le\frac{F(x+h)-F(x)}{h}\le M(h).\]</span> Since <span class="math inline">\(f(x)\)</span> is continuous on <span class="math inline">\([x,x+h]\)</span> we have that <span class="math inline">\(\lim_{h\rightarrow 0^+}m(h)=\lim_{h\rightarrow 0^+}M(h)=f(x)\)</span> and so by the pinching theorem <span class="math display">\[\lim_{h\rightarrow 0^+}\frac{F(x+h)-F(x)}{h}=f(x).\]</span> A similar argument applies to the limit from below and together they give <span class="math display">\[F&#39;(x)=\lim_{h\rightarrow 0}\frac{F(x+h)-F(x)}{h}=f(x)\]</span> which proves that <span class="math inline">\(F(x)\)</span> is an indefinite integral of <span class="math inline">\(f(x).\)</span> The proof of the first part of the theorem is completed by showing that <span class="math inline">\(F(x)\)</span> is continuous from the right at <span class="math inline">\(x=a\)</span> and from the left at <span class="math inline">\(x=b.\)</span> Both these follow by a simple consideration of the limit of the relevant quotient. Finally, to prove the last part of the theorem the key observation is that any indefinite integral <span class="math inline">\(\widetilde F(x)\)</span> is related to <span class="math inline">\(F(x)\)</span> by the addition of a constant.<br />
The fundamental theorem of calculus provides a simple rule for differentiating a definite integral with respect to its limits.</p>
<p><span class="math display">\[Eg. \quad \quad \frac{d}{dx}\int_0^x\frac{1}{1+\sin^2t}\,dt=
\frac{1}{1+\sin^2x}. \hskip 4cm\]</span></p>
<p> </p>
<p>We can combine this result with the chain rule if the limit is a more complicated expression <span class="math display">\[Eg. \quad \quad \frac{d}{dx}\int_0^{x^2}\frac{1}{1+e^t}\,dt=
\frac{1}{1+e^{x^2}}\bigg(\frac{d}{dx}x^2\bigg)
=\frac{2x}{1+e^{x^2}}. \hskip 4cm\]</span></p>
</section>
<section id="limits-with-logarithms-powers-and-exponentials" class="level2" data-number="4.3">
<h2 data-number="4.3"><span class="header-section-number">4.3</span> Limits with logarithms, powers and exponentials</h2>
<p>There are some important results concerning limits as <span class="math inline">\(x\rightarrow\infty\)</span> for the logarithm and exponential functions. To derive these results we begin with the following,<br />
<span><strong>Lemma 1</strong></span>: <span class="math inline">\(\forall\ x\ge 0, \quad e^{x}\ge 1+x\)</span></p>
<p>Proof: Consider <span class="math inline">\(f(x)=e^x-(1+x)\)</span> then <span class="math inline">\(f(0)=0\)</span> and <span class="math inline">\(f&#39;(x)=e^x-1\ge 0\)</span>.</p>
<p>Hence <span class="math inline">\(f(x)\)</span> is monotonic increasing in <span class="math inline">\([0,\infty)\)</span> so <span class="math inline">\(f(x)\ge 0\)</span> for all <span class="math inline">\(x\ge 0.\)</span><br />
<span><strong>Lemma 2</strong></span>: <span class="math inline">\(\forall\ x\ge 0, \mbox{ and for any positive integer } n, \quad e^{x}\ge \sum_{j=0}^n x^j/j!\)</span>.</p>
<p>Note that the case <span class="math inline">\(n=1\)</span> corresponds to Lemma 1, and the proof for general <span class="math inline">\(n\)</span> is similar to the proof of Lemma 1.<br />
<span><strong>Result 1: powers beat logs</strong></span></p>
<p>For any constant <span class="math inline">\(a&gt;0\)</span> <span class="math display">\[\lim_{x\rightarrow\infty}\frac{\log x}{x^a}=0.\]</span> This result is encapsulated by the phrase <span><em>powers beat logs.</em></span><br />
Proof: Put <span class="math inline">\(x=e^y\)</span> then <span class="math display">\[\lim_{x\to\infty}\frac{\log x}{x^a}=\lim_{y\to\infty}\frac{y}{e^{ay}}.\]</span> For <span class="math inline">\(y&gt;0\)</span> then by Lemma 2 with <span class="math inline">\(n=2\)</span> <span class="math display">\[0\le \frac{y}{e^{ay}}\le \frac{y}{1+ay+\frac{1}{2}a^2y^2}\le \frac{y}{\frac{1}{2}a^2y^2}=\frac{2}{a^2y}\]</span> As <span class="math inline">\(\lim_{y\to\infty}\frac{2}{a^2y}=0\)</span> then by the pinching theorem <span class="math display">\[\lim_{y\to\infty}\frac{y}{e^{ay}}=0=\lim_{x\to\infty}\frac{\log x}{x^a}.\]</span></p>
<p><span><strong>Result 2: exponentials beat powers</strong></span></p>
<p>For any constant <span class="math inline">\(a&gt;0\)</span> <span class="math display">\[\lim_{x\rightarrow\infty}\frac{x^a}{e^x}=0.\]</span> This result is encapsulated by the phrase <span><em>exponentials beat powers.</em></span><br />
Proof: Let <span class="math inline">\(n\)</span> be the smallest integer such that <span class="math inline">\(n&gt;a.\)</span> By Lemma 2, for <span class="math inline">\(x&gt;0\)</span> we have that <span class="math display">\[0\le \frac{x^a}{e^x}\le \frac{x^a}{1+x+\ldots +x^n/n!}
=\frac{x^{a-n}}{x^{-n}+x^{1-n}+\ldots 1/n!}\]</span> As <span class="math inline">\(a-n&lt;0\)</span> then <span class="math inline">\(\lim_{x\to\infty}\frac{x^{a-n}}{x^{-n}+x^{1-n}+\ldots 1/n!}=0\)</span>, hence by the pinching theorem <span class="math inline">\(\lim_{x\rightarrow\infty}\frac{x^a}{e^x}=0.\)</span><br />
<span><strong>Result 3: the exponential as a limit</strong></span></p>
<p>For any constant <span class="math inline">\(a\)</span> <span class="math display">\[\lim_{x\rightarrow\infty}\bigg(1+\frac{a}{x}\bigg)^x=e^a.\]</span> Proof (for the case <span class="math inline">\(a&gt;0\)</span>):</p>
<p>Recall the definition of the derivative of a function <span class="math inline">\(f(x)\)</span> at <span class="math inline">\(x=b.\)</span> <span class="math display">\[f&#39;(b)=\lim_{h\rightarrow 0}\frac{f(b+h)-f(b)}{h}.\]</span> Apply this to <span class="math inline">\(f(x)=\log x\)</span> so that <span class="math inline">\(f&#39;(x)=\frac{1}{x}\)</span> and take <span class="math inline">\(b=1.\)</span> <span class="math display">\[1=\lim_{h\rightarrow 0}\frac{\log(1+h)-\log(1)}{h}
=\lim_{h\rightarrow 0}\frac{\log(1+h)}{h}.\]</span> With the change of variable <span class="math inline">\(h=\frac{a}{x}\)</span> this becomes <span class="math display">\[1=\lim_{x\rightarrow \infty}\frac{\log(1+\frac{a}{x})}{\frac{a}{x}}
\quad \mbox{ie.} \quad
a=\lim_{x\rightarrow \infty}(x\log(1+\frac{a}{x})).\]</span> Since <span class="math inline">\(e^x\)</span> is continuous at <span class="math inline">\(a\)</span> we have that <span class="math display">\[e^a=\lim_{x\rightarrow \infty}\exp(x\log(1+\frac{a}{x}))
=\lim_{x\rightarrow \infty}\bigg(1+\frac{a}{x}\bigg)^x
.\]</span></p>
</section>
<section id="integration-using-a-recurrence-relation" class="level2" data-number="4.4">
<h2 data-number="4.4"><span class="header-section-number">4.4</span> Integration using a recurrence relation</h2>
<p>Eg. Calculate <span class="math inline">\(\int_0^1 x^3e^x\,dx.\)</span></p>
<p>Define <span class="math inline">\(I_n=\int_0^1 x^ne^x\,dx\)</span>  for all integer <span class="math inline">\(n\ge 0.\)</span> <span class="math display">\[I_{n+1}=\int_0^1 x^{n+1}e^x\,dx=\bigg[x^{n+1}e^x\bigg]_0^1-\int_0^1 (n+1)x^ne^x\,dx
 =e-(n+1)I_n.\]</span> The recurrence relation <span class="math inline">\(I_{n+1}=e-(n+1)I_n\)</span> can be used to calculate <span class="math inline">\(I_n\)</span> for any positive integer <span class="math inline">\(n\)</span> from the starting value <span class="math inline">\(I_0=\int_0^1 e^x\,dx=[e^x]_0^1=e-1.\)</span></p>
<p><span class="math inline">\(I_1=e-I_0=e-(e-1)=1, \quad
I_2=e-2I_1=e-2(1)=e-2, \quad\)</span></p>
<p><span class="math inline">\(I_3=e-3I_2=e-3(e-2)=6-2e \quad\)</span> is the required integral.<br />
 </p>
<p>Eg. Calculate <span class="math inline">\(\int \tan^4 x\,dx.\)</span></p>
<p>Define <span class="math inline">\(F_n(x)=\int \tan^n x\,dx\)</span>  for all integer <span class="math inline">\(n\ge 0.\)</span> <span class="math display">\[F_{n+2}(x)+F_n(x)=\int \tan^n x\,(1+\tan^2 x)\,dx
=\int \tan^n x\,\mbox{sec}^2x\,dx\]</span> Put <span class="math inline">\(u=\tan x\)</span> then <span class="math inline">\(du=\mbox{sec}^2x\,dx\)</span> <span class="math display">\[F_{n+2}(x)+F_n(x)=
\int u^n\,du=\frac{u^{n+1}}{n+1}=\frac{\tan^{n+1}x}{n+1}.\]</span> The recurrence relation <span class="math inline">\(F_{n+2}(x)=\frac{1}{n+1}\tan^{n+1}(x)-F_n(x)\)</span> can be used to calculate the required integral for <span class="math inline">\(n\)</span> even from the starting value <span class="math inline">\(F_0(x)=\int 1\,dx=x\)</span> and for <span class="math inline">\(n\)</span> odd from the starting value <span class="math inline">\(F_1(x)=-\log |\cos x|.\)</span></p>
<p>In particular, <span class="math inline">\(F_2(x)=\tan x\,-x\)</span> and <span class="math inline">\(F_4(x)=\frac{1}{3}\tan^3x-\tan x\,+x\)</span> thus</p>
<p><span class="math inline">\(\int \tan^4 x\,dx=\frac{1}{3}\tan^3x-\tan x\,+x\,+c.\)</span></p>
</section>
<section id="definite-integrals-using-even-and-odd-functions" class="level2" data-number="4.5">
<h2 data-number="4.5"><span class="header-section-number">4.5</span> Definite integrals using even and odd functions</h2>
<p>The definite integral of an odd function over a symmetric interval is zero.</p>
<p>If <span class="math inline">\(f_{odd}(x)\)</span> is an integrable odd function on <span class="math inline">\([-a,a]\)</span> then <span class="math display">\[\int_{-a}^a f_{odd}(x)\,dx=0.\]</span> Proof: <span class="math display">\[\int_{-a}^a f_{odd}(x)\,dx=
\int_{-a}^0 f_{odd}(u)\,du+\int_0^a f_{odd}(x)\,dx\]</span> <span class="math display">\[=-\int_{a}^0 f_{odd}(-x)\,dx+\int_0^a f_{odd}(x)\,dx
=\int_0^a (f_{odd}(-x)+f_{odd}(x))\,dx=0.\]</span></p>
<p> </p>
<p>A similarly argument shows that if <span class="math inline">\(f_{even}(x)\)</span> is an integrable even function on <span class="math inline">\([-a,a]\)</span> then <span class="math display">\[\int_{-a}^a f_{even}(x)\,dx=2\int_{0}^a f_{even}(x)\,dx.\]</span><br />
Recall that any function <span class="math inline">\(f(x)\)</span> can be decomposed as a sum of even and odd functions <span class="math inline">\(f(x)=f_{even}(x)+f_{odd}(x).\)</span> This can be a useful technique to calculate definite integrals over symmetric intervals as <span class="math display">\[\int_{-a}^a f(x)\,dx=
\int_{-a}^a f_{even}(x)+f_{odd}(x)\,\,dx=
2\int_{0}^a f_{even}(x)\,dx.\]</span>  </p>
<p>Eg. Calculate <span class="math inline">\(\int_{-1}^{1} \frac{e^xx^4}{\cosh x}\,dx.\)</span></p>
<p>For <span class="math inline">\(f(x)=\frac{e^xx^4}{\cosh x}\)</span> we have <span class="math inline">\(f_{even}(x)=\frac{1}{2}f(x)+\frac{1}{2}f(-x)
=\frac{1}{2}\frac{x^4(e^x+e^{-x})}{\cosh x}
=x^4.\)</span> Thus <span class="math display">\[\int_{-1}^{1} \frac{e^xx^4}{\cosh x}\,dx
=2\int_0^1 x^4=2\bigg[\frac{1}{5}x^5\bigg]_0^1=\frac{2}{5}.\]</span>  </p>
<p>Eg. Calculate <span class="math inline">\(\int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \frac{(1+2x)^3\cos x}{1+12x^2}
\,dx.\)</span></p>
<p>For <span class="math inline">\(f(x)= \frac{(1+2x)^3\cos x}{1+12x^2}\)</span> we have</p>
<p><span class="math inline">\(f_{even}(x)=\frac{1}{2}f(x)+\frac{1}{2}f(-x)=
\frac{(\cos x) \{(1+2x)^3+(1-2x)^3\}}{2(1+12x^2)}
=\frac{(\cos x) (2+24x^2)}{2(1+12x^2)}
=\cos x.\)</span> Thus <span class="math display">\[\int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \frac{(1+2x)^3\cos x}{1+12x^2}
\,dx=
2\int_0^{\frac{\pi}{4}}\cos x\,dx=2\bigg[\sin x\bigg]_0^{\frac{\pi}{4}}
=2\frac{1}{\sqrt{2}}=\sqrt{2}.\]</span></p>
</section>
<section id="summary-integration" class="level2" data-number="4.6">
<h2 data-number="4.6"><span class="header-section-number">4.6</span> Summary: Integration</h2>
<p>You should have a good understanding of the definitions of indefinite and definite integrals, and how they are related via the Fundamental Theorem of Calculus. You should also know how to use methods to calculate integrals such as integration by parts, recurrence relations and simplifications by considering even and odd (parts of) functions integrated over an interval symmetric about <span class="math inline">\(x=0\)</span>. Here are some key points:</p>
<ul>
<li><p>A function <span class="math inline">\(F\)</span> is an <span><em>indefinite integral</em></span> or <span><em>antiderivative</em></span> of a function <span class="math inline">\(f\)</span> if the derivative of <span class="math inline">\(F\)</span> is <span class="math inline">\(f\)</span>, i.e. if <span class="math inline">\(F&#39;(x) = f(x)\)</span>. Note that for a given <span class="math inline">\(f\)</span>, <span class="math inline">\(F\)</span> is not unique, but is fixed up to an <span><em>integration constant</em></span>.</p></li>
<li><p>The <span><em>definite integral</em></span> of <span class="math inline">\(f\)</span> over an interval <span class="math inline">\([a,b]\)</span> is the area under the graph of <span class="math inline">\(f\)</span> over this interval and can be defined as a limit of <span><em>Riemann sums</em></span>. When this limit exists we say <span class="math inline">\(f\)</span> is <span><em>integrable</em></span> on <span class="math inline">\([a,b]\)</span> (and if <span class="math inline">\(f\)</span> is continuous on <span class="math inline">\([a,b]\)</span> then it is integrable on <span class="math inline">\([a,b]\)</span>) and we denote the integral by <span class="math inline">\(\int_a^b f(x) dx\)</span>.</p></li>
<li><p>The <span><em>Fundamental theorem of calculus</em></span> says that if we define <span class="math inline">\(F(x) = \int_a^x f(t) dt\)</span> then <span class="math inline">\(F\)</span> is an antiderivative of <span class="math inline">\(f\)</span>, i.e. <span class="math inline">\(F&#39;(x) = \frac{d}{dx} \int_a^x f(t) dt = f(x)\)</span>.</p></li>
<li><p>You should know the definition of <span><em>even</em></span> and <span><em>odd functions</em></span> and that any function <span class="math inline">\(f\)</span> can be uniquely split into its even and odd parts <span class="math inline">\(f = f_{even} + f_{odd}\)</span>. The integral of any odd function over <span class="math inline">\([-a, a]\)</span> is zero and the integral of any even function over <span class="math inline">\([-a, a]\)</span> is twice the integral of that function over <span class="math inline">\([0,a]\)</span>.</p></li>
<li><p>Sometimes we have a family of definite or indefinite integrals parametrised by <span class="math inline">\(n\)</span> which we can denote <span class="math inline">\(I_n\)</span>. If we can find a <span><em>recurrence relation</em></span> relating the integrals for different values of <span class="math inline">\(n\)</span>, we can use this to calculate <span class="math inline">\(I_n\)</span>. E.g. if we can determine <span class="math inline">\(I_{n+1}\)</span> in terms of <span class="math inline">\(I_n\)</span> and we can calculate <span class="math inline">\(I_1\)</span> then the recurrence relation determines <span class="math inline">\(I_n\)</span> for all <span class="math inline">\(n \in \mathbb{N}\)</span>.</p></li>
<li><p>This section also contained some results for limits which are summarised as “<span><em>exponentials beat powers beat logs</em></span>” as <span class="math inline">\(x \to \infty\)</span>. We also saw that <span class="math inline">\(\lim_{y \to \infty} \left(1 + \frac{x}{y}\right)^y = e^x\)</span>.</p></li>
</ul>
</section>
</section>
<section id="double-integrals" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Double integrals</h1>
<section id="rectangular-regions" class="level2" data-number="5.1">
<h2 data-number="5.1"><span class="header-section-number">5.1</span> Rectangular regions</h2>
<p>Recall that for a function <span class="math inline">\(f(x)\)</span> the definite integral <span class="math inline">\(\int_a^b f(x)\,dx\)</span> is the signed area under the curve <span class="math inline">\(y=f(x)\)</span> between <span class="math inline">\(x=a\)</span> and <span class="math inline">\(x=b\)</span>. This interpretation of the definite integral can be generalized for a function of two variables to a volume under a surface.</p>
<p>Given a function <span class="math inline">\(f(x,y)\)</span> and a region <span class="math inline">\(D\)</span> in the <span class="math inline">\((x,y)\)</span> plane, the double integral <span class="math display">\[\iint\limits_D f(x,y)\, dxdy\]</span> is the signed volume of the region between the surface <span class="math inline">\(z=f(x,y)\)</span> and the region <span class="math inline">\(D\)</span> in the <span class="math inline">\(z=0\)</span> plane (see Figure <a href="#fig-doubleintegral" data-reference-type="ref" data-reference="fig-doubleintegral">13</a>).</p>
<p><img src="double_integral1.jpg" title="fig:" id="fig-doubleintegral" style="width:6cm" alt="The double integral is the signed volume of the region between the surface z=f(x,y) and the region D in the z=0 plane. It is obtained as the limit of a Riemann sum of cuboid volumes." /> <img src="double_integral3.jpg" title="fig:" id="fig-doubleintegral" style="width:6.7cm" alt="The double integral is the signed volume of the region between the surface z=f(x,y) and the region D in the z=0 plane. It is obtained as the limit of a Riemann sum of cuboid volumes." /></p>
<p>In a similar manner to our earlier construction of the definite integral, in terms of the limit of a Riemann sum of areas of rectangles, we can define the double integral as the limit of a Riemann sum of volumes of cuboids.</p>
<p>For simplicity, consider the case of a rectangular region <span class="math inline">\(D=[a_0,a_1]\times[b_0,b_1].\)</span> We construct a subdivision <span class="math inline">\(S\)</span> of <span class="math inline">\(D\)</span> by defining the points of a two-dimensional lattice as <span class="math inline">\(a_0=x_0&lt;x_1&lt;\ldots&lt;x_n=a_1\)</span> and <span class="math inline">\(b_0=y_0&lt;y_1&lt;\ldots&lt;y_m=b_1.\)</span> The edge lengths of the lattice are equal to <span class="math inline">\(dx_i=x_i-x_{i-1}\)</span> for <span class="math inline">\(i=1,\dots,n\)</span> and <span class="math inline">\(dy_j=y_j-y_{j-1}\)</span> for <span class="math inline">\(j=1,\dots,m.\)</span> The norm of the subdivision <span class="math inline">\(|S|\)</span> is given by the maximum of all the <span class="math inline">\(dx_i\)</span> and <span class="math inline">\(dy_j.\)</span></p>
<p>We introduce sample points <span class="math inline">\((p_i,q_j)\in[x_{i-1},x_i]\times[y_{j-1},y_j]\)</span> inside each rectangle of the lattice. The area of the rectangle is <span class="math inline">\(dx_idy_j\)</span> and we associate to this rectangle a cuboid of height <span class="math inline">\(f(p_i,q_j).\)</span> The volume of all the cuboids is the Riemann sum <span class="math display">\[{\cal R}=\sum_{i=1}^n\sum_{j=1}^m f(p_i,q_j) dx_idy_j\]</span> and the double integral is the limit <span class="math display">\[\iint\limits_D f(x,y)\, dxdy=\lim_{|S|\to 0} {\cal R}.\]</span></p>
<p>In the special case that <span class="math inline">\(f(x,y)\)</span> is a constant, say <span class="math inline">\(f(x,y)=c\)</span>, then</p>
<p><span class="math inline">\(\iint\limits_D f(x,y)\, dxdy=c\times {\rm area}(D).\)</span></p>
<p> </p>
<p>For a rectangular region <span class="math inline">\(D=[a_0,a_1]\times[b_0,b_1]\)</span> a practical way to compute the double integral is to use the following iterated integral result (valid providing <span class="math inline">\(f\)</span> is continuous on <span class="math inline">\(D\)</span>) <span class="math display">\[\iint\limits_D f(x,y)\, dxdy=
\int_{a_0}^{a_1}\bigg(\int_{b_0}^{b_1} f(x,y)\, dy\bigg)\, dx
=\int_{b_0}^{b_1}\bigg(\int_{a_0}^{a_1} f(x,y)\, dx\bigg)\, dy.\]</span> Eg. Given the region <span class="math inline">\(D=[-2,1]\times[0,1]\)</span>, calculate <span class="math inline">\(\iint\limits_D (x^2+y^2) \,dxdy.\)</span></p>
<p><span class="math display">\[\iint\limits_D (x^2+y^2) \,dxdy=
\int_{-2}^1\bigg(\int_0^1 (x^2+y^2)\,dy\bigg)\,dx
=\int_{-2}^1\bigg(\bigg[yx^2+\frac{1}{3}y^3\bigg]_{y=0}^{y=1}
\bigg)\,dx\]</span> <span class="math display">\[=\int_{-2}^1(x^2+\frac{1}{3})\,dx=\bigg[\frac{x^3}{3}+\frac{x}{3}\bigg]_{-2}^1
=\frac{1}{3}(1+1+8+2)=4.\]</span> As an exercise, check that the same result is obtained if the integration is performed in the other order.</p>
</section>
<section id="beyond-rectangular-regions" class="level2" data-number="5.2">
<h2 data-number="5.2"><span class="header-section-number">5.2</span> Beyond rectangular regions</h2>
<p>To compute double integrals beyond rectangular regions we need to consider the following definition.<br />
<span><strong>Defn:</strong></span> A region <span class="math inline">\(D\)</span> of the plane is called <span class="math inline">\({\bf y-simple}\)</span> if every line that is parallel to the <span class="math inline">\(y\)</span>-axis and intersects <span class="math inline">\(D\)</span>, does so in a single line segment (or a single point if this is on the boundary of <span class="math inline">\(D\)</span>).<br />
</p>
<figure>
<img src="new_ysimple.png" id="fig-ysimple" style="width:7cm" alt="" /><figcaption>A <span class="math inline">\(y\)</span>-simple region.</figcaption>
</figure>
<p>See Figure <a href="#fig-ysimple" data-reference-type="ref" data-reference="fig-ysimple">14</a> for an example of a <span class="math inline">\(y\)</span>-simple region. The boundaries of this region are given by the curves <span class="math inline">\(y=\phi_1(x)\)</span> and <span class="math inline">\(y=\phi_2(x)\)</span> for <span class="math inline">\(a_0\le x\le a_1.\)</span><br />
The double integral can be calculated as an iterated integral by integrating over <span class="math inline">\(y\)</span> first <span class="math display">\[\iint\limits_D f(x,y) \,dxdy=
\int_{a_0}^{a_1}\bigg(\int_{\phi_1(x)}^{\phi_2(x)} f(x,y)\,dy\bigg)\,dx.\]</span></p>
<p>Eg. Sketch the region <span class="math inline">\(D\)</span> that lies between the curves <span class="math inline">\(y=x\)</span> and <span class="math inline">\(y=x^2\)</span> for <span class="math inline">\(0\le x\le 1\)</span> and calculate <span class="math inline">\(\iint\limits_D 6xy \,dxdy.\)</span></p>
<figure>
<img src="new_region1.png" id="fig-region1" style="width:6cm" alt="" /><figcaption>A sketch of the region <span class="math inline">\(D\)</span> in the example.</figcaption>
</figure>
<p>As the region <span class="math inline">\(D\)</span> is <span class="math inline">\(y\)</span>-simple then <span class="math display">\[\iint\limits_D 6xy \,dxdy
=\int_0^1\bigg(\int_{x^2}^x 6xy\,dy\bigg)\,dx
=\int_0^1\bigg[3xy^2\bigg]_{y=x^2}^{y=x}\,dx
=3\int_0^1(x^3-x^5)\,dx\]</span> <span class="math display">\[=3\bigg[\frac{x^4}{4}-\frac{x^6}{6}\bigg]_0^1
=3\bigg(\frac{1}{4}-\frac{1}{6}\bigg)=\frac{1}{4}.\]</span>  </p>
<p>There is a similar definition of an <span class="math inline">\(x\)</span>-simple region.<br />
<span><strong>Defn:</strong></span> A region <span class="math inline">\(D\)</span> of the plane is called <span class="math inline">\({\bf x-simple}\)</span> if every line that is parallel to the <span class="math inline">\(x\)</span>-axis and intersects <span class="math inline">\(D\)</span>, does so in a single line segment (or a single point if this is on the boundary of <span class="math inline">\(D\)</span>).<br />
Figure <a href="#fig-xsimple" data-reference-type="ref" data-reference="fig-xsimple">16</a> shows an example of an <span class="math inline">\(x\)</span>-simple region that is not <span class="math inline">\(y\)</span>-simple.</p>
<figure>
<img src="new_xsimple.png" id="fig-xsimple" style="width:6cm" alt="" /><figcaption>A region that is <span class="math inline">\(x\)</span>-simple but is not <span class="math inline">\(y\)</span>-simple.</figcaption>
</figure>
<p>The boundaries of this region are the curves <span class="math inline">\(x=\psi_1(y)\)</span> and <span class="math inline">\(x=\psi_2(y)\)</span> for <span class="math inline">\(b_0\le y\le b_1.\)</span></p>
<p>The double integral can be calculated as an iterated integral by integrating over <span class="math inline">\(x\)</span> first <span class="math display">\[\iint\limits_D f(x,y) \,dxdy=
\int_{b_0}^{b_1}\bigg(\int_{\psi_1(y)}^{\psi_2(y)} f(x,y)\,dx\bigg)\,dy.\]</span></p>
<p> </p>
<p>A region can be both <span class="math inline">\(x\)</span>-simple and <span class="math inline">\(y\)</span>-simple, in which case the double integral can be calculated as an iterated integral by integrating over <span class="math inline">\(x\)</span> first or <span class="math inline">\(y\)</span> first. The region in the previous example is <span class="math inline">\(x\)</span>-simple, so we can recalculate this double integral using this property.<br />
Same Eg. <span class="math inline">\(D\)</span> is the region between the curves <span class="math inline">\(y=x\)</span> and <span class="math inline">\(y=x^2\)</span> for <span class="math inline">\(0\le x\le 1\)</span>. Use the fact that this region is <span class="math inline">\(x\)</span>-simple to calculate <span class="math inline">\(\iint\limits_D 6xy \,dxdy.\)</span><br />
The boundaries of <span class="math inline">\(D\)</span> are given by the curves <span class="math inline">\(x=y\)</span> and <span class="math inline">\(x=\sqrt{y}\)</span> for <span class="math inline">\(0\le y\le 1\)</span>. Note from Figure <a href="#fig-region1" data-reference-type="ref" data-reference="fig-region1">15</a> that moving along a line (that passes through <span class="math inline">\(D\)</span>) parallel to the <span class="math inline">\(x\)</span>-axis with <span class="math inline">\(x\)</span> increasing, intersects the curve <span class="math inline">\(x=y\)</span> before it intersects the curve <span class="math inline">\(x=\sqrt{y}.\)</span> Thus <span class="math inline">\(y\)</span> is the lower limit in the <span class="math inline">\(x\)</span> integration and <span class="math inline">\(\sqrt{y}\)</span> is the upper limit. <span class="math display">\[\iint\limits_D 6xy \,dxdy
=\int_0^1\bigg(
\int_y^{\sqrt{y}} 6xy\,dx\bigg)\,dy
=\int_0^1\bigg[3x^2y\bigg]_{x=y}^{x=\sqrt{y}}\,dy
=3\int_0^1(y^2-y^3)\,dy\]</span> <span class="math display">\[=3\bigg[\frac{y^3}{3}-\frac{y^4}{4}\bigg]_0^1
=3\bigg(\frac{1}{3}-\frac{1}{4}\bigg)=\frac{1}{4}.\]</span></p>
<p> </p>
<p>Sometimes a region may be both <span class="math inline">\(x\)</span>-simple and <span class="math inline">\(y\)</span>-simple but we can only perform the integration explicitly for one of the ordering choices ie. either integrating over <span class="math inline">\(x\)</span> first or <span class="math inline">\(y\)</span> first.<br />
Eg. The boundaries of <span class="math inline">\(D\)</span> are given by the curves <span class="math inline">\(y=x\)</span> and <span class="math inline">\(y=\sqrt{x}\)</span> for <span class="math inline">\(0\le x\le 1\)</span>.</p>
<p>Calculate <span class="math inline">\(\iint\limits_D \frac{e^y}{y} \,dxdy\)</span>.</p>
<p>If we use the fact that <span class="math inline">\(D\)</span> is <span class="math inline">\(y\)</span>-simple then we have <span class="math display">\[\iint\limits_D \frac{e^y}{y} \,dxdy
=\int_0^1\bigg(
\int_x^{\sqrt{x}}\frac{e^y}{y}\,dy\bigg)\,dx,\]</span> but we can’t do the integration. However, if we use the fact that <span class="math inline">\(D\)</span> is <span class="math inline">\(x\)</span>-simple and the bounding curves are <span class="math inline">\(x=y\)</span> and <span class="math inline">\(x=y^2\)</span> then <span class="math display">\[\iint\limits_D \frac{e^y}{y} \,dxdy
=\int_0^1\bigg(\int_{y^2}^{y}\frac{e^y}{y}\,dx\bigg)\,dy
=\int_0^1\bigg[\frac{xe^y}{y}\bigg]_{x=y^2}^{x=y}\,dy
=\int_0^1(e^y-ye^y)\,dy\]</span> <span class="math display">\[=[e^y]_0^1-[ye^y]_0^1+\int_0^1e^y\,dy
=e-2.\]</span></p>
</section>
<section id="integration-using-polar-coordinates" class="level2" data-number="5.3">
<h2 data-number="5.3"><span class="header-section-number">5.3</span> Integration using polar coordinates</h2>
<p>Sometimes it may be useful to describe the region of integration <span class="math inline">\(D\)</span> in terms of polar coordinates <span class="math inline">\(r\)</span> and <span class="math inline">\(\theta\)</span>, where <span class="math inline">\(x=r\cos\theta\)</span> and <span class="math inline">\(y=r\sin\theta.\)</span> To convert a double integral into polar coordinates we need to know what to do with the area element <span class="math inline">\(dA=dxdy.\)</span> Recall that this area element came from the definition of the integral in terms of a division of <span class="math inline">\(D\)</span> into small rectangles. The area of a small rectangle with side lengths <span class="math inline">\(dx\)</span> and <span class="math inline">\(dy\)</span> is <span class="math inline">\(dA=dx dy\)</span> which is the area element in the infinitesimal limit.<br />
We therefore need to know the area <span class="math inline">\(dA\)</span> of a small region obtained by taking the point with polar cooridnates <span class="math inline">\((r,\theta)\)</span> and extending <span class="math inline">\(r\)</span> by <span class="math inline">\(dr\)</span> and <span class="math inline">\(\theta\)</span> by <span class="math inline">\(d\theta\)</span>, as shown in Figure <a href="#fig-polar" data-reference-type="ref" data-reference="fig-polar">17</a>. We see that the area is approximately a rectangle with area <span class="math inline">\(dA\approx r d\theta  dr\)</span> and this approximation improves as the area decreases. In the infinitesimal limit that defines the integral the result is <span class="math inline">\(dA=dxdy=rd\theta dr.\)</span><br />
We now know how to convert a double integral to polar coordinates, we replace <span class="math inline">\(dxdy\)</span> with <span class="math inline">\(rd\theta dr.\)</span> Note the crucial factor of <span class="math inline">\(r\)</span> here. We can then calculate the double integral as an iterated integral if the region <span class="math inline">\(D\)</span> is <span class="math inline">\(\theta\)</span>-simple or <span class="math inline">\(r\)</span>-simple (with the obvious definitions of these terms).</p>
<figure>
<img src="new_polar.png" id="fig-polar" style="width:9cm" alt="" /><figcaption>The area element in polar coordinates.</figcaption>
</figure>
<p>Eg. Let <span class="math inline">\(D\)</span> be the region between the curves <span class="math inline">\(x^2+y^2=1\)</span> and <span class="math inline">\(x^2+y^2=4\)</span> satisfying <span class="math inline">\(x\ge 0\)</span> and <span class="math inline">\(y\ge 0.\)</span> Calculate <span class="math inline">\(\iint\limits_D xy \,dxdy.\)</span><br />
In polar coordinates the region <span class="math inline">\(D\)</span> is given by <span class="math inline">\(1\le r\le 2\)</span> and <span class="math inline">\(0\le\theta\le \frac{\pi}{2}.\)</span></p>
<p>The area element is <span class="math inline">\(dxdy=rd\theta dr\)</span> and the integrand is <span class="math inline">\(xy=r^2\cos\theta\sin\theta.\)</span> <span class="math display">\[\iint\limits_D xy \,dxdy=
\iint\limits_D r^2\sin\theta\cos\theta \,rdrd\theta
=\int_1^2\bigg(\int_0^{\pi/2} r^3\sin\theta\cos\theta\,d\theta\bigg)dr\]</span> <span class="math display">\[=\int_1^2\bigg(
\int_0^{\pi/2}\frac{1}{2}\sin(2\theta)\,d\theta\bigg)r^3\,dr
=\int_1^2\bigg[-\frac{1}{4}\cos(2\theta)\bigg]_{\theta=0}^{\theta=\pi/2}
r^3\,dr
=\int_1^2\frac{1}{2}r^3\,dr\]</span> <span class="math display">\[=\bigg[\frac{1}{8}r^4\bigg]_1^2=\frac{15}{8}.\]</span> As an exercise, you can check that you obtain the same result if you perform the calculation without changing to polar coordinates.</p>
</section>
<section id="change-of-variables-and-the-jacobian" class="level2" data-number="5.4">
<h2 data-number="5.4"><span class="header-section-number">5.4</span> Change of variables and the Jacobian</h2>
<p>Using polar coordinates <span class="math inline">\(r,\theta\)</span> rather than Cartesian coordiantes <span class="math inline">\(x,y\)</span> is a particular example of a change of variables. In general we might want to change variables from <span class="math inline">\(x,y\)</span> to new variables <span class="math inline">\(u,v\)</span> given by relations of the form <span class="math inline">\(x=g(u,v)\)</span> and <span class="math inline">\(y=h(u,v)\)</span> for some functions <span class="math inline">\(g\)</span> and <span class="math inline">\(h.\)</span> Not only do we need to know what the integration region <span class="math inline">\(D\)</span> looks like in the new variables, but we also need the area element <span class="math inline">\(dxdy\)</span> in the new variables. The following definition plays the central role in this issue.<br />
<span><strong>Defn.</strong></span> The <span><strong>Jacobian</strong></span> of the transformation from the variables <span class="math inline">\(x,y\)</span> to <span class="math inline">\(u,v\)</span> is <span class="math display">\[J=\frac{\partial(x,y)}{\partial(u,v)}
=\left| \begin{array}{ccc}
\frac{\partial x}{\partial u}&amp; &amp;
\frac{\partial x}{\partial v}\\
 &amp; \\
\frac{\partial y}{\partial u}&amp; &amp;
\frac{\partial y}{\partial v}\\
\end{array}
\right|\]</span> ie. it is the determinant of the <span class="math inline">\(2\times 2\)</span> matrix of partial derivatives.<br />
To obtain the area element <span class="math inline">\(dxdy\)</span> in terms of the new variables we first compute the Jacobian <span class="math inline">\(J\)</span> and then use the result that <span class="math display">\[dxdy=|J|dudv\]</span> where <span class="math inline">\(|J|\)</span> is the absolute value of the Jacobian.<br />
As an example, we can rederive the area element in polar coordinates. We have <span class="math inline">\(x=r\cos\theta\)</span> and <span class="math inline">\(y=r\sin\theta,\)</span> so in this case <span class="math inline">\(r,\theta\)</span> are the new variables, playing the role of <span class="math inline">\(u,v\)</span> in the general setting. <span class="math display">\[J=\frac{\partial(x,y)}{\partial(r,\theta)}
=\left| \begin{array}{ccc}
\frac{\partial x}{\partial r}&amp; &amp;
\frac{\partial x}{\partial \theta}\\
 &amp; \\
\frac{\partial y}{\partial r}&amp; &amp;
\frac{\partial y}{\partial \theta}\\
\end{array}
\right|
=\left| \begin{array}{ccc}
\cos\theta &amp; &amp; -r\sin\theta\\
&amp; \\
\sin\theta &amp; &amp; r\cos\theta\\
\end{array}
\right|
=r\cos^2\theta+r\sin^2\theta=r\]</span> giving <span class="math inline">\(dxdy=|J|drd\theta=rdrd\theta\)</span> as before.<br />
Eg. Let <span class="math inline">\(D\)</span> be the square in the <span class="math inline">\((x,y)\)</span> plane with vertices <span class="math inline">\((0,0),(1,1),(2,0),(1,-1).\)</span> Calculate <span class="math inline">\(\iint\limits_D (x+y) \,dxdy\)</span> by making the change of variables <span class="math inline">\(x=u+v\)</span> and <span class="math inline">\(y=u-v.\)</span><br />
First we need to determine the region <span class="math inline">\(D\)</span> in terms of the variables <span class="math inline">\([u,v].\)</span> Using <span class="math inline">\(u=(x+y)/2\)</span> and <span class="math inline">\(v=(x-y)/2\)</span> we find that the vertices map to the <span class="math inline">\([u,v]\)</span> coordinates <span class="math inline">\([0,0],[1,0],[1,1],[0,1].\)</span> The edges of the square lie along the lines <span class="math inline">\(y=x,\ y=-x,\ y=2-x,\ y=x-2\)</span> which map to the lines <span class="math inline">\(v=0,\ u=0,\ u=1,\ v=1.\)</span> Therefore in the <span class="math inline">\([u,v]\)</span> plane <span class="math inline">\(D\)</span> is again a square, with the vertices given above.</p>
<figure>
<img src="trans.png" id="fig-square" style="width:9cm" alt="" /><figcaption>A square in the <span class="math inline">\((x,y)\)</span> plane is transformed into a square in the <span class="math inline">\([u,v]\)</span> plane.</figcaption>
</figure>
<p>The Jacobian of the transformation is <span class="math display">\[J=\frac{\partial(x,y)}{\partial(u,v)}
=\left| \begin{array}{ccc}
\frac{\partial x}{\partial u}&amp; &amp;
\frac{\partial x}{\partial v}\\
 &amp; \\
\frac{\partial y}{\partial u}&amp; &amp;
\frac{\partial y}{\partial v}\\
\end{array}
\right|
=\left| \begin{array}{ccc}
1 &amp; &amp; 1\\
&amp; \\
1 &amp; &amp; -1\\ 
\end{array}
\right|
=-2.\]</span> Thus <span class="math inline">\(dxdy=|J|dudv=2dudv.\)</span></p>
<p>Finally, the integrand is <span class="math inline">\(x+y=2u.\)</span> Putting all this together we get <span class="math display">\[\iint\limits_D (x+y) \,dxdy
=\iint\limits_D 4u \,dudv
=\int_0^1\bigg(\int_0^1 4u\,dv\bigg)\,du\]</span> <span class="math display">\[=\int_0^1\bigg[4uv\bigg]_{v=0}^{v=1}\,du=\int_0^1 4u\,du
=\bigg[2u^2\bigg]_0^1=2.\]</span></p>
</section>
<section id="the-gaussian-integral" class="level2" data-number="5.5">
<h2 data-number="5.5"><span class="header-section-number">5.5</span> The Gaussian integral</h2>
<p>An important integral that appears in a wide range of mathematical contexts is the Gaussian integral <span class="math display">\[\int_{-\infty}^\infty e^{-ax^2}\,dx=\sqrt{\frac{\pi}{a}}\]</span> where <span class="math inline">\(a\)</span> is a positive constant.<br />
We can derive this result using a trick that involves calculating a double integral, as follows. We define <span class="math inline">\(I\)</span> to be the required integral <span class="math display">\[I=\int_{-\infty}^\infty e^{-ax^2}\,dx\]</span> and observe that <span class="math display">\[I^2=\bigg(\int_{-\infty}^\infty e^{-ax^2}\,dx\bigg)
\bigg(\int_{-\infty}^\infty e^{-ay^2}\,dy\bigg)
=\iint\limits_{\mathbb{R}^2}
e^{-a(x^2+y^2)}\,dxdy.\]</span> We now use polar coordinates to evaluate this double integral <span class="math display">\[I^2=\iint\limits_{\mathbb{R}^2}
e^{-ar^2}r\,drd\theta
=\int_0^\infty\bigg(\int_0^{2\pi}r e^{-ar^2}\,d\theta\bigg)\,dr
=2\pi\int_0^\infty re^{-ar^2}\,dr\]</span> <span class="math display">\[=-2\pi\bigg[\frac{e^{-ar^2}}{2a}\bigg]_0^\infty
=\frac{\pi}{a}.\]</span> Hence <span class="math inline">\(I=\sqrt{\pi/a}\)</span>, which is the required result.</p>
</section>
<section id="summary-double-integration" class="level2" data-number="5.6">
<h2 data-number="5.6"><span class="header-section-number">5.6</span> Summary: Double integration</h2>
<p>You should have a good understanding of how to calculate double integrals and methods such as swapping the order of integration or changing variables. Here are some key points:</p>
<ul>
<li><p>The <span><em>double integral</em></span> of a function of two variables <span class="math inline">\(f(x,y)\)</span> over a region <span class="math inline">\(D\)</span> is the definite integral <span class="math inline">\(\int\int_D f(x,y) dx dy\)</span> which can be defined as a limit of Riemann sums. This limit always exists if <span class="math inline">\(f\)</span> is continuous on a closed region <span class="math inline">\(D\)</span>. This has the interpretation as the (signed) volume between the surface <span class="math inline">\(f(x,y)\)</span> and the region <span class="math inline">\(D\)</span> in the <span class="math inline">\((x,y)\)</span>-plane. If <span class="math inline">\(f(x,y) = 1\)</span> the integral gives the area of <span class="math inline">\(D\)</span>.</p></li>
<li><p>You should know how to calculate double integrals for <span><em><span class="math inline">\(x\)</span>-simple</em></span> and <span><em><span class="math inline">\(y\)</span>-simple</em></span> regions which are regions which can be divided into strips parallel to the <span class="math inline">\(x\)</span>-axis or <span class="math inline">\(y\)</span>-axis respectively with each strip being a single interval. You should know how to change the order of integration for regions which are both <span class="math inline">\(x\)</span>-simple and <span class="math inline">\(y\)</span>-simple – note that this process is trivial for rectangular regions but otherwise requires some care.</p></li>
<li><p>Sometimes for a region which is both <span class="math inline">\(x\)</span>-simple and <span class="math inline">\(y\)</span>-simple we can only calculate the integral for one order of integration, sometimes both ways are possible but one way is easier.</p></li>
<li><p>A change of variable from <span class="math inline">\((x,y)\)</span> to <span class="math inline">\((u,v)\)</span> can be performed but care must be taken so that the integration measure is correct, i.e. that the value of the integral doesn’t depend on the choice of variables. This can be derived by ensuring that the double integral of <span class="math inline">\(1\)</span> always gives the area of any region <span class="math inline">\(D\)</span>. The result is <span class="math inline">\(dx dy = |J| du dv\)</span> where <span class="math inline">\(J\)</span> is the <span><em>Jacobian</em></span> determinant <span class="math inline">\(J = \frac{\partial(x,y)}{\partial(u,v)} = \left\vert \begin{array}{cc} \frac{\partial x}{\partial u} &amp; \frac{\partial x}{\partial v} \\ \frac{\partial y}{\partial u} &amp; \frac{\partial y}{\partial v} \end{array} \right\vert\)</span>.</p></li>
<li><p>A particular change of variables is from 2d Cartesian coordinates <span class="math inline">\((x, y)\)</span> to 2d polar coordinates <span class="math inline">\((r, \theta)\)</span> where <span class="math inline">\(dx dy = r dr d\theta\)</span>.</p></li>
<li><p>Changes of variable may be motivated by the shape of the region <span class="math inline">\(D\)</span> or by the form of the integrand but both factors will affect how easy or hard it is to calculate the integral.</p></li>
<li><p>The 1d <span><em>Gaussian integral</em></span> <span class="math inline">\(I = \int_{- \infty}^{\infty} e^{-a x^2} dx\)</span> for <span class="math inline">\(a &gt; 0\)</span> is an interesting example where we can square it to find a 2d Gaussian integral which is a double integral we can evaluate by changing to polar coordinates. This then gives the result for the original Gaussian integral <span class="math inline">\(I = \sqrt{\pi/a}\)</span> which we had no way to calculate as a single variable integral.</p></li>
</ul>
</section>
</section>
<section id="first-order-differential-equations" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> First order differential equations</h1>
<section id="first-order-separable-odes" class="level2" data-number="6.1">
<h2 data-number="6.1"><span class="header-section-number">6.1</span> First order separable ODEs</h2>
<p>A <span><strong>differential equation</strong></span> is an equation that relates an unknown function (the dependent variable) to one or more of its derivatives. The <span><strong>order</strong></span> of a differential equation is the order of the highest derivative that appears in the equation. A function that satisfies the differential equation is called a <span><strong>solution</strong></span> and the process of finding a solution is called <span><strong>solving</strong></span> the differential equation. If the dependent variable depends on only a single unknown variable (the independent variable) then the differential equation is called an <span><strong>ordinary differential equation</strong></span> (ODE). We shall deal only with ODEs.</p>
<p>Differential equations for functions with several independent variables and involving partial derivatives are called <span><strong>partial differential equations</strong></span> (PDEs). These are generally much harder to solve and wont be discussed in this course.<br />
We shall usually discuss ODEs using <span class="math inline">\(y\)</span> to denote the dependent variable and <span class="math inline">\(x\)</span> for the independent variable, so solving the ODE involves finding <span class="math inline">\(y(x).\)</span><br />
The generic first order ODE may be written in the form <span class="math display">\[\frac{dy}{dx}=f(x,y) \hskip 3cm (\star)\]</span> Generically this will have a one-parameter family of solutions ie. the <span><strong>general solution</strong></span> will contain an arbitrary constant. Assigning a particular value to this constant gives a <span><strong>particular solution</strong></span>. A particular solution will be singled out by the assignment of an <span><strong>initial value</strong></span> ie. requiring <span class="math inline">\(y(x_0)=y_0,\)</span> for given <span class="math inline">\(x_0\)</span> and <span class="math inline">\(y_0.\)</span> In this case the ODE is called an <span><strong>initial value problem</strong></span> (IVP). To solve an IVP, first solve the ODE to find the general solution and then determine the value of the constant so that the IVP is also satisfied.<br />
Depending upon the form of the function <span class="math inline">\(f(x,y)\)</span> there are various methods that can be used to solve certain kinds of ODEs. We shall discuss these in turn.<br />
The ODE <span class="math inline">\((\star)\)</span> is <span><strong>separable</strong></span> if <span class="math inline">\(f(x,y)=X(x)Y(y).\)</span></p>
<p>It can be solved by direct integration as <span class="math display">\[\int \frac{1}{Y(y)}\,dy=\int X(x)\,dx.\]</span>  <span> Eg</span>. Solve the IVP <span class="math display">\[\frac{dy}{dx}=xe^{y-x} \quad
\mbox{with}\quad y(0)=0.\]</span> <span class="math display">\[y&#39;=xe^{-x}e^y, \quad
\int e^{-y}\,dy=\int xe^{-x}\,dx, \quad
-e^{-y}=-xe^{-x}+\int e^{-x}\,dx=-xe^{-x}-e^{-x}+c\]</span> <span class="math display">\[y=-\log(e^{-x}(1+x)-c). \quad
y(0)=0=\log(1-c), \quad \mbox{so}\quad c=0.\]</span> <span class="math display">\[y=-\log(e^{-x}(1+x))=x-\log(1+x).\]</span>  <br />
<span> Eg</span>. Solve <span class="math display">\[y&#39;=\frac{2x(1+y^2)}{(1+x^2)^2}.\]</span> <span class="math display">\[\int \frac{1}{1+y^2}\,dy=\int \frac{2x}{(1+x^2)^2}\,dx, \quad
\tan^{-1}y=-\frac{1}{1+x^2}-c, \quad
y=-\tan\bigg(\frac{1}{1+x^2}+c\bigg).\]</span>  <br />
Eg. Solve the IVP <span class="math display">\[y&#39;=\frac{x^2y-y}{1+y}, \quad y(3)=1.\]</span> <span class="math display">\[\int \frac{1+y}{y}\,dy=\int (x^2-1)\, dx, \quad
y+\log|y|=\frac{x^3}{3}-x+c.\quad \mbox{Put}\ x=3\ \mbox{and} \ y=1\]</span> <span class="math display">\[1=6+c, \quad c=-5, \quad \mbox{hence} \quad y+\log|y|=\frac{x^3}{3}-x-5.\]</span> In this case the final solution can only be written in implicit form ie. it cannot be written in an explicit form <span class="math inline">\(y=...\)</span> where the right hand side is a function of <span class="math inline">\(x\)</span> only.<br />
</p>
</section>
<section id="first-order-homogeneous-odes" class="level2" data-number="6.2">
<h2 data-number="6.2"><span class="header-section-number">6.2</span> First order homogeneous ODEs</h2>
<p>The ODE <span class="math inline">\((\star)\)</span> is <span><strong>homogeneous</strong></span> if <span class="math inline">\(f(tx,ty)=f(x,y)\ \ \forall \ t\in\mathbb{R}.\)</span><br />
In this case the substitution <span class="math inline">\(y=xv\)</span> produces a separable ODE for <span class="math inline">\(v(x).\)</span><br />
<span> Eg</span>. Solve <span class="math display">\[y&#39;=\frac{y^2-x^2}{xy}.\]</span> <span class="math display">\[f(tx,ty)=\frac{t^2y^2-t^2x^2}{txty}=\frac{y^2-x^2}{xy}=f(x,y)
\quad \mbox{hence homogeneous.}\]</span> Put <span class="math inline">\(y=xv\)</span> then <span class="math inline">\(y&#39;=v+xv&#39;\)</span> and the ODE becomes <span class="math display">\[v+xv&#39;=\frac{x^2v^2-x^2}{x^2v}=v-\frac{1}{v}, \quad
v&#39;=-\frac{1}{xv}, \quad
\int v\,dv=\int -\frac{1}{x}\,dx, \quad \frac{v^2}{2}=-\log|x|+\log c,\]</span> <span class="math display">\[v=\pm \sqrt{2\log\bigg|\frac{c}{x}\bigg|}, \quad 
y=xv=\pm x\sqrt{2\log\bigg|\frac{c}{x}\bigg|}.\]</span></p>
</section>
<section id="first-order-linear-odes" class="level2" data-number="6.3">
<h2 data-number="6.3"><span class="header-section-number">6.3</span> First order linear ODEs</h2>
<p>The ODE <span class="math inline">\((\star)\)</span> is <span><strong>linear</strong></span> if <span class="math inline">\(f(x,y)=-p(x)y+q(x),\)</span> in which case we can write the standard form of a linear first order ODE as <span class="math display">\[y&#39;+py=q\]</span> where <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> can be any functions of <span class="math inline">\(x.\)</span></p>
<p>In this case the ODE can be solved in terms of the <span><strong>integrating factor</strong></span> <span class="math display">\[I(x)=e^{\int p(x)\,dx}.\]</span> The solution is given by <span class="math display">\[y=\frac{1}{I(x)}\int I(x)q(x)\, dx.\]</span> Proof: We need to show that <span class="math inline">\(y\)</span> satisfies the ODE <span class="math inline">\(y&#39;+py=q.\)</span><br />
The first step is to observe that <span class="math inline">\(I&#39;=e^{\int p\,dx}p=Ip.\)</span><br />
With <span class="math inline">\(y=\frac{1}{I}\int Iq\,dx\)</span> we have <span class="math display">\[y&#39;=-\frac{I&#39;}{I^2}\int Iq\,dx+\frac{1}{I}Iq
=-\frac{I&#39;}{I}y+q=-\frac{Ip}{I}y+q=-py+q,\]</span> as required.<br />
<span> Eg</span>. Solve the IVP <span class="math display">\[y&#39;-\frac{2}{x}y=3x^3, \ \ y(-1)=2.\]</span></p>
<p>In the above notation <span class="math inline">\(p=-\frac{2}{x}\)</span> and <span class="math inline">\(q=3x^3.\)</span> <span class="math display">\[I=\exp\bigg(\int p\,dx\bigg)=\exp\bigg(\int -\frac{2}{x}\,dx\bigg)
=\exp\bigg(-2\log x\bigg)=\frac{1}{x^2}.\]</span> <span class="math display">\[y=\frac{1}{I}\int Iq\,dx=x^2\int \frac{1}{x^2}3x^3\,dx
=x^2\int 3x\,dx=x^2\bigg(\frac{3}{2}x^2+c\bigg)
=\frac{3}{2}x^4+cx^2.\]</span> Using <span class="math inline">\(y(-1)=2\)</span> we have <span class="math inline">\(2=\frac{3}{2}+c\)</span>  hence  <span class="math inline">\(c=\frac{1}{2}\)</span>  giving  <span class="math inline">\(y=\frac{3}{2}x^4+\frac{1}{2}x^2.\)</span></p>
</section>
<section id="first-order-exact-odes" class="level2" data-number="6.4">
<h2 data-number="6.4"><span class="header-section-number">6.4</span> First order exact ODEs</h2>
<p>An alternative form in which to write a first order ODE is <span class="math display">\[M(x,y)\,dx+N(x,y)\,dy=0. \hskip 3cm (\star\star)\]</span> Rearranging gives <span class="math display">\[\frac{dy}{dx}=-\frac{M(x,y)}{N(x,y)}\]</span> so this agrees with the form <span class="math inline">\((\star)\)</span> with <span class="math inline">\(f(x,y)=\frac{M(x,y)}{N(x,y)}.\)</span></p>
<p>Note that a given <span class="math inline">\(f(x,y)\)</span> does not correspond to a unique choice of <span class="math inline">\(M(x,y)\)</span> and <span class="math inline">\(N(x,y)\)</span> as only their ratio determines the ODE, so there is a freedom to multiply both <span class="math inline">\(M\)</span> and <span class="math inline">\(N\)</span> by the same arbitrary function.<br />
For any function <span class="math inline">\(g(x,y)\)</span> the <span><strong>total differential</strong></span> <span class="math inline">\(dg\)</span> is defined to be <span class="math display">\[dg=\frac{\partial g}{\partial x}\,dx+\frac{\partial g}{\partial y}\,dy.\]</span> You may think of <span class="math inline">\(dg\)</span> as the small change in the function <span class="math inline">\(g\)</span> that arises in moving from the point <span class="math inline">\((x,y)\)</span> to <span class="math inline">\((x+dx,y+dy)\)</span> where <span class="math inline">\(dx\)</span> and <span class="math inline">\(dy\)</span> are both small. In particular, if <span class="math inline">\(dg\)</span> is identically zero then <span class="math inline">\(g\)</span> is a constant.<br />
The ODE <span class="math inline">\((\star\star)\)</span> is called <span><strong>exact</strong></span> if there exists a function <span class="math inline">\(g(x,y)\)</span> such that the left hand side of <span class="math inline">\((\star\star)\)</span> is equal to the total derivative <span class="math inline">\(dg\)</span> ie. <span class="math display">\[M=\frac{\partial g}{\partial x} \quad \mbox{and} \quad
N=\frac{\partial g}{\partial y}.\]</span> In this case the ODE says that <span class="math inline">\(dg=0\)</span> hence <span class="math inline">\(g=constant\)</span> and this yields the solution of the ODE.<br />
The equality of the mixed partial derivatives <span class="math inline">\(\frac{\partial^2 g}{\partial y\partial x}= 
\frac{\partial^2 g}{\partial x\partial y}\)</span> requires that an exact equation satisfies <span class="math inline">\(\frac{\partial M}{\partial y}=\frac{\partial N}{\partial x}.\)</span></p>
<p>This results in the following <span><strong>test for exactness</strong></span> <span class="math display">\[\mbox{The ODE}  \quad
M(x,y)\,dx+N(x,y)\,dy=0 \quad \mbox{is exact iff} \quad
\frac{\partial M}{\partial y}=\frac{\partial N}{\partial x}.\]</span></p>
<p>Eg.Show that <span class="math inline">\((3e^{3x}y+e^x)\,dx+(e^{3x}+1)\,dy=0\)</span> is an exact equation and hence solve it.</p>
<p>In this example <span class="math inline">\(M=3e^{3x}y+e^x\)</span> and <span class="math inline">\(N=e^{3x}+1.\)</span></p>
<p><span class="math inline">\(\frac{\partial M}{\partial y}=3e^{3x}=\frac{\partial N}{\partial x}\)</span> hence this equation is exact.</p>
<p><span class="math display">\[\mbox{From} \ M=\frac{\partial g}{\partial x}\ \mbox{we have} \
\frac{\partial g}{\partial x}=3e^{3x}y+e^x \quad \mbox{giving } \
g=e^{3x}y+e^x+\phi(y)\]</span> where the usual constant of integration is replaced by an arbitrary function of integration <span class="math inline">\(\phi(y)\)</span> because of the partial differentiation. To determine this function we use <span class="math display">\[\frac{\partial g}{\partial y}=N, \quad
\frac{\partial g}{\partial y}=e^{3x}+1=e^{3x}+\phi&#39;,
\quad \mbox{so} \ \phi&#39;=1, \ \mbox{giving} \ \phi=y.\]</span> <span class="math display">\[\mbox{Finally we have that}\quad
g=e^{3x}y+e^x+y=\mbox{constant}=c.\]</span> In this case we can write the solution in explicit form <span class="math inline">\(y={(c-e^x)}/{(e^{3x}+1)}.\)</span></p>
<p>As an exercise check that this does indeed solve the starting ODE</p>
<p><span class="math inline">\(y&#39;=-(3e^{3x}y+e^x)/(e^{3x}+1).\)</span> Note that this example is also a linear ODE so could also have been solved using an integrating factor.<br />
Consider an ODE <span class="math inline">\(M\,dx+N\,dy=0\)</span> that is not exact ie. <span class="math inline">\(\frac{\partial M}{\partial y}\ne\frac{\partial N}{\partial x}.\)</span></p>
<p>By multiplying the ODE by a function <span class="math inline">\(I(x,y)\)</span> we can get an equivalent representation of the ODE as <span class="math inline">\(m\,dx+n\,dy=0\)</span> where <span class="math inline">\(m=MI\)</span> and <span class="math inline">\(n=NI.\)</span> If this equation is exact ie. <span class="math inline">\(\frac{\partial m}{\partial y}=\frac{\partial n}{\partial x}\)</span> then <span class="math inline">\(I\)</span> is called an <span><strong>integrating factor</strong></span> for the original ODE.<br />
Eg. Show that <span class="math inline">\(x\)</span> is an integrating factor for <span class="math inline">\((3xy-y^2)\,dx+x(x-y)\, dy=0.\)</span></p>
<p><span class="math inline">\(M=3xy-y^2\)</span>  so  <span class="math inline">\(\frac{\partial M}{\partial y}=3x-2y,\)</span> but <span class="math inline">\(N=x^2-xy\)</span>  so  <span class="math inline">\(\frac{\partial N}{\partial x}=2x-y.\)</span></p>
<p>Therefore  <span class="math inline">\(\frac{\partial M}{\partial y}\ne \frac{\partial N}{\partial x}\)</span> and the ODE is not exact.</p>
<p>However, with the integrating factor <span class="math inline">\(I=x\)</span> we get <span class="math inline">\(m=MI=3x^2y-y^2x\)</span> and <span class="math inline">\(n=NI=x^3-x^2y\)</span> so now <span class="math inline">\(\frac{\partial m}{\partial y}=3x^2-2yx=
 \frac{\partial n}{\partial x}\)</span> which is exact.</p>
<p>We can now solve this exact equation using the above method.</p>
<p><span class="math inline">\(\frac{\partial g}{\partial x}=m=3x^2y-y^2x\)</span>  giving <span class="math inline">\(g=x^3y-\frac{1}{2}y^2x^2+\phi(y).\)</span></p>
<p><span class="math inline">\(\frac{\partial g}{\partial y}=n=x^3-x^2y=x^3-x^2y+\phi&#39;\)</span> so  <span class="math inline">\(\phi&#39;=0\)</span> and we can take <span class="math inline">\(\phi=0.\)</span></p>
<p>This gives the final solution <span class="math inline">\(g=\mbox{constant}=c\)</span>  ie.  <span class="math inline">\(x^3y-\frac{1}{2}y^2x^2=c.\)</span></p>
</section>
<section id="bernoulli-equations" class="level2" data-number="6.5">
<h2 data-number="6.5"><span class="header-section-number">6.5</span> Bernoulli equations</h2>
<p>A <span><strong>Bernoulli equation</strong></span> is a nonlinear ODE of the form <span class="math display">\[y&#39;+p(x)y=q(x)y^n\]</span> where <span class="math inline">\(n\ne 0,1,\)</span> otherwise the equation is simply linear.<br />
These ODEs can be solved by first performing the substitution <span class="math inline">\(v=y^{1-n}\)</span>, which converts the equation to a linear ODE for <span class="math inline">\(v(x)\)</span>.<br />
Eg. Solve <span class="math display">\[y&#39;-\frac{2y}{x}=-x^2y^2.\]</span></p>
<p>This is a Bernoulli equation with <span class="math inline">\(n=2\)</span> hence put <span class="math inline">\(v=\frac{1}{y},\)</span>  which gives <span class="math inline">\(v&#39;=-\frac{y&#39;}{y^2}.\)</span></p>
<p>Dividing the ODE by <span class="math inline">\(y^2\)</span> yields <span class="math display">\[\frac{y&#39;}{y^2}-\frac{2}{xy}=-x^2\]</span> which in terms of <span class="math inline">\(v\)</span> is <span class="math display">\[-v&#39;-\frac{2v}{x}=-x^2\]</span>  ie  the linear equation <span class="math display">\[v&#39;+\frac{2}{x}v=x^2.\]</span> We solve this with an integrating factor <span class="math inline">\(I=\exp\bigg(\int \frac{2}{x}\, dx\bigg)=\exp(2\log x)=x^2\)</span> as <span class="math display">\[v=\frac{1}{x^2}\int x^2 x^2\, dx
=\frac{1}{x^2}\bigg(\frac{1}{5}x^5+\frac{c}{5}\bigg).\]</span> So finally <span class="math display">\[y=\frac{1}{v}=\frac{5x^2}{x^5+c}.\]</span></p>
</section>
<section id="summary-first-order-odes" class="level2" data-number="6.6">
<h2 data-number="6.6"><span class="header-section-number">6.6</span> Summary: First order ODEs</h2>
<p>You should have a good understanding of how to solve the various types of first order ODEs we covered. We assume a first order ODE can be written in the form <span class="math inline">\(\frac{dy}{dx} = f(x,y)\)</span>. Here are some key points:</p>
<ul>
<li><p>The <span><em>general solution</em></span> to a first order ODE will have 1 free real parameter which we can call the integration constant. If we are given an <span><em>initial condition</em></span> determining the value of <span class="math inline">\(y\)</span> for some specific value of <span class="math inline">\(x\)</span> then we can fix this integration constant.</p></li>
<li><p>Often when solving an ODE we will get an <span><em>implicit solution</em></span>, i.e. and algebraic expression involving <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. If it is reasonably straightforward to do so, solve this to write an <span><em>explicit solution</em></span>, i.e. an explicit expression for <span class="math inline">\(y(x)\)</span> as a function of <span class="math inline">\(x\)</span>.</p></li>
<li><p>If <span class="math inline">\(f(x,y) = X(x)Y(y)\)</span> the ODE is <span><em>separable</em></span>. Solve by separating the <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> dependence and integrating: <span class="math inline">\(\int \frac{dy}{Y} = \int X dx\)</span>.</p></li>
<li><p>If <span class="math inline">\(f(tx, ty) = f(x,y)\)</span> for all <span class="math inline">\(x, y, t \in \mathbb{R}\)</span> then the ODE is <span><em>first order homogeneous</em></span>. Solve by substituting <span class="math inline">\(v = y/x\)</span> for <span class="math inline">\(y\)</span> and the OPE will become separable in variables <span class="math inline">\(x\)</span> and <span class="math inline">\(v\)</span>. Remember to substitute back after solving to give the solution for the original variable <span class="math inline">\(y\)</span>.</p></li>
<li><p>If <span class="math inline">\(f(x,y) = -p(x)y + q(x)\)</span>, i.e. if <span class="math inline">\(f(x,y)\)</span> is linear in <span class="math inline">\(y\)</span>, we have a <span><em>linear first order ODE</em></span> which can be written as <span class="math inline">\(y + py&#39; = q\)</span>. We can solve by multiplying both sides by an <span><em>integrating factor</em></span> <span class="math inline">\(I = \exp(\int p(x) dx)\)</span> so that the LHS becomes the total derivative <span class="math inline">\((Iy)&#39;\)</span> and we then solve by integrating the RHS <span class="math inline">\(Iq\)</span>.</p></li>
<li><p>A <span><em>Bernoulli equation</em></span> is a first order ODE of the form <span class="math inline">\(y + p(x) y&#39; = q(x) y^n\)</span> with any <span class="math inline">\(n \in \mathbb{R}\ \{0, 1\}\)</span> where we exclude those values of <span class="math inline">\(n\)</span> for which this is just a linear ODE. We solve by dividing bot sides by <span class="math inline">\(y^n\)</span> and substituting <span class="math inline">\(v = y^{1-n}\)</span> which results in a first order linear ODE for <span class="math inline">\(v(x)\)</span>.</p></li>
<li><p>A first order <span><em>exact ODE</em></span> is one of the form <span class="math inline">\(M(x,y) dx + N(x,y) dy = 0\)</span> with <span class="math inline">\(\frac{\partial M}{\partial y} = \frac{\partial N}{\partial x}\)</span> which means we can write <span class="math inline">\(M = \frac{\partial g}{\partial x}\)</span> and <span class="math inline">\(N = \frac{\partial g}{\partial y}\)</span> for such function <span class="math inline">\(g(x,y)\)</span>. The ODE is then simply <span class="math inline">\(dg = 0\)</span> which means that <span class="math inline">\(g(x,y) = c\)</span> for some <span class="math inline">\(c \in \mathbb{R}\)</span>. To find <span class="math inline">\(g\)</span> either integrate <span class="math inline">\(M\)</span> wrt. <span class="math inline">\(x\)</span> while treating <span class="math inline">\(y\)</span> as a constant or integrate <span class="math inline">\(N\)</span> wrt. <span class="math inline">\(y\)</span> while treating <span class="math inline">\(x\)</span> as a constant. The integration will give <span class="math inline">\(g(x,y)\)</span> up to an integration ‘constant’ which is an arbitrary function of <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> respectively (since these were treated as constants in the integration). Fix this integration ‘constant’ up to a real constant by substituting the expression for <span class="math inline">\(g\)</span> into the other equation, <span class="math inline">\(N = \frac{\partial g}{\partial y}\)</span> or <span class="math inline">\(M = \frac{\partial g}{\partial x}\)</span> respectively.</p></li>
<li><p>We can write a first order ODE in the form <span class="math inline">\(M(x,y) dx + N(x,y) dy = 0\)</span> in infinitely many ways since we can multiply through by any function <span class="math inline">\(I(x,y)\)</span>. In general this will not be an exact ODE but it can be for specific <span><em>integrating factors</em></span> <span class="math inline">\(I(x,y)\)</span>. Unfortunately there is no general method to finding these integrating factors (unlike the integrating factor for linear ODEs). There are some methods which work in some cases, but we did not cover that this term, so you just need to know the concept.</p></li>
</ul>
</section>
</section>
<section id="second-order-differential-equations" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Second order differential equations</h1>
<section id="linear-constant-coefficient-homogeneous-odes" class="level2" data-number="7.1">
<h2 data-number="7.1"><span class="header-section-number">7.1</span> Linear constant coefficient homogeneous ODEs</h2>
<p>The general form of a second order linear constant coefficient ODE is <span class="math display">\[\alpha_2y&#39;&#39;+\alpha_1y&#39;+\alpha_0 y=\phi(x) \hskip 3cm (\dagger)\]</span> where <span class="math inline">\(\alpha_2\ne 0,\alpha_1,\alpha_0\)</span> are constants (the constant coefficients) and <span class="math inline">\(\phi(x)\)</span> is an arbitrary function of <span class="math inline">\(x.\)</span> The ODE is still second order and linear if these constants are replaced by functions of <span class="math inline">\(x,\)</span> but then the ODE is not so easy to solve.<br />
We first restrict to the case <span class="math inline">\(\phi(x)=0\)</span>  ie. <span class="math display">\[\alpha_2y&#39;&#39;+\alpha_1y&#39;+\alpha_0 y=0
\hskip 3cm (\dagger\dagger)\]</span> in which case the second order ODE is called <span><strong>homogeneous</strong></span>.<br />
The first point to note is that if <span class="math inline">\(y_1\)</span> and <span class="math inline">\(y_2\)</span> are any two solutions of the homogeneous ODE <span class="math inline">\((\dagger\dagger)\)</span> then so is any arbitrary linear combination</p>
<p><span class="math inline">\(y=Ay_1+By_2,\)</span> where <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are constants.</p>
<p>Proof: <span class="math inline">\(y=Ay_1+By_2\)</span>  so  <span class="math inline">\(y&#39;=Ay&#39;_1+By&#39;_2\)</span>  and  <span class="math inline">\(y&#39;&#39;=Ay&#39;&#39;_1+By&#39;&#39;_2.\)</span>  Hence</p>
<p><span class="math inline">\(\alpha_2y&#39;&#39;+\alpha_1y&#39;+\alpha_0 y=
\alpha_2(Ay&#39;&#39;_1+By&#39;&#39;_2)+\alpha_1(Ay&#39;_1+By&#39;_2)+\alpha_0 (Ay_1+By_2)=\)</span></p>
<p><span class="math inline">\(=A(\alpha_2y_1&#39;&#39;+\alpha_1y_1&#39;+\alpha_0 y_1)
+B(\alpha_2y_2&#39;&#39;+\alpha_1y_2&#39;+\alpha_0 y_2)=0+0=0.\)</span></p>
<p>Note that the linearity of the ODE is crucial for this result.<br />
The general solution of the ODE <span class="math inline">\((\dagger\dagger)\)</span> contains two arbitrary constants (because the ODE is second order). If <span class="math inline">\(y_1\)</span> and <span class="math inline">\(y_2\)</span> are any two independent particular solutions then the general solution is given by <span class="math inline">\(y=Ay_1+By_2,\)</span> with <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> the two arbitrary constants. The task is therefore to find two independent particular solutions.<br />
To find a particular solution, look for one in the form <span class="math inline">\(y=e^{\lambda x}.\)</span></p>
<p>Putting this into <span class="math inline">\((\dagger\dagger)\)</span> yields the <span><strong>characteristic</strong></span> (or <span><strong>auxiliary</strong></span>) <span><strong>equation</strong></span> <span class="math display">\[\alpha_2\lambda^2+\alpha_1\lambda+\alpha_0=0. \hskip 3cm (Char)\]</span> There are 3 cases to consider, depending upon the type of roots of <span class="math inline">\((Char)\)</span>.<br />
<span><em>(i). Distinct real roots.</em></span></p>
<p>If <span class="math inline">\((Char)\)</span> has real roots <span class="math inline">\(\lambda_1\ne\lambda_2\)</span> then <span class="math inline">\(y_1=e^{\lambda_1 x}\)</span> and <span class="math inline">\(y_2=e^{\lambda_2 x}\)</span> are the two required particular solutions and the general solution is <span class="math display">\[y=Ae^{\lambda_1 x}+Be^{\lambda_2 x}.\]</span>  </p>
<p>Eg. Solve  <span class="math inline">\(y&#39;&#39;-y&#39;-2y=0.\)</span> Then <span class="math inline">\((Char)\)</span> is <span class="math inline">\(\lambda^2-\lambda-2=0=(\lambda-2)(\lambda+1)\)</span> with roots <span class="math inline">\(\lambda=2,-1.\)</span> The general solution is <span class="math inline">\(y=Ae^{2 x}+Be^{-x}.\)</span><br />
<span><em>(ii). Repeated real root.</em></span></p>
<p><span class="math inline">\((Char)\)</span> has a repeated real root if <span class="math inline">\(\alpha_1^2=4\alpha_0\alpha_2\)</span> ie. when <span class="math inline">\(\alpha_0=\frac{\alpha_1^2}{4\alpha_2}.\)</span></p>
<p><span class="math inline">\((Char)\)</span> then reduces to <span class="math display">\[\alpha_2\lambda^2+\alpha_1\lambda+\frac{\alpha_1^2}{4\alpha_2}=0
=\alpha_2\bigg(\lambda+\frac{\alpha_1}{2\alpha_2}\bigg)^2
\quad \mbox{with } \ \lambda_1=-\frac{\alpha_1}{2\alpha_2} \
\mbox{the real double root.}\]</span> Thus <span class="math inline">\((Char)\)</span> has produced only one solution <span class="math inline">\(y_1=e^{\lambda_1 x}.\)</span></p>
<p>However, as we now show, <span class="math inline">\(y=xe^{\lambda_1 x}\)</span> is also a solution in this case.</p>
<p>The original ODE <span class="math inline">\((\dagger\dagger)\)</span> now takes the form <span class="math display">\[\alpha_2y&#39;&#39;+\alpha_1y&#39;+\frac{\alpha_1^2}{4\alpha_2}y=0
=\alpha_2(y&#39;&#39;-2\lambda_1y&#39;+\lambda_1^2y).\]</span> With <span class="math inline">\(y=xe^{\lambda_1 x}\)</span> we have <span class="math inline">\(y&#39;=e^{\lambda_1 x}+\lambda_1xe^{\lambda_1 x}\)</span> and <span class="math inline">\(y&#39;&#39;=2\lambda_1e^{\lambda_1 x}+\lambda_1^2xe^{\lambda_1 x}.\)</span> Hence <span class="math display">\[y&#39;&#39;-2\lambda_1y&#39;+\lambda_1^2y=2\lambda_1e^{\lambda_1 x}+\lambda_1^2xe^{\lambda_1 x}
-2\lambda_1(e^{\lambda_1 x}+\lambda_1xe^{\lambda_1 x})
+\lambda_1^2xe^{\lambda_1 x}=0.\]</span>  </p>
<p><span class="math inline">\(y_1=e^{\lambda_1 x}\)</span> and <span class="math inline">\(y_2=xe^{\lambda_1 x}\)</span> are the two required particular solutions and the general solution is <span class="math display">\[y=Ae^{\lambda_1 x}+Bxe^{\lambda_1 x}.\]</span>  </p>
<p>Eg. Solve  <span class="math inline">\(2y&#39;&#39;-12y&#39;+18y=0.\)</span> Then <span class="math inline">\((Char)\)</span> is <span class="math inline">\(2\lambda^2-12\lambda+18=0=2(\lambda-3)^2\)</span> with double root <span class="math inline">\(\lambda=3\)</span> The general solution is <span class="math inline">\(y=Ae^{3 x}+Bxe^{3 x}.\)</span><br />
<span><em>(iii). Complex roots.</em></span></p>
<p>If the roots of <span class="math inline">\((Char)\)</span> are complex then they come in a complex conjugate pair ie. <span class="math inline">\(\lambda_1=\alpha+i\beta\)</span> and <span class="math inline">\(\lambda_2=\alpha-i\beta.\)</span> We therefore have the two solutions <span class="math inline">\(y_1=e^{\lambda_1x}=e^{\alpha x}e^{i\beta x}\)</span> and <span class="math inline">\(y_2=e^{\lambda_2x}=e^{\alpha x}e^{-i\beta x},\)</span> but these are not the solutions we are looking for, since they are complex and we want real solutions. However, we have seen that we can take any linear combination of these solutions (even with complex coefficients) and it will still be a solution. In particular the combinations <span class="math display">\[Y_1=\frac{1}{2}(y_1+y_2)=\frac{1}{2}e^{\alpha x}(e^{i\beta x}+e^{-i\beta x})=
e^{\alpha x}\cos(\beta x)\]</span> <span class="math display">\[Y_2=\frac{1}{2i}(y_1-y_2)=\frac{1}{2i}e^{\alpha x}(e^{i\beta x}-e^{-i\beta x})=
e^{\alpha x}\sin(\beta x)\]</span> are both real and provide the two particular solutions we want.</p>
<p>The general solution is an arbitrary real linear combination of <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> ie. <span class="math display">\[y=Ae^{\alpha x}\cos(\beta x)+Be^{\alpha x}\sin(\beta x)
=e^{\alpha x}(A\cos(\beta x)+B\sin(\beta x))\]</span> with <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> real. Recall that <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are both real and are the real and imaginary parts of the complex root of <span class="math inline">\((Char).\)</span><br />
Eg. Solve  <span class="math inline">\(y&#39;&#39;-6y&#39;+10y=0.\)</span> Then <span class="math inline">\((Char)\)</span> is <span class="math inline">\(\lambda^2-6\lambda+10=0\)</span> with roots <span class="math display">\[\lambda=\frac{6\pm\sqrt{36-40}}{2}=\frac{6\pm 2i}{2}=3\pm i
=\alpha\pm i\beta.\]</span> Hence <span class="math inline">\(\alpha=3\)</span> and <span class="math inline">\(\beta=1\)</span> and the general solution is <span class="math inline">\(y=e^{3x}(A\cos x+B\sin x).\)</span></p>
</section>
<section id="the-method-of-undetermined-coefficients" class="level2" data-number="7.2">
<h2 data-number="7.2"><span class="header-section-number">7.2</span> The method of undetermined coefficients</h2>
<p>We now return to the general inhomogeneous ODE <span class="math display">\[\alpha_2y&#39;&#39;+\alpha_1y&#39;+\alpha_0 y=\phi(x) \hskip 3cm (\dagger)\]</span> where <span class="math inline">\(\phi(x)\)</span> is a function that is not identically zero.<br />
The general solution to <span class="math inline">\((\dagger)\)</span> is obtained as a sum of two parts <span class="math display">\[y=y_{CF}+y_{PI}\]</span> where <span class="math inline">\(y_{CF}\)</span> is called the <span><strong>complementary function</strong></span> and is the general solution of the homogeneous version of the ODE ie. <span class="math inline">\((\dagger\dagger)\)</span> which is obtained by removing the <span class="math inline">\(\phi(x)\)</span> term. This part of the solution contains the two arbitrary constants and we have already seen how to find this.</p>
<p><span class="math inline">\(y_{PI}\)</span> is called the <span><strong>particular integral</strong></span> and is any particular solution of <span class="math inline">\((\dagger).\)</span> We haven’t yet seen any methods to find this. However, before we look at a method, let us first show that the combination <span class="math inline">\(y=y_{CF}+y_{PI}\)</span> is indeed a solution of <span class="math inline">\((\dagger).\)</span> We have that <span class="math inline">\(y&#39;=y&#39;_{CF}+y&#39;_{PI}\)</span> and <span class="math inline">\(y&#39;&#39;=y&#39;&#39;_{CF}+y&#39;&#39;_{PI}\)</span> so put these into the left hand side of <span class="math inline">\((\dagger)\)</span> to get <span class="math display">\[\alpha_2y&#39;&#39;+\alpha_1y&#39;+\alpha_0 y=
\alpha_2(y&#39;&#39;_{CF}+y&#39;&#39;_{PI})+\alpha_1(y&#39;_{CF}+y&#39;_{PI})+\alpha_0(y_{CF}+y_{PI})\]</span> <span class="math display">\[=
\underbrace{\alpha_2y&#39;&#39;_{CF}+\alpha_1y&#39;_{CF}+\alpha_0y_{CF}}_\text{$=0$ \ by \ $(\dagger\dagger)$}
+\underbrace{\alpha_2y&#39;&#39;_{PI}+\alpha_1y&#39;_{PI}+\alpha_0y_{PI}}_\text{$=\phi(x)$ \ by 
$(\dagger)$}
=\phi(x).\]</span> To find a particular integral we shall use the <span><strong>method of undetermined coefficients,</strong></span> which can be applied if <span class="math inline">\(\phi(x)\)</span> takes certain forms such as polynomials, exponentials or trigonometric functions, including sums and products of these. The idea is to try an appropriate form of the solution that contains some unknown constant coefficients which are then determined by explicit calculation and the requirement that the try yields a solution. The table below lists the kind of terms that can be dealt with if they appear in <span class="math inline">\(\phi(x)\)</span> (they can come with any constant coefficients in front) together with the form to try for <span class="math inline">\(y_{PI},\)</span> containing undetermined constant coefficients <span class="math inline">\(a_i.\)</span><br />
</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Term in <span class="math inline">\(\phi(x)\)</span></th>
<th style="text-align: left;">Form to try for <span class="math inline">\(y_{PI}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(e^{\gamma x}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(a_1e^{\gamma x}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(x^n\)</span></td>
<td style="text-align: left;"><span class="math inline">\(a_0+a_1x+...+a_nx^n\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\cos(\gamma x)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(a_1\cos(\gamma x)+a_2\sin(\gamma x)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(\sin(\gamma x)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(a_1\cos(\gamma x)+a_2\sin(\gamma x)\)</span></td>
</tr>
</tbody>
</table>
<p><br />
The motivation for the above is that the form of the try when differentiated zero, once or twice, should have a similar functional form to <span class="math inline">\(\phi(x),\)</span> as there is then a chance that the left hand side of <span class="math inline">\((\dagger)\)</span> could equal the right hand side. If <span class="math inline">\(\phi(x)\)</span> contains sums/products of the kind of terms above then try sums/products of the listed forms for the try.<br />
<span><strong>Special case rule:</strong></span> If the suggested form of the try for <span class="math inline">\(y_{PI}\)</span> is contained in <span class="math inline">\(y_{CF}\)</span> then we know that this form wont work as the left hand side of <span class="math inline">\((\dagger)\)</span> will then be identically zero and so cant equal <span class="math inline">\(\phi(x).\)</span> In this case first multiply the suggested form of the try by <span class="math inline">\(x\)</span> to get the correct try. In some special cases this rule may need to be applied twice as <span class="math inline">\(x\)</span> times the suggested try may also be contained in <span class="math inline">\(y_{CF}.\)</span><br />
<span><em>Eg</em></span>. Solve  <span class="math inline">\(y&#39;&#39;-y&#39;-2y=7-2x^2.\)</span></p>
<p>From earlier we already know that <span class="math inline">\(y_{CF}=Ae^{2 x}+Be^{-x}.\)</span></p>
<p>To find <span class="math inline">\(y_{PI}\)</span> we try the form <span class="math inline">\(y=a_0+a_1x+a_2x^2\)</span></p>
<p>to simplify the notation for the calculation we have dropped the <span class="math inline">\(\,_{PI}\)</span> subscript here.</p>
<p>Now <span class="math inline">\(y&#39;=a_1+2a_2x\)</span> and <span class="math inline">\(y&#39;&#39;=2a_2,\)</span> so putting these into the ODE gives <span class="math inline">\(2a_2-(a_1+2a_2x)-2(a_0+a_1x+a_2x^2)=7-2x^2\)</span></p>
<p><span class="math inline">\(=2a_2-a_1-2a_0+x(-2a_2-2a_1)-2a_2x^2.\)</span></p>
<p>Comparing coefficients of <span class="math inline">\(x^2,x^1,x^0\)</span> gives <span class="math inline">\(-2a_2=-2, \ (a_2=1), \ -2a_2-2a_1=0,\)</span>  <span class="math inline">\(\ (a_1=-1), \
2a_2-a_1-2a_0=7, \ (a_0=-2).\)</span></p>
<p>We have found <span class="math inline">\(y_{PI}=-2-x+x^2\)</span> and the general solution is <span class="math inline">\(y=y_{CF}+y_{PI}\)</span> ie.</p>
<p><span class="math inline">\(y=Ae^{2 x}+Be^{-x}-2-x+x^2.\)</span><br />
<span><em>Eg</em></span>. Solve  <span class="math inline">\(y&#39;&#39;+4y&#39;+4y=5e^{3x}.\)</span></p>
<p>First find <span class="math inline">\(y_{CF}\)</span> by solving <span class="math inline">\(y&#39;&#39;+4y&#39;+4y=0.\)</span></p>
<p><span class="math inline">\((Char)\)</span> is <span class="math inline">\(\lambda^2+4\lambda+4=0=(\lambda+2)^2\)</span> with <span class="math inline">\(\lambda=-2\)</span> repeated,</p>
<p>hence <span class="math inline">\(y_{CF}=e^{-2x}(A+Bx).\)</span></p>
<p>For <span class="math inline">\(y_{PI}\)</span> try <span class="math inline">\(y=a_1e^{3x}\)</span> so <span class="math inline">\(y&#39;=3a_1e^{3x}\)</span> and <span class="math inline">\(y&#39;&#39;=9a_1e^{3x}.\)</span> Put these into the ODE</p>
<p><span class="math inline">\(9a_1e^{3x}+12a_1e^{3x}+4a_1e^{3x}=5e^{3x}=25a_1e^{3x}\)</span> so <span class="math inline">\(a_1=\frac{1}{5}\)</span> giving <span class="math inline">\(y_{PI}=\frac{1}{5}e^{3x}.\)</span></p>
<p>The general solution is <span class="math inline">\(y=y_{CF}+y_{PI}\)</span> ie <span class="math inline">\(y=e^{-2x}(A+Bx)+\frac{1}{5}e^{3x}.\)</span><br />
Eg. Solve  <span class="math inline">\(y&#39;&#39;-2y&#39;+2y=10\cos(2x).\)</span></p>
<p>First find <span class="math inline">\(y_{CF}\)</span> by solving <span class="math inline">\(y&#39;&#39;-2y&#39;+2y=0.\)</span></p>
<p><span class="math inline">\((Char)\)</span> is <span class="math inline">\(\lambda^2-2\lambda+2=0\)</span> with <span class="math inline">\(\lambda=1\pm i.\)</span> Hence <span class="math inline">\(y_{CF}=e^x(A\cos x+B\sin x).\)</span></p>
<p>For <span class="math inline">\(y_{PI}\)</span> try <span class="math inline">\(y=a_1\cos(2x)+a_2\sin(2x)\)</span> so <span class="math inline">\(y&#39;=-2a_1\sin(2x)+2a_2\cos(2x)\)</span> and <span class="math inline">\(y&#39;&#39;=-4a_1\cos(2x)-4a_2\sin(2x).\)</span> Put these into the ODE <span class="math inline">\(y&#39;&#39;-2y&#39;+2y=
-4a_1\cos(2x)-4a_2\sin(2x)-2(-2a_1\sin(2x)+2a_2\cos(2x))
+2(a_1\cos(2x)+a_2\sin(2x))=10\cos(2x)
=
(-2a_1-4a_2)\cos(2x)+(-2a_2+4a_1)\sin(2x).\)</span></p>
<p>Comparing coefficients of <span class="math inline">\(\sin(2x)\)</span> and <span class="math inline">\(\cos(2x)\)</span> gives <span class="math inline">\(-2a_2+4a_1=0, \ (a_2=2a_1), \ -2a_1-4a_2=10, \ -10a_1=10, \ 
(a_1=-1, \ a_2=-2).\)</span></p>
<p>Thus <span class="math inline">\(y_{PI}=-\cos(2x)-2\sin(2x).\)</span></p>
<p>The general solution is <span class="math inline">\(y=e^x(A\cos x+B\sin x)-\cos(2x)-2\sin(2x).\)</span><br />
<span><em>Eg</em></span>. Solve  <span class="math inline">\(y&#39;&#39;-y&#39;-2y=6e^{-x}.\)</span></p>
<p>From earlier we already know that <span class="math inline">\(y_{CF}=Ae^{2 x}+Be^{-x}.\)</span></p>
<p>To find <span class="math inline">\(y_{PI}\)</span> we first think that we should try the form <span class="math inline">\(y=a_1e^{-x}\)</span> but note that this is contained in <span class="math inline">\(y_{CF}\)</span> so instead we try <span class="math inline">\(y=a_1xe^{-x}.\)</span> Then</p>
<p><span class="math inline">\(y&#39;=a_1e^{-x}-a_1xe^{-x}\)</span> and <span class="math inline">\(y&#39;&#39;=-2a_1e^{-x}+a_1xe^{-x}.\)</span> Put into ODE</p>
<p><span class="math inline">\(-2a_1e^{-x}+a_1xe^{-x}-(a_1e^{-x}-a_1xe^{-x})-2a_1xe^{-x}=6e^{-x}
=-3a_1e^{-x}\)</span> so <span class="math inline">\(a_1=-2\)</span> and <span class="math inline">\(y_{PI}=-2xe^{-x}\)</span>.</p>
<p>The general solution is <span class="math inline">\(y=Ae^{2 x}+Be^{-x}-2xe^{-x}.\)</span><br />
Eg. Solve  <span class="math inline">\(y&#39;&#39;-y&#39;-2y=e^x(8\sin(3x)-14\cos(3x)).\)</span></p>
<p>From earlier we already know that <span class="math inline">\(y_{CF}=Ae^{2 x}+Be^{-x}.\)</span></p>
<p>For <span class="math inline">\(y_{PI}\)</span> try <span class="math inline">\(y=e^x(a_1\cos(3x)+a_2\sin(3x)).\)</span></p>
<p>It is an exercise to show that <span class="math inline">\(a_1=1,\ a_2=-1.\)</span></p>
<p>The general solution is then <span class="math inline">\(y=Ae^{2 x}+Be^{-x}
+e^x(\cos(3x)-\sin(3x)).\)</span><br />
Eg. Solve  <span class="math inline">\(y&#39;&#39;-y&#39;-2y=-5+9x-2x^3+4\cos x+2\sin x.\)</span></p>
<p>From earlier we already know that <span class="math inline">\(y_{CF}=Ae^{2 x}+Be^{-x}.\)</span></p>
<p>For <span class="math inline">\(y_{PI}\)</span> try <span class="math inline">\(y=a_0+a_1x+a_2x^2+a_3x^3+a_4\cos x+a_5\sin x.\)</span></p>
<p>It is an exercise to show that</p>
<p><span class="math inline">\(a_0=1,\ a_1=0,\ a_2=-\frac{3}{2}, \
a_3=1,\ a_4=-1,\ a_5=-1.\)</span></p>
<p>The general solution is then <span class="math inline">\(y=Ae^{2 x}+Be^{-x}
+1-\frac{3}{2}x^2+x^3-\cos x-\sin x.\)</span><br />
</p>
</section>
<section id="initial-and-boundary-value-problems" class="level2" data-number="7.3">
<h2 data-number="7.3"><span class="header-section-number">7.3</span> Initial and boundary value problems</h2>
<p>The values of the two arbitrary constants in the general solution of a second order ODE are fixed by specifying two extra requirements on the solution and/or its derivative.<br />
An <span><strong>initial value problem</strong></span> (IVP) is when we require <span class="math inline">\(y(x_0)=y_0\)</span> and <span class="math inline">\(y&#39;(x_0)=\delta\)</span> for given constants <span class="math inline">\(x_0,y_0,\delta.\)</span> In this case the two constraints are given at the same value of the independent variable.<br />
A <span><strong>boundary value problem</strong></span> (BVP) is when we require <span class="math inline">\(y(x_0)=y_0\)</span> and <span class="math inline">\(y(x_1)=y_1\)</span> for given constants <span class="math inline">\(x_0\ne x_1,y_0,y_1.\)</span> In this case the two constraints are given at two different values of the independent variable.<br />
The way to solve an IVP or BVP is to first find the general solution of the ODE and then determine the values of the two constants in this solution so that the extra conditions are satisfied.<br />
Eg. Solve the IVP <span class="math inline">\(y&#39;&#39;-y&#39;-2y=7-2x^2, \quad y(0)=5, \ y&#39;(0)=1.\)</span></p>
<p>From earlier we already know that the general solution of the ODE is</p>
<p><span class="math inline">\(y(x)=Ae^{2 x}+Be^{-x}-2-x+x^2.\)</span></p>
<p>Therefore <span class="math inline">\(y(0)=A+B-2=5,\)</span> so  <span class="math inline">\(A+B=7.\)</span></p>
<p>Now <span class="math inline">\(y&#39;(x)=2Ae^{2 x}-Be^{-x}-1+2x,\)</span> giving <span class="math inline">\(y&#39;(0)=2A-B-1=1,\)</span> so <span class="math inline">\(2A-B=2.\)</span></p>
<p>The solution of these two equations for <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> is <span class="math inline">\(A=3, \ B=4.\)</span></p>
<p>Therefore the solution of the IVP is <span class="math inline">\(y=3e^{2 x}+4e^{-x}-2-x+x^2.\)</span><br />
<span><em>Eg</em></span>. Solve the BVP <span class="math inline">\(4y&#39;&#39;+y=0, \quad y(0)=1, \ y(\pi)=2.\)</span></p>
<p><span class="math inline">\((Char)\)</span> is <span class="math inline">\(4\lambda^2+1=0\)</span>  with roots <span class="math inline">\(\lambda=\pm \frac{i}{2}.\)</span></p>
<p>The general solution is <span class="math inline">\(y=A\cos(\frac{x}{2})+B\sin(\frac{x}{2}).\)</span></p>
<p><span class="math inline">\(y(0)=A=1\)</span> and <span class="math inline">\(y(\pi)=B=2.\)</span></p>
<p>Hence the solution of the BVP is <span class="math inline">\(y=\cos(\frac{x}{2})+2\sin(\frac{x}{2}).\)</span><br />
</p>
</section>
<section id="the-method-of-variation-of-parameters" class="level2" data-number="7.4">
<h2 data-number="7.4"><span class="header-section-number">7.4</span> The method of variation of parameters</h2>
<p>So far, the only method we have seen to construct a particular integral is the method of undetermined coefficients. As we have seen, this method only applies if the inhomogeneous term <span class="math inline">\(\phi\)</span> takes particular forms. In this section we consider a more general method to find a particular integral, known as the method of variation of parameters.<br />
<span><strong>Defn.</strong></span> Given two differentiable functions, <span class="math inline">\(y_1(x),y_2(x),\)</span> we define the <span><strong>Wronskian</strong></span> to be <span class="math display">\[W(y_1,y_2)=\bigg|\begin{matrix} y_1 &amp; y_2 \\ y_1&#39; &amp; y_2&#39;\end{matrix}\bigg|
=y_1y_2&#39;-y_2y_1&#39;.\]</span> It is obvious that if <span class="math inline">\(y_1\)</span> and <span class="math inline">\(y_2\)</span> are linearly dependent then <span class="math inline">\(W(y_1,y_2)\)</span> is identically zero, that is, zero for all <span class="math inline">\(x.\)</span> Therefore, if <span class="math inline">\(W(y_1,y_2)\)</span> is not identically zero then this implies that <span class="math inline">\(y_1\)</span> and <span class="math inline">\(y_2\)</span> are linearly independent.<br />
The task at hand is to find a particular integral for the inhomogeneous ODE <span class="math inline">\((\dagger)\)</span>, <span class="math display">\[\alpha_2y&#39;&#39;+\alpha_1y&#39;+\alpha_0 y=\phi.\]</span> The starting point is to consider the two linearly independent solutions <span class="math inline">\(y_1,y_2\)</span> of the homogeneous version of the ODE <span class="math inline">\((\dagger\dagger)\)</span>. In other words <span class="math inline">\(y_{CF}=Ay_1+By_2.\)</span></p>
<p>The method of variation of parameters is to look for a particular integral by replacing the constants in <span class="math inline">\(y_{CF}\)</span> by functions. Namely, a solution to <span class="math inline">\((\dagger)\)</span> is sought in the form <span class="math display">\[y=u_1y_1+u_2y_2\]</span> for functions <span class="math inline">\(u_1(x),u_2(x).\)</span> Given this form then <span class="math display">\[y&#39;=u_1&#39;y_1+u_2&#39;y_2+u_1y_1&#39;+u_2y_2&#39;.\]</span> The form we have chosen has two arbitrary functions and the ODE will only give one relation, hence we need to impose a second condition. This condition is chosen to be <span class="math display">\[u_1&#39;y_1+u_2&#39;y_2=0\]</span> so that the derivative now simplifies to <span class="math display">\[y&#39;=u_1y_1&#39;+u_2y_2&#39;.\]</span> Differentiating once more gives <span class="math display">\[y&#39;&#39;=u_1&#39;y_1&#39;+u_2&#39;y_2&#39;+u_1y_1&#39;&#39;+u_2y_2&#39;&#39;.\]</span> Putting these expressions into <span class="math inline">\((\dagger)\)</span> yields <span class="math display">\[\alpha_2(u_1&#39;y_1&#39;+u_2&#39;y_2&#39;+u_1y_1&#39;&#39;+u_2y_2&#39;&#39;)+\alpha_1(u_1y_1&#39;+u_2y_2&#39;)
+\alpha_0(u_1y_1+u_2y_2)=\phi.\]</span> Using the fact that both <span class="math inline">\(y_1\)</span> and <span class="math inline">\(y_2\)</span> solve <span class="math inline">\((\dagger\dagger)\)</span> simplifies the above equation to <span class="math display">\[\alpha_2(u_1&#39;y_1&#39;+u_2&#39;y_2&#39;)=\phi.\]</span> We now have two equations for the two unknown functions <span class="math inline">\(u_1&#39;,u_2&#39;\)</span> and this gives <span class="math display">\[u_1&#39;=-\frac{y_2\phi/\alpha_2}{W(y_1,y_2)},
\qquad \qquad
u_2&#39;=\frac{y_1\phi/\alpha_2}{W(y_1,y_2)},\]</span> which are solved by direct integration <span class="math display">\[u_1=-\int \frac{y_2\phi/\alpha_2}{W(y_1,y_2)}\,dx,
\qquad \qquad
u_2=\int\frac{y_1\phi/\alpha_2}{W(y_1,y_2)}\,dx.\]</span></p>
<p>As a simple first example, we will apply the method of variation of parameters to find a particular integral that could also be found using the method of undetermined coefficients.<br />
Eg. Solve <span class="math inline">\(y&#39;&#39;-y=e^{2x}.\)</span></p>
<p>We have that <span class="math inline">\(y_{CF}=Ae^x+Be^{-x}\)</span> hence <span class="math inline">\(y_1=e^x\)</span> and <span class="math inline">\(y_2=e^{-x}.\)</span></p>
<p><span class="math display">\[W(y_1,y_2)=\bigg|\begin{matrix} e^{x} &amp; e^{-x} \\ e^{x} &amp; -e^{-x}\end{matrix}\bigg|=-2.\]</span> Using the above formulae <span class="math display">\[u_1=-\int \frac{e^{-x}e^{2x}}{-2}\,dx=\int \frac{1}{2}e^x\,dx=\frac{1}{2}e^x.\]</span> <span class="math display">\[u_2=\int \frac{e^{x}e^{2x}}{-2}\,dx=\int \frac{-1}{2}e^{3x}\,dx=-\frac{1}{6}e^{3x}.\]</span> <span class="math display">\[y_{PI}=u_1y_1+u_2y_2=\frac{1}{2}e^{x}e^x-\frac{1}{6}e^{3x}e^{-x}=\frac{1}{3}e^{2x}.\]</span> <span class="math display">\[y=y_{CF}+y_{PI}=Ae^x+Be^{-x}+\frac{1}{3}e^{2x}.\]</span></p>
<p>Note that if you don’t want to remember the formulae you can simply remember that the key step in the method is to remove the <span class="math inline">\(u_1&#39;,u_2&#39;\)</span> terms from <span class="math inline">\(y&#39;.\)</span></p>
<p>Here is the same problem solved via this slightly longer way of proceeding.<br />
<span class="math inline">\(y=u_1e^x+u_2e^{-x}\)</span> hence <span class="math inline">\(y&#39;=[u_1&#39;e^x+u_2&#39;e^{-x}]+u_1e^x-u_2e^{-x}\)</span><br />
we set <span class="math inline">\([u_1&#39;e^x+u_2&#39;e^{-x}]=0\)</span> and differentiate <span class="math inline">\(y&#39;\)</span> again to get <span class="math inline">\(y&#39;&#39;=u_1&#39;e^x-u_2&#39;e^{-x}+u_1e^x+u_2e^{-x}.\)</span><br />
Putting all the expressions into the ODE gives <span class="math inline">\(u_1&#39;e^x-u_2&#39;e^{-x}=e^{2x}.\)</span></p>
<p>Adding and subtracting the two equations <span class="math inline">\(u_1&#39;e^x+u_2&#39;e^{-x}=0\)</span> and <span class="math inline">\(u_1&#39;e^x-u_2&#39;e^{-x}=e^{2x}\)</span>  yields</p>
<p><span class="math inline">\(u_1&#39;=\frac{1}{2}e^x\)</span> and <span class="math inline">\(u_2&#39;=-\frac{1}{2}e^{3x}\)</span>, which are the same expressions as found above using the formulae.<br />
Here is an example that needs the method of variation of parameters as the method of undetermined coefficients is inapplicable.<br />
Eg. Solve <span class="math display">\[y&#39;&#39;-2y&#39;+y=\frac{e^x}{x^2+1}.\]</span> CF: (CHAR) <span class="math inline">\(\lambda^2-2\lambda+1=0=(\lambda-1)^2, \ y_{CF}=(A+Bx)e^x.\)</span><br />
<span class="math inline">\(y_1=e^x, \ y_2=xe^x,\)</span> with <span class="math inline">\(W(y_1,y_2)=y_1y_2&#39;-y_2y_1&#39;=e^{2x}\)</span> <span class="math display">\[u_1=-\int \frac{e^x}{x^2+1}\frac{xe^x}{e^{2x}}\, dx
=-\int \frac{x}{x^2+1}\,dx
=-\frac{1}{2}\log(x^2+1)\]</span> <span class="math display">\[u_2=\int \frac{e^x}{x^2+1}\frac{e^x}{e^{2x}}\, dx
=\int \frac{1}{x^2+1}\,dx
=\tan^{-1}x\]</span> <span class="math inline">\(y_{PI}=-\frac{1}{2}e^x\log(x^2+1)+xe^x\tan^{-1}x\)</span><br />
<span class="math inline">\(y=y_{CF}+y_{PI}=(A+Bx)e^x-\frac{1}{2}e^x\log(x^2+1)+xe^x\tan^{-1}x\)</span><br />
</p>
</section>
<section id="systems-of-first-order-linear-odes" class="level2" data-number="7.5">
<h2 data-number="7.5"><span class="header-section-number">7.5</span> Systems of first order linear ODEs</h2>
<p>A system of <span class="math inline">\(n\)</span> coupled first order linear ODEs for <span class="math inline">\(n\)</span> dependent variables can be written as a single <span class="math inline">\(n^{th}\)</span> order linear ODE for a single dependent variable by eliminating the other dependent variables. An associated IVP is obtained if all the values of the dependent variables are specified at a single value of the independent variable.<br />
Eg. Find the solution <span class="math inline">\(y(x),z(x)\)</span> of the pair of first order linear ODEs</p>
<p> <span class="math inline">\(y&#39;=-y+z+x^2, \quad z&#39;=-8y+5z+8x^2-7x+1,\)</span>  </p>
<p>satisfying the initial condition <span class="math inline">\(y(0)=2,\ z(0)=0.\)</span><br />
We solve by first finding a second order ODE for <span class="math inline">\(y(x).\)</span></p>
<p>From the first equation  <span class="math inline">\(z=y&#39;+y-x^2\)</span>  hence <span class="math inline">\(z&#39;=y&#39;&#39;+y&#39;-2x.\)</span></p>
<p>Substituting these expressions into the second equation gives</p>
<p><span class="math inline">\(y&#39;&#39;+y&#39;-2x=-8y+5(y&#39;+y-x^2)+8x^2-7x+1\)</span></p>
<p>ie. the second order ODE <span class="math inline">\(y&#39;&#39;-4y&#39;+3y=3x^2-5x+1\)</span></p>
<p>We can now solve this ODE using our earlier methods.</p>
<p><span class="math inline">\((Char)\)</span> is <span class="math inline">\(\lambda^2-4\lambda+3=0=(\lambda-3)(\lambda-1)\)</span>  with roots  <span class="math inline">\(\lambda=1,3.\)</span> Hence <span class="math inline">\(y_{CF}=Ae^x+Be^{3x}\)</span></p>
<p>For <span class="math inline">\(y_{PI}\)</span> try <span class="math inline">\(y=a_0+a_1x+a_2x^2\)</span> to give</p>
<p><span class="math inline">\(y&#39;&#39;-4y&#39;+3y=2a_2-4(a_1+2a_2x)+3(a_0+a_1x+a_2x^2)=3a_2x^2+(3a_1-8a_2)x+2a_2-4a_1+3a_0=3x^2-5x+1\)</span></p>
<p>Comparing coefficients gives the solution <span class="math inline">\(a_2=1, \ a_1=1, \ a_0=1.\)</span></p>
<p>The general solution for <span class="math inline">\(y\)</span> is therefore <span class="math inline">\(y=Ae^x+Be^{3x}+x^2+x+1\)</span></p>
<p>To obtain <span class="math inline">\(z\)</span> we use the earlier relation <span class="math inline">\(z=y&#39;+y-x^2=2Ae^x+4Be^{3x}+3x+2.\)</span></p>
<p>We now have the general solution for both <span class="math inline">\(y\)</span> and <span class="math inline">\(z\)</span>.</p>
<p>From the general solution  <span class="math inline">\(y(0)=A+B+1=2\)</span>  and <span class="math inline">\(z(0)=2A+4B+2=0\)</span> with solution <span class="math inline">\(A=3,\ B=-2.\)</span></p>
<p>Hence the solution of the IVP is <span class="math inline">\(y=3e^x-2e^{3x}+x^2+x+1,\)</span> <span class="math inline">\(z=6e^x-8e^{3x}+3x+2.\)</span><br />
</p>
</section>
<section id="summary-second-order-odes" class="level2" data-number="7.6">
<h2 data-number="7.6"><span class="header-section-number">7.6</span> Summary: Second order ODEs</h2>
<p>You should have a good understanding of how to solve linear constant-coefficient second order ODEs which can be written as <span class="math inline">\(\alpha_2 y&#39;&#39; + \alpha_1 y&#39; + \alpha_0 y = \phi(x)\)</span>. Here are some key points:</p>
<ul>
<li><p>Second order ODEs will have two parameters (integration constants) in the general solution. These can be fixed with <span><em>initial conditions</em></span> (fixing the value of <span class="math inline">\(y\)</span> and <span class="math inline">\(y&#39;\)</span> at the same point) or <span><em>boundary conditions</em></span> (fixing the value of <span class="math inline">\(y\)</span> at two different points). Initial conditions will uniquely fix the integration constants. Boundary conditions will typically uniquely fix the integration constants but it is possible that there could be no solution or a one-parameter family of solutions – e.g. consider <span class="math inline">\(y&#39;&#39; + y = 0\)</span> with <span class="math inline">\(y(0) = 0\)</span> (which gives <span class="math inline">\(y = A \sin x\)</span>) and the other boundary condition being <span class="math inline">\(y(\pi/2) = 1\)</span> (1 solution) or <span class="math inline">\(y(\pi) = 1\)</span> (no solutions) or <span class="math inline">\(y(\pi) = 0\)</span> (one-parameter family of solutions).</p></li>
<li><p>If <span class="math inline">\(\phi\)</span> is zero we have a <span><em>homogeneous second order ODE</em></span>. We solve this by first solving the <span><em>Characteristic Equation</em></span> (CE) <span class="math inline">\(\alpha_2 \lambda^2 + \alpha_1 \lambda + \alpha_0 = 0\)</span>.</p></li>
<li><p>If the CE has two real solutions <span class="math inline">\(\lambda_1 \ne \lambda_2\)</span> then the ODE has general solution <span class="math inline">\(y = Ae^{\lambda_1 x} + Be^{\lambda_2 x}\)</span>.</p></li>
<li><p>If the CE has only one solution <span class="math inline">\(\lambda_1\)</span> (repeated roots) then the ODE has general solution <span class="math inline">\(y = Ae^{\lambda_1 x} + Bxe^{\lambda_1 x}\)</span>.</p></li>
<li><p>If the CE has two complex solutions <span class="math inline">\(\alpha + i\beta\)</span> and <span class="math inline">\(\alpha - i\beta\)</span> then the ODE has general solution <span class="math inline">\(y = Ce^{(\alpha + i \beta) x} + De^{(\alpha - i \beta) x} =
^{\alpha x} (A \cos(\beta x) + B \sin(\beta x))\)</span>.</p></li>
<li><p>In all case the general solution of the homogeneous ODE is of the form <span class="math inline">\(y(x) = Ay_1(x) + By_2(x)\)</span> where <span class="math inline">\(y_1(x)\)</span> and <span class="math inline">\(y_2(x)\)</span> are two linearly independent solutions of the ODE.</p></li>
<li><p>The general solution to a linear ODE is <span class="math inline">\(y = y_{CF} + y_{PI}\)</span> where <span class="math inline">\(y_{PI}\)</span> is a <span><em>particular integral</em></span> (PI) which is any solution of the ODE and <span class="math inline">\(y_{CF}\)</span> is the <span><em>complementary function</em></span> (CF) which is the general solution of the homogeneous ODE formed by setting <span class="math inline">\(\phi\)</span> to zero.</p></li>
<li><p>If <span class="math inline">\(\phi(x)\)</span> is formed from sums of products of exponentials <span class="math inline">\(e^{\gamma x}\)</span>, sines and cosines <span class="math inline">\(\sin(\gamma x)\)</span> and <span class="math inline">\(\cos(\gamma x)\)</span>, and polynomials we can find a PI using the <span><em>method of undetermined coefficients</em></span>. To do this we use an ansatz for <span class="math inline">\(y_{PI}\)</span> which is of the same form as <span class="math inline">\(\phi(x)\)</span> with arbitrary coefficients for each term. Then substitute this ansatz into the ODE to solve for the coefficients. Note that if a term solves the homogeneous ODE we need to include an extra factor of <span class="math inline">\(x\)</span> with that term, and another factor of <span class="math inline">\(x\)</span> if that still solves the homogeneous ODE.</p></li>
<li><p>If we cannot use the method of undetermined coefficients, we can try the <span><em>method of variation of parameters</em></span>. If <span class="math inline">\(y_{CF} = Ay_1 + By_2\)</span> we take <span class="math inline">\(y = u_1y_1 + u_2y_2\)</span> where <span class="math inline">\(u_1\)</span> and <span class="math inline">\(u_2\)</span> are functions of <span class="math inline">\(x\)</span> and we impose the constraint <span class="math inline">\(u_1&#39; y_1 + u_2&#39; y_2 = 0\)</span> so that <span class="math inline">\(y&#39;\)</span> does not depend on <span class="math inline">\(u_1&#39;\)</span> or <span class="math inline">\(u_2&#39;\)</span>. Substituting this into the ODE, all terms with <span class="math inline">\(u_1\)</span> and <span class="math inline">\(u_2\)</span> (not differentiated) cancel as they must since constant <span class="math inline">\(u_1\)</span> and <span class="math inline">\(u_2\)</span> would give a solution of the homogeneous ODE – the result is a second linear equation for <span class="math inline">\(u_1&#39;\)</span> and <span class="math inline">\(u_2&#39;\)</span>, <span class="math inline">\(\alpha_2(u_1&#39; y_1&#39; + u_2&#39; y_2&#39;) = \phi\)</span>. Solve these two linear equation to find <span class="math inline">\(u_1&#39;\)</span> and <span class="math inline">\(u_2&#39;\)</span> and then integrate to find <span class="math inline">\(u_1\)</span> and <span class="math inline">\(u_2\)</span> (noting that the integration constants are exactly the parameters in <span class="math inline">\(y_{CF}\)</span>).</p></li>
<li><p>Two coupled first order linear ODEs for two variables give, by eliminating one of the variables, a linear second order ODE for one variable. This gives one method to solve coupled first order ODEs. (We can also go the other way by defining <span class="math inline">\(z\)</span> as a linear combination of <span class="math inline">\(y\)</span> and <span class="math inline">\(y&#39;\)</span> and using this to write a second order linear ODE for <span class="math inline">\(y\)</span> as a first order linear ODE involving <span class="math inline">\(z&#39;\)</span>, <span class="math inline">\(z\)</span> and <span class="math inline">\(y\)</span>.)</p></li>
</ul>
</section>
</section>
<section id="taylor-series" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Taylor series</h1>
<section id="taylors-theorem" class="level2" data-number="8.1">
<h2 data-number="8.1"><span class="header-section-number">8.1</span> Taylor’s theorem</h2>
<p><span><strong>Taylor’s theorem</strong></span> states that if <span class="math inline">\(f(x)\)</span> has <span class="math inline">\(n+1\)</span> continuous derivatives in an open interval <span class="math inline">\(I\)</span> that contains the point <span class="math inline">\(x=a,\)</span> then <span class="math inline">\(\forall\ x\in I\)</span> <span class="math display">\[f(x)=\bigg(\sum_{k=0}^n \frac{f^{(k)}(a)}{k!}(x-a)^k\bigg) \ + R_n(x)\]</span> <span class="math display">\[\mbox{where \ } 
R_n(x)=\frac{1}{n!}\int_a^x(x-t)^nf^{(n+1)}(t)\,dt
\quad \mbox{is called the {\bf remainder}.}\]</span>  </p>
<p>Proof:</p>
<p>Fix <span class="math inline">\(x\in I\)</span> then <span class="math inline">\(\int_a^xf&#39;(t)\,dt=f(x)-f(a),\)</span>  so <span class="math display">\[f(x)=f(a)+\int_a^xf&#39;(t)\,dt.\]</span> If we think of the integrand in the above as  <span class="math inline">\(f&#39;(t)\cdot 1\)</span>  then we can perform an integration by parts where we choose the constant of integration to be <span class="math inline">\(-x\)</span> so that <span class="math inline">\(\int 1\,dt =(t-x).\)</span> This gives <span class="math display">\[\begin{aligned}
f(x)&amp;=&amp;f(a)+\bigg[f&#39;(t)(t-x)\bigg]_a^x-\int_a^xf&#39;&#39;(t)(t-x)\, dt\\
&amp;=&amp;f(a)+f&#39;(a)(x-a)+\int_a^xf&#39;&#39;(t)(x-t)\, dt.\\\end{aligned}\]</span> Note that this proves the theorem for <span class="math inline">\(n=1.\)</span> To prove the theorem for <span class="math inline">\(n=2\)</span> we perform another integration by parts on this equation, <span class="math display">\[\begin{aligned}
f(x)&amp;=&amp;f(a)+f&#39;(a)(x-a)+\int_a^xf&#39;&#39;(t)(x-t)\, dt\\
&amp;=&amp;f(a)+f&#39;(a)(x-a)-\bigg[f&#39;&#39;(t)\frac{(x-t)^2}{2}\bigg]_a^x
+\int_a^xf&#39;&#39;&#39;(t)\frac{(x-t)^2}{2}\, dt\\
&amp;=&amp;f(a)+f&#39;(a)(x-a)+\frac{f&#39;&#39;(a)}{2}(x-a)^2+\int_a^xf&#39;&#39;&#39;(t)\frac{(x-t)^2}{2}.\\\end{aligned}\]</span> This proves the theorem for <span class="math inline">\(n=2.\)</span> Continuing in this way the theorem follows after performing an integration by parts a total of <span class="math inline">\(n\)</span> times. More formally, this can be written in the form of a proof by induction.</p>
</section>
<section id="taylor-polynomials" class="level2" data-number="8.2">
<h2 data-number="8.2"><span class="header-section-number">8.2</span> Taylor polynomials</h2>
<p>The combination <span class="math inline">\(P_n(x)=f(x)-R_n(x)\)</span> is a polynomial in <span class="math inline">\(x\)</span> of degree <span class="math inline">\(n\)</span> called <span><strong>the <span class="math inline">\(n^{th}\)</span> order Taylor polynomial of <span class="math inline">\(f(x)\)</span> about <span class="math inline">\(x=a\)</span></strong></span> <span class="math display">\[P_n(x)=f(a)+f&#39;(a)(x-a)+\frac{f&#39;&#39;(a)}{2!}(x-a)^2+...
+\frac{f^{(n)}(a)}{n!}(x-a)^n.\]</span> If the term ‘about <span class="math inline">\(x=a\)</span>’ is not included when referring to the <span class="math inline">\(n^{th}\)</span> order Taylor polynomial of <span class="math inline">\(f(x)\)</span>, then by default this is taken to mean the choice <span class="math inline">\(a=0,\)</span> as this is the most common case.<br />
The Taylor polynomial <span class="math inline">\(P_n(x)\)</span> is an approximation to the function <span class="math inline">\(f(x).\)</span> Generically, it is a good approximation if <span class="math inline">\(x\)</span> is close to <span class="math inline">\(a\)</span> and the approximation improves with increasing order <span class="math inline">\(n.\)</span> The remainder provides an exact expression for the error in the approximation.<br />
Eg. Calculate the <span class="math inline">\(n^{th}\)</span> order Taylor polynomial of <span class="math inline">\(e^x.\)</span></p>
<p><span class="math inline">\(f(x)=e^x,\ f&#39;(x)=e^x, \ ... \ ,f^{(k)}(x)=e^x\)</span>  so <span class="math inline">\(f^{(k)}(0)=1\)</span> giving <span class="math display">\[P_n(x)=1+x+\frac{x^2}{2!}+...+\frac{x^n}{n!}
=\sum_{k=0}^n\frac{x^k}{k!}.\]</span> Figure <a href="#fig-taylorexp" data-reference-type="ref" data-reference="fig-taylorexp">19</a> shows the graph of <span class="math inline">\(e^x\)</span> and its Taylor polynomials of order 0 to 3.</p>
<figure>
<img src="new_taylorexp.png" id="fig-taylorexp" style="width:8cm" alt="" /><figcaption>The function <span class="math inline">\(e^x\)</span> (red) and its associated Taylor polynomials <span class="math inline">\(P_0(x),P_1(x),P_2(x),P_3(x)\)</span> of order 0 (orange), 1 (green), 2 (blue) and 3 (pink).</figcaption>
</figure>
<p>If <span class="math inline">\(f(x)\)</span> is infinitely differentiable on an open interval <span class="math inline">\(I\)</span> that contains the point <span class="math inline">\(x=a\)</span> and in addition for each <span class="math inline">\(x\in I\)</span> we have that <span class="math inline">\(\lim_{n\rightarrow\infty}R_n(x)=0,\)</span> then we say that <span class="math inline">\(f(x)\)</span> can be expanded as a <span><strong>Taylor series</strong></span> about <span class="math inline">\(x=a\)</span> and we write <span class="math display">\[f(x)=\sum_{k=0}^\infty \frac{f^{(k)}(a)}{k!}(x-a)^k.\]</span> </p>
<p>Infinite series and discussions/tests concerning their convergence are covered in the Analysis I course.<br />
Note that the <span class="math inline">\(n^{th}\)</span> order Taylor polynomial is obtained by taking just the first <span class="math inline">\((n+1)\)</span> terms of the Taylor series (where we count terms even if they happen to be zero).<br />
Eg. From our earlier calculation we have that the Taylor series of <span class="math inline">\(e^x\)</span> is <span class="math display">\[e^x=\sum_{k=0}^\infty\frac{x^k}{k!}=1+x+\frac{x^2}{2!}+\frac{x^3}{3!}+\cdots\]</span> where <span class="math inline">\(\cdots\)</span> denotes an infinite number of terms with increasing powers of <span class="math inline">\(x.\)</span><br />
Note that if we set <span class="math inline">\(x=1\)</span> in the above Taylor series then we obtain a formula for Euler’s number <span class="math display">\[e=\sum_{k=0}^\infty\frac{1}{k!}=1+\frac{1}{1!}+\frac{1}{2!}+\frac{1}{3!}+\cdots\]</span><br />
Eg. Calculate the Taylor series of <span class="math inline">\(\sin x.\)</span></p>
<p><span class="math inline">\(f(x)=\sin x, \ f(0)=0, \quad
f&#39;(x)=\cos x, \ f&#39;(0)=1, \quad\)</span></p>
<p><span class="math inline">\(f&#39;&#39;(x)=-\sin x, \ f&#39;&#39;(0)=0, \quad
f&#39;&#39;&#39;(x)=-\cos x, \ f&#39;&#39;&#39;(0)=-1, \quad\)</span></p>
<p><span class="math inline">\(f^{(4)}(x)=\sin x\)</span> so now the pattern repeats and we see that for all non-negative integers <span class="math inline">\(k\)</span> we have that <span class="math inline">\(f^{2k}(0)=0\)</span> and <span class="math inline">\(f^{2k+1}(0)=(-1)^k.\)</span></p>
<p>The Taylor series of <span class="math inline">\(\sin x\)</span> is therefore given by <span class="math display">\[\sin x=\sum_{k=0}^\infty\frac{(-1)^k}{(2k+1)!}x^{2k+1}=x-\frac{x^3}{3!}+\frac{x^5}{5!}-\frac{x^7}{7!}+\cdots\]</span> Observe that only odd powers of <span class="math inline">\(x\)</span> appear in the Taylor series of <span class="math inline">\(\sin x\)</span> as this is an odd function.<br />
A similar calculation (exercise) yields the Taylor series of <span class="math inline">\(\cos x\)</span> <span class="math display">\[\cos x=\sum_{k=0}^\infty\frac{(-1)^k}{(2k)!}x^{2k}=1-\frac{x^2}{2!}+\frac{x^4}{4!}-\frac{x^6}{6!}+\cdots\]</span> in which only even powers of <span class="math inline">\(x\)</span> appear, as <span class="math inline">\(\cos x\)</span> is an even function.<br />
To calculate the Taylor series of <span class="math inline">\(\sinh x\)</span> observe that for all non-negative integer <span class="math inline">\(k\)</span> we have that <span class="math inline">\(f(x)=\sinh x\)</span> satisfies <span class="math display">\[f^{(k)}(x)=\begin{cases}
\sinh x &amp; \text{if $k$ \ is even}\\
\cosh x &amp; \text{if $k$ \ is odd}\\
\end{cases}\]</span> thus <span class="math inline">\(f^{(2k)}(0)=0\)</span> and <span class="math inline">\(f^{(2k+1)}(0)=1\)</span> giving <span class="math display">\[\sinh x=\sum_{k=0}^\infty\frac{1}{(2k+1)!}x^{2k+1}=x+\frac{x^3}{3!}+\frac{x^5}{5!}+\frac{x^7}{7!}+\cdots\]</span> </p>
<p>A similar calculation (exercise) yields the Taylor series of <span class="math inline">\(\cosh x\)</span> <span class="math display">\[\cosh x=\sum_{k=0}^\infty\frac{1}{(2k)!}x^{2k}=1+\frac{x^2}{2!}+\frac{x^4}{4!}+\frac{x^6}{6!}+\cdots\]</span> </p>
<p>These two results can also be obtained directly from the Taylor series of <span class="math inline">\(e^x\)</span> by noting that <span class="math inline">\(\cosh x\)</span> and <span class="math inline">\(\sinh x\)</span> are the even and odd parts of <span class="math inline">\(e^x.\)</span><br />
As <span class="math inline">\(\log x\)</span> is not defined at <span class="math inline">\(x=0\)</span> it does not make sense to consider the Taylor series of <span class="math inline">\(\log x\)</span> about <span class="math inline">\(x=0.\)</span> Instead we consider the Taylor series of <span class="math inline">\(\log x\)</span> about <span class="math inline">\(x=1.\)</span></p>
<p><span class="math inline">\(f(x)=\log x,\ f(1)=0, \quad f&#39;(x)=\frac{1}{x},\ f&#39;(1)=1, \quad\)</span></p>
<p><span class="math inline">\(f&#39;&#39;(x)=-\frac{1}{x^2},\ f&#39;&#39;(1)=-1, \quad f&#39;&#39;&#39;(x)=\frac{2}{x^3},\ f&#39;&#39;&#39;(1)=2, 
\quad\)</span></p>
<p><span class="math inline">\(f^{(4)}(x)=-\frac{3\cdot 2}{x^4},\ f^{(4)}(1)=-3\cdot 2\)</span> and in general for <span class="math inline">\(k\)</span> a positive integer <span class="math inline">\(f^{(k)}(x)=(-1)^{k-1}\frac{(k-1)!}{x^k},\  f^{(k)}(1)=(-1)^{k-1}{(k-1)!}\)</span></p>
<p>Thus the Taylor series of <span class="math inline">\(\log x\)</span> about <span class="math inline">\(x=1\)</span> is <span class="math display">\[\log x=\sum_{k=1}^\infty \frac{(-1)^{k-1}(k-1)!}{k!}(x-1)^k
=\sum_{k=1}^\infty \frac{(-1)^{k-1}}{k}(x-1)^k\]</span> This result is more often expressed in terms of the variable <span class="math inline">\(X=x-1,\)</span> when it becomes <span class="math inline">\(\log (1+X)=\sum_{k=1}^\infty \frac{(-1)^{k-1}}{k}X^k.\)</span></p>
<p>If we now rename the variable <span class="math inline">\(X\)</span> as <span class="math inline">\(x\)</span> we get <span class="math display">\[\log (1+x)=\sum_{k=1}^\infty \frac{(-1)^{k-1}}{k}x^k
=x-\frac{x^2}{2}+\frac{x^3}{3}-\frac{x^4}{4}+\cdots\]</span> This result is not valid at <span class="math inline">\(x=-1,\)</span> and this is to be expected because the logarithm is not defined when its argument is zero. A careful examination of the requirement <span class="math inline">\(\lim_{n\rightarrow\infty}R_n(x)=0\)</span> reveals that <span class="math inline">\(x\)</span> must satisfy <span class="math inline">\(-1&lt;x\le 1\)</span> for the above Taylor series to be valid (ie. for the series to converge).<br />
</p>
</section>
<section id="lagrange-form-for-the-remainder" class="level2" data-number="8.3">
<h2 data-number="8.3"><span class="header-section-number">8.3</span> Lagrange form for the remainder</h2>
<p>There is a more convenient expression for the remainder term in Taylor’s theorem. The <span><strong>Lagrange form for the remainder</strong></span> is <span class="math display">\[R_n(x)=\frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1},\quad\quad
\mbox{for some \ } c\in(a,x).\]</span> </p>
<p>To prove this expression for the remainder we will first need to prove the following lemma:<br />
<span><em>Lemma</em></span></p>
<p>Let <span class="math inline">\(h(t)\)</span> be differentiable <span class="math inline">\(n+1\)</span> times on <span class="math inline">\([a,x]\)</span> with <span class="math inline">\(h^{(k)}(a)=0\)</span>  for <span class="math inline">\(0\le k\le n\)</span> and <span class="math inline">\(h(x)=0.\)</span> Then <span class="math inline">\(\exists\ c\in(a,x)\)</span> s.t. <span class="math inline">\(h^{(n+1)}(c)=0.\)</span><br />
Proof:</p>
<p><span class="math inline">\(h(a)=0=h(x)\)</span>  so by Rolle’s theorem <span class="math inline">\(\exists\ c_1\in(a,x)\)</span> s.t. <span class="math inline">\(h&#39;(c_1)=0.\)</span></p>
<p><span class="math inline">\(h&#39;(a)=0=h&#39;(c_1)\)</span>  so by Rolle’s theorem <span class="math inline">\(\exists\ c_2\in(a,c_1)\)</span> s.t. <span class="math inline">\(h&#39;&#39;(c_1)=0.\)</span></p>
<p>Repeating this argument a total of <span class="math inline">\(n\)</span> times we arrive at</p>
<p><span class="math inline">\(h^{(n)}(a)=0=h^{(n)}(c_n)\)</span>  so by Rolle’s theorem <span class="math inline">\(\exists\ c_{n+1}\in(a,c_n)\)</span> s.t. <span class="math inline">\(h^{(n+1)}(c_{n+1})=0.\)</span></p>
<p>This proves the lemma with <span class="math inline">\(c=c_{n+1}\in (a,x).\)</span><br />
Proof of the Lagrange form of the remainder:</p>
<p>Consider the function <span class="math display">\[h(t)=(f(t)-P_n(t))(x-a)^{n+1}-(f(x)-P_n(x))(t-a)^{n+1}.\]</span> By construction <span class="math inline">\(h(x)=0.\)</span></p>
<p>Also <span class="math inline">\(\frac{d^k}{dt^k}(t-a)^{n+1}\)</span> is zero when evaluated at <span class="math inline">\(t=a\)</span> for <span class="math inline">\(0\le k\le n.\)</span> Furthermore, by definition of the Taylor polynomial <span class="math inline">\(P_n(t)\)</span> we have that <span class="math inline">\(f^{(k)}(a)=P_n^{(k)}(a)\)</span> for <span class="math inline">\(0\le k\le n.\)</span></p>
<p>Hence <span class="math inline">\(h^{(n)}(a)=0\)</span> for <span class="math inline">\(0\le k\le n.\)</span></p>
<p><span class="math inline">\(h(t)\)</span> therefore satisfies the conditions of the lemma and we have that</p>
<p><span class="math inline">\(\exists\ c\in(a,x)\)</span> s.t. <span class="math inline">\(h^{(n+1)}(c)=0.\)</span></p>
<p>As <span class="math inline">\(P_n(t)\)</span> is a polynomial of degree <span class="math inline">\(n\)</span> then <span class="math inline">\(P_n^{(n+1)}(t)=0.\)</span></p>
<p>Also, <span class="math inline">\(\frac{d^{n+1}}{dt^{n+1}}(t-a)^{n+1}=(n+1)!\)</span> hence <span class="math display">\[0=h^{(n+1)}(c)=(x-a)^{n+1}f^{(n+1)}(c)-(n+1)!(f(x)-P_n(x))\]</span> Rearranging this expression gives the required result <span class="math display">\[f(x)=P_n(x)+\frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1}.\]</span><br />
One use of the Lagrange form of the remainder is to provide an upper bound on the error of a Taylor polynomial approximation to a function.</p>
<p>Suppose that <span class="math inline">\(|f^{(n+1)}(t)|\le M, \quad \forall \ t\)</span> in the closed interval between <span class="math inline">\(a\)</span> and <span class="math inline">\(x.\)</span></p>
<p>Then <span class="math inline">\(|R_n(x)|\le \frac{M|x-a|^{n+1}}{(n+1)!}\)</span>  provides a bound on the error.<br />
Eg. Show that the error in approximating <span class="math inline">\(e^{x}\)</span> by its <span class="math inline">\(6^{th}\)</span> order Taylor polynomial is always less than <span class="math inline">\(0.0006\)</span> throughout the interval <span class="math inline">\([0,1].\)</span><br />
In this example <span class="math inline">\(f(x)=e^x\)</span> and <span class="math inline">\(n=6\)</span> so we first require an upper bound on <span class="math inline">\(|f^{(7)}(t)|=|e^t|\)</span> for <span class="math inline">\(t\in[0,1].\)</span> As <span class="math inline">\(e^t\)</span> is monotonic increasing and positive then <span class="math inline">\(|e^t|\le e^1=e&lt;3.\)</span> Thus, in the above notation, we may take <span class="math inline">\(M=3.\)</span></p>
<p>As <span class="math inline">\(a=0\)</span> we now have that <span class="math inline">\(|R_6(x)|&lt; \frac{3|x|^{7}}{7!}\le  \frac{3}{7!}\)</span> for <span class="math inline">\(x\in[0,1].\)</span></p>
<p>Evaluating <span class="math inline">\(\frac{3}{7!}=\frac{1}{1680}&lt;0.0006\)</span> and the required result has been shown.<br />
</p>
</section>
<section id="calculating-limits-using-taylor-series" class="level2" data-number="8.4">
<h2 data-number="8.4"><span class="header-section-number">8.4</span> Calculating limits using Taylor series</h2>
<p><span><strong>* Only use this method in assignments/exam questions when told to do so **</strong></span><br />
<span><strong>Defn:</strong></span> Let <span class="math inline">\(n\)</span> be a positive integer.</p>
<p>We say that <span class="math inline">\(f(x)=o(x^n)\)</span> (as <span class="math inline">\(x\rightarrow 0\)</span>) if <span class="math inline">\(\lim_{x\rightarrow 0}\frac{f(x)}{x^n}=0.\)</span></p>
<p> </p>
<p>In particular, if <span class="math inline">\(\alpha\)</span> is any non-zero constant then <span class="math inline">\(\alpha x^m=o(x^n)\)</span> iff <span class="math inline">\(m&gt;n.\)</span><br />
Egs. <span class="math inline">\(3x^4=o(x^3),\  3x^4=o(x^2),\ 3x^8-x^6=o(x^5), \ o(x^8)+o(x^5)=o(x^5).\)</span><br />
If we know that a Taylor series is valid in a suitable open interval, then it may be useful in calculating certain limits.</p>
<p>It can be shown that the Taylor series we have already seen for <span class="math inline">\(\sin x\)</span> and <span class="math inline">\(\cos x\)</span> are valid for all <span class="math inline">\(x\in\mathbb{R}\)</span>. Although we have not proved this result you may assume that it is true and use it in calculating limits. As examples, we shall now calculate the two important trigonometric limits that we saw earlier.<br />
Eg. Use Taylor series to calculate <span class="math inline">\(\lim_{x\rightarrow 0}\frac{\sin x}{x}.\)</span></p>
<p>From the Taylor series of <span class="math inline">\(\sin x\)</span> we have that <span class="math inline">\(\sin x=x-\frac{x^3}{3!}+o(x^4).\)</span> Hence <span class="math display">\[\lim_{x\rightarrow 0}\frac{\sin x}{x}=
\lim_{x\rightarrow 0}\frac{x-\frac{x^3}{3!}+o(x^4)}{x}=
\lim_{x\rightarrow 0}({1-\frac{x^2}{3!}+o(x^3)})=
\lim_{x\rightarrow 0}({1+o(x)})=1.\]</span> </p>
<p>Eg. Use Taylor series to calculate <span class="math inline">\(\lim_{x\rightarrow 0}\frac{1-\cos x}{x}.\)</span></p>
<p>From the Taylor series of <span class="math inline">\(\cos x\)</span> we have that <span class="math inline">\(\cos x=1-\frac{x^2}{2}+o(x^3).\)</span> Hence <span class="math display">\[\lim_{x\rightarrow 0}\frac{1-\cos x}{x}=
\lim_{x\rightarrow 0}\frac{1-1+\frac{x^2}{2}+o(x^3)}{x}
=\lim_{x\rightarrow 0}\frac{\frac{x^2}{2}+o(x^3)}{x}
=\lim_{x\rightarrow 0}\bigg(\frac{x}{2}+o(x^2)\bigg)=0.\]</span></p>
</section>
<section id="summary-taylor-series" class="level2" data-number="8.5">
<h2 data-number="8.5"><span class="header-section-number">8.5</span> Summary: Taylor Series</h2>
<p>You should know how to calculate Taylor polynomials <span class="math inline">\(P_n(x)\)</span> and what the integral form and Lagrange form of the remainder <span class="math inline">\(R_n(x)\)</span> are, as well as how to estimate the maximum error in using a Taylor polynomial as an approximation of a function. Here are some key points:</p>
<ul>
<li><p>The <span><em>Taylor polynomial</em></span> of degree <span class="math inline">\(n\)</span> about <span class="math inline">\(x=a\)</span> for a function <span class="math inline">\(f\)</span> is the degree <span class="math inline">\(n\)</span> polynomial in <span class="math inline">\((x-a)\)</span>, <span class="math inline">\(P_n(x) = \sum_{k=0}^n \frac{f^{(k)}(a)}{k!} (x-a)^k\)</span>. At the point <span class="math inline">\(x=a\)</span>, <span class="math inline">\(P_n\)</span> and its first <span class="math inline">\(n\)</span> derivatives will agree with <span class="math inline">\(f\)</span> and its first <span class="math inline">\(n\)</span> derivatives. In this sense the Taylor polynomial tries to approximate <span class="math inline">\(f\)</span> close to <span class="math inline">\(x=a\)</span>. Note that if we don’t explicitly state “about <span class="math inline">\(x=a\)</span>” then it is assumed we are working about <span class="math inline">\(x=0\)</span>.</p></li>
<li><p><span><em>Taylor’s theorem</em></span> states that <span class="math inline">\(f(x) = P_n(x) + R_n(x)\)</span> where <span class="math inline">\(R_n(x) = \frac{1}{n!} \int_a^x (x-t)^n f^{(n+1)}(t) dt\)</span> is the <span><em>remainder</em></span>.</p></li>
<li><p>The <span><em>Lagrange form of the remainder</em></span> says that <span class="math inline">\(R_n(x) = \frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1}\)</span> for some (unknown) <span class="math inline">\(c\)</span> between <span class="math inline">\(a\)</span> and <span class="math inline">\(x\)</span>. (Note the similarity to the next term in the Taylor polynomial.) This can often be used to place an upper bound on <span><em>the error</em></span> <span class="math inline">\(|R_n(x)|\)</span> in using <span class="math inline">\(P_n(x)\)</span> as an approximation of <span class="math inline">\(f(x)\)</span>.</p></li>
<li><p>The <span><em>Taylor series</em></span> about <span class="math inline">\(x=a\)</span> is <span class="math inline">\(\lim_{n \to \infty} P_n(x)\)</span>. If <span class="math inline">\(\lim_{n \to \infty} R_n(x) = 0\)</span> (i.e. the error vanishes in this limit) for all <span class="math inline">\(x\)</span> in some interval containing <span class="math inline">\(a\)</span> we say that the Taylor series converges to <span class="math inline">\(f(x)\)</span> on that interval. In such cases <span class="math inline">\(P_n(x)\)</span> approximates <span class="math inline">\(f(x)\)</span> as well as we want on that interval by taking <span class="math inline">\(n\)</span> large enough.</p></li>
<li><p>You should be familiar with the form of the Taylor series (about <span class="math inline">\(x=0\)</span>) for <span class="math inline">\(e^x\)</span>, <span class="math inline">\(\sinh x\)</span>, <span class="math inline">\(\cosh x\)</span>, <span class="math inline">\(\sin x\)</span>, <span class="math inline">\(\cos x\)</span> and <span class="math inline">\(\log(1+x)\)</span>. The Taylor series for <span class="math inline">\(\log(1+x)\)</span> converges to <span class="math inline">\(\log(1+x)\)</span> for <span class="math inline">\(x \in (-1, 1]\)</span>. The other ones converge to their functions <span class="math inline">\(\forall x \in \mathbb{R}\)</span>.</p></li>
<li><p>We can find Taylor polynomials of degree <span class="math inline">\(n\)</span> for sums of products of functions by taking sums of products of Taylor polynomials of degree <span class="math inline">\(n\)</span> (and ignoring any terms with degree higher than <span class="math inline">\(n\)</span> which arise from products). We can also use substitution, e.g. to find the Taylor polynomial of degree <span class="math inline">\(n\)</span> for <span class="math inline">\(e^{\sin x}\)</span> replace <span class="math inline">\(x\)</span> in the Taylor polynomial of degree <span class="math inline">\(n\)</span> for <span class="math inline">\(e^x\)</span> with the Taylor polynomial of degree <span class="math inline">\(n\)</span> for <span class="math inline">\(\sin x\)</span> (and again ignore all powers higher than <span class="math inline">\(n\)</span>). It is sometimes possible to divide by Taylor series using <span class="math inline">\(1/(1-x) = 1 + x + x^2 + x^3 + \cdots\)</span> for <span class="math inline">\(x \in (-1,1)\)</span> and appropriate substitution.</p></li>
<li><p>We can evaluate limits as <span class="math inline">\(x \to a\)</span> by replacing functions with their Taylor polynomials of sufficiently high order about <span class="math inline">\(x=a\)</span> provided the Taylor series converge to the functions on some interval containing <span class="math inline">\(a\)</span>. This is because in such cases the higher order terms (higher powers of <span class="math inline">\((x-a)\)</span>) will vanish in the limit <span class="math inline">\(x \to a\)</span>.</p></li>
</ul>
</section>
</section>
<section id="fourier-series" class="level1" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> Fourier series</h1>
<section id="fourier-coefficients" class="level2" data-number="9.1">
<h2 data-number="9.1"><span class="header-section-number">9.1</span> Fourier coefficients</h2>
<p>In our study of Taylor series and Taylor polynomials we have seen how to write and approximate functions in terms of polynomials. If the function we are interested in is periodic, then it is more appropriate to use trigonometric functions rather than polynomials. This is the topic of Fourier series, which are important in a wide range of areas and applications. In particular, they play a vital role in the solution of certain partial differential equations.<br />
Consider a function <span class="math inline">\(f(x)\)</span> of period <span class="math inline">\(2L\)</span> which is given on the interval <span class="math inline">\((-L,L).\)</span> The functions <span class="math inline">\(\cos \frac{n\pi x}{L}\)</span> and <span class="math inline">\(\sin \frac{n\pi x}{L},\)</span> with <span class="math inline">\(n\)</span> any positive integer, are also periodic with period <span class="math inline">\(2L.\)</span> It therefore seems reasonable to try and write <span class="math inline">\(f(x)\)</span> in terms of these trigonometric functions. Note that a constant is trivially a periodic function (for any period) so we can also include a constant term. We therefore aim to write <span class="math display">\[f(x)=\frac{a_0}{2}+\sum_{n=1}^\infty \bigg(
a_n \cos \frac{n\pi x}{L}
+b_n \sin \frac{n\pi x}{L}\bigg)
\hskip 3cm (FS)\]</span> where <span class="math inline">\(a_0,a_n,b_n\)</span> are constants labelled by the positive integer <span class="math inline">\(n,\)</span> and are called the <span><strong>Fourier coefficients</strong></span> of <span class="math inline">\(f(x).\)</span> (It is just a convenient notation to call the constant term <span class="math inline">\(a_0/2.\)</span>). If these Fourier coefficients are such that this series converges then it is called the <span><strong>Fourier series</strong></span> of <span class="math inline">\(f(x).\)</span><br />
Eg. The function <span class="math inline">\(f(x)=2\cos^2\frac{\pi x}{L}+3\sin\frac{\pi x}{L}\)</span> has period <span class="math inline">\(2L.\)</span></p>
<p>Its Fourier series contains only a finite number of terms as</p>
<p><span class="math inline">\(2\cos^2\frac{\pi x}{L}+3\sin\frac{\pi x}{L}
=1+\cos\frac{2\pi x}{L}+3\sin\frac{\pi x}{L}.\)</span></p>
<p>Therefore <span class="math inline">\(a_0=2,\ a_2=1,\ b_1=3,\)</span> and all the other Fourier coefficients are zero.</p>
<p> </p>
<p>In general an infinite number of Fourier coefficients may be non-zero and we need a method to determine these from the given function <span class="math inline">\(f(x).\)</span></p>
<p>In order to derive formulae for the Fourier coefficients we first need to prove some identities for integrals of trigonometric functions.</p>
<p>In the following let <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span> be positive integers.<br />
<span class="math display">\[\begin{aligned}
&amp;(i)\quad\quad&amp; \int _{-L}^{L} \cos \frac{n\pi x}{L}\,dx =0.\\
&amp;(ii)\quad\quad&amp; \int _{-L}^{L} \sin \frac{n\pi x}{L}\,dx =0.\\
&amp;(iii)\quad\quad&amp; \int _{-L}^{L} \sin \frac{m\pi x}{L}\,\cos \frac{n\pi x}{L}\,dx =0.\\
&amp;(iv)\quad\quad&amp; \frac{1}{L}\int _{-L}^{L} \cos \frac{m\pi x}{L}\,\cos \frac{n\pi x}{L}\,dx =\begin{cases}
0&amp; \text{if \ $m\ne n$}\\
1&amp; \text{if \ $m=n.$}\\
\end{cases}\\
&amp;(v)\quad\quad&amp; \frac{1}{L}\int _{-L}^{L} \sin \frac{m\pi x}{L}\,\sin \frac{n\pi x}{L}\,dx =\begin{cases}
0&amp; \text{if \ $m\ne n$}\\
1&amp; \text{if \ $m=n.$}\\
\end{cases}\end{aligned}\]</span> The expression that occurs on the right hand side of the last two formulae arises so often that it is useful to introduce a shorthand notation for this. The Kronecker delta <span class="math inline">\(\delta_{mn}\)</span> is defined to be <span class="math display">\[\delta_{mn}=\begin{cases}
0&amp; \text{if \ $m\ne n$}\\
1&amp; \text{if \ $m=n.$}\\
\end{cases}\]</span> So, for example, we may write <span class="math inline">\(\frac{1}{L}\int _{-L}^{L} \sin \frac{m\pi x}{L}\,\sin \frac{n\pi x}{L}\,dx =
\delta_{mn}.\)</span><br />
It is trivial to prove <span class="math inline">\((i):\)</span> <span class="math inline">\(\int _{-L}^{L} \cos \frac{n\pi x}{L}\,dx= 
\bigg[\frac{L}{n\pi}\sin \frac{n\pi x}{L}\bigg]^L_{-L}=
\frac{2L}{n\pi}\sin(n\pi)=0.\)</span></p>
<p><span class="math inline">\((ii)\)</span> and <span class="math inline">\((iii)\)</span> are true by inspection, as they are both integrals of odd functions over a symmetric interval.</p>
<p>We can prove <span class="math inline">\((iv)\)</span> and <span class="math inline">\((v)\)</span> by using <span class="math inline">\(\cos(x\pm y)=\cos x \cos y\mp \sin x \sin y.\)</span></p>
<p>First assume <span class="math inline">\(m\ne n\)</span> then <span class="math display">\[\frac{1}{L}\int _{-L}^{L} \cos \frac{m\pi x}{L}\,\cos \frac{n\pi x}{L}\,dx 
%$\cos \frac{m\pi x}{L}\,\cos \frac{n\pi x}{L}
=\frac{1}{2L}\int _{-L}^{L} \bigg(\cos \frac{(m-n)\pi x}{L}+\cos \frac{(m+n)\pi x}{L}\bigg)\,dx\]</span> <span class="math display">\[=
\frac{1}{2\pi}\bigg[\frac{1}{m-n}\sin\frac{(m-n)\pi x}{L}
+\frac{1}{m+n}\sin\frac{(m+n)\pi x}{L}\bigg]^L_{-L}
=0.\]</span> Now if <span class="math inline">\(m=n\)</span> <span class="math display">\[\frac{1}{L}\int _{-L}^{L} \cos \frac{m\pi x}{L}\,\cos \frac{n\pi x}{L}\,dx 
=\frac{1}{2L}\int _{-L}^{L}\bigg(1+\cos \frac{2n\pi x}{L}\bigg)\,dx
%$$ $$
=\frac{1}{2L}\bigg[x+\frac{L}{2n\pi}\sin \frac{2n\pi x}{L}\bigg]^L_{-L}
=1.\]</span> This proves <span class="math inline">\((iv)\)</span> and a similar calculation (exercise) proves <span class="math inline">\((v).\)</span><br />
We say that the set of functions <span class="math inline">\(\{1,\cos \frac{n\pi x}{L},
\sin \frac{n\pi x}{L}\}\)</span> form an <span><strong>orthogonal set</strong></span> on <span class="math inline">\([-L,L]\)</span> because if <span class="math inline">\(\phi,\psi\)</span> are any two <span><em>different</em></span> functions from this set then <span class="math inline">\(\frac{1}{L}\int _{-L}^{L} \phi\psi\,dx=0.\)</span><br />
We now use the identities <span class="math inline">\((i),..,(v)\)</span> to derive expressions for the Fourier coefficients in <span class="math inline">\((FS).\)</span></p>
<p>First of all, by integrating <span class="math inline">\((FS)\)</span> we have <span class="math display">\[\frac{1}{L}\int _{-L}^{L} f(x)\,dx
=\frac{1}{L}\int _{-L}^{L} \bigg\{
\frac{a_0}{2}+\sum_{n=1}^\infty \bigg(
a_n \cos \frac{n\pi x}{L}
+b_n \sin \frac{n\pi x}{L}\bigg)
\bigg\}\,dx=a_0\]</span> using <span class="math inline">\((i)\)</span> and <span class="math inline">\((ii).\)</span> Thus we have derived an expression for <span class="math inline">\(a_0\)</span> <span class="math display">\[a_0=\frac{1}{L}\int _{-L}^{L} f(x)\,dx.\]</span> Let <span class="math inline">\(m\)</span> be a positive integer and multiply <span class="math inline">\((FS)\)</span> by <span class="math inline">\(\cos\frac{m\pi x}{L}\)</span> and integrate to give <span class="math display">\[\frac{1}{L}\int _{-L}^{L} \cos\frac{m\pi x}{L}f(x)\,dx
=\frac{1}{L}\int _{-L}^{L} \bigg\{
\frac{a_0}{2}+\sum_{n=1}^\infty \bigg(
a_n \cos \frac{n\pi x}{L}
+b_n \sin \frac{n\pi x}{L}\bigg)
\bigg\}\cos\frac{m\pi x}{L}
\,dx\]</span> <span class="math display">\[=\sum_{n=1}^\infty a_n\delta_{mn}=a_m,
\quad\quad\quad \mbox{where we have used the identities\ } (i),(iii),(iv).\]</span> Thus we have derived an expression for <span class="math inline">\(a_n\)</span> <span class="math display">\[a_n=\frac{1}{L}\int _{-L}^{L} \cos\frac{n\pi x}{L}f(x)\,dx.\]</span> Note that if we extend this relation to <span class="math inline">\(n=0\)</span> then it reproduces the correct expression given above for <span class="math inline">\(a_0.\)</span><br />
Similarly, multiply <span class="math inline">\((FS)\)</span> by <span class="math inline">\(\sin\frac{m\pi x}{L}\)</span> and integrate to give <span class="math display">\[\frac{1}{L}\int _{-L}^{L} \sin\frac{m\pi x}{L}f(x)\,dx
=\frac{1}{L}\int _{-L}^{L} \bigg\{
\frac{a_0}{2}+\sum_{n=1}^\infty \bigg(
a_n \cos \frac{n\pi x}{L}
+b_n \sin \frac{n\pi x}{L}\bigg)
\bigg\}\sin\frac{m\pi x}{L}
\,dx\]</span> <span class="math display">\[=\sum_{n=1}^\infty b_n\delta_{mn}=b_m,
\quad\quad\quad \mbox{where we have used the identities\ } (ii),(iii),(v).\]</span> Thus we have derived an expression for <span class="math inline">\(b_n\)</span> <span class="math display">\[b_n=\frac{1}{L}\int _{-L}^{L} \sin\frac{n\pi x}{L}f(x)\,dx.\]</span></p>
</section>
<section id="examples-of-fourier-series" class="level2" data-number="9.2">
<h2 data-number="9.2"><span class="header-section-number">9.2</span> Examples of Fourier series</h2>
<p>Eg. The function <span class="math inline">\(f(x)\)</span> has period 2, that is <span class="math inline">\(f(x+2)=f(x),\)</span> and is given by <span class="math inline">\(f(x)=|x|\)</span> for <span class="math inline">\(-1&lt;x&lt;1.\)</span> The graph of this function is shown in Figure <a href="#fig-fouriermodx" data-reference-type="ref" data-reference="fig-fouriermodx">20</a>.</p>
<p><img src="new_fouriermodx.png" id="fig-fouriermodx" style="width:8cm" alt="image" /> <span id="fig-fouriermodx" label="fig-fouriermodx">[fig-fouriermodx]</span></p>
<p>To calculate the Fourier series of this function we apply the earlier formulae with <span class="math inline">\(L=1.\)</span></p>
<p><span class="math inline">\(a_0=\int_{-1}^1 |x|\,dx=2\int_0^1 x\,dx=\bigg[x^2\bigg]^1_0=1.\)</span></p>
<p>For <span class="math inline">\(n&gt;0\)</span> <span class="math display">\[a_n=\int_{-1}^1 |x|\cos(n\pi x)\,dx=2\int_0^1 x\cos(n\pi x)\,dx\]</span> <span class="math display">\[=2\bigg\{
\bigg[\frac{x}{n\pi}\sin(n\pi x)\bigg]_0^1-\int_0^1\frac{1}{n\pi}\sin(n\pi x)\,dx\bigg\}
=\frac{2}{n^2\pi^2}\bigg[\cos(n\pi x)\bigg]_0^1\]</span> <span class="math display">\[=\frac{2}{n^2\pi^2}(\cos(n\pi)-1)
=\frac{2}{n^2\pi^2}((-1)^n-1).\]</span> Furthermore, for <span class="math inline">\(n&gt;0\)</span> <span class="math display">\[b_n=\int_{-1}^1 |x|\sin(n\pi x)\,dx=0\]</span> because this is the integral of an odd function over a symmetric interval.<br />
This demonstrates a general point that if <span class="math inline">\(f(x)\)</span> is an even function on the interval <span class="math inline">\((-L,L)\)</span> then all <span class="math inline">\(b_n=0\)</span> and the Fourier series contains only cosine terms (plus a constant term). This is called a cosine series.<br />
Putting all this together we have the Fourier (cosine) series <span class="math display">\[f(x)=\frac{1}{2}+\sum_{n=1}^\infty \frac{2}{n^2\pi^2}((-1)^{n}-1)\cos(n\pi x)\]</span> <span class="math display">\[=\frac{1}{2}-\frac{4}{\pi^2}\bigg(
\cos(\pi x)+\frac{1}{9}\cos(3\pi x)+\frac{1}{25}\cos(5\pi x)
+\cdots
\bigg)\]</span> Note that in this example <span class="math inline">\(a_{2n}=0\)</span> and <span class="math inline">\(a_{2n-1}=-\frac{4}{\pi^2(2n-1)^2},\)</span> so this Fourier (cosine) series could also be written as <span class="math display">\[f(x)=\frac{1}{2}-\frac{4}{\pi^2}\sum_{n=1}^\infty 
\frac{\cos((2n-1)\pi x)}{(2n-1)^2}.\]</span> </p>
<p>To see how the Fourier series approaches the function <span class="math inline">\(f(x)\)</span> define the <span><strong>partial sum</strong></span> <span class="math display">\[S_m(x)=\frac{a_0}{2}+\sum_{n=1}^m \bigg(
a_n \cos \frac{n\pi x}{L}
+b_n \sin \frac{n\pi x}{L}\bigg).\]</span> In this example, <span class="math inline">\(S_1(x)=\frac{1}{2}-\frac{4}{\pi^2}\cos(\pi x),
\quad  S_3(x)=\frac{1}{2}-\frac{4}{\pi^2}(\cos(\pi x)+\frac{1}{9}\cos(3\pi x)),\)</span></p>
<p><span class="math inline">\(S_5(x)=\frac{1}{2}-\frac{4}{\pi^2}(\cos(\pi x)+\frac{1}{9}\cos(3\pi x)+\frac{1}{25}\cos(5\pi x)),\)</span>  etc.<br />
In Figure <a href="#fig-fouriermodx2" data-reference-type="ref" data-reference="fig-fouriermodx2">23</a> we plot the graph of <span class="math inline">\(f(x)\)</span> together with the partial sums <span class="math inline">\(S_1(x),S_5(x),S_{11}(x).\)</span></p>
<p>This helps to demonstrate that, in this case, <span class="math inline">\(\lim_{m\rightarrow\infty}S_m(x)=f(x).\)</span><br />
</p>
<p><img src="new_fouriermodx01.png" title="fig:" id="fig-fouriermodx2" style="width:5cm" alt="The graph of f(x)=|x| for -1&lt;x&lt;1, together with the partial sums S_1(x),S_5(x),S_{11}(x). " /> <img src="new_fouriermodx05.png" title="fig:" id="fig-fouriermodx2" style="width:5cm" alt="The graph of f(x)=|x| for -1&lt;x&lt;1, together with the partial sums S_1(x),S_5(x),S_{11}(x). " /> <img src="new_fouriermodx11.png" title="fig:" id="fig-fouriermodx2" style="width:5cm" alt="The graph of f(x)=|x| for -1&lt;x&lt;1, together with the partial sums S_1(x),S_5(x),S_{11}(x). " /></p>
<p>Eg. The function <span class="math inline">\(f(x)\)</span> has period <span class="math inline">\(2\pi\)</span> and is given by <span class="math inline">\(f(x)=x\)</span> for <span class="math inline">\(-\pi&lt;x&lt;\pi.\)</span></p>
<p>Calculate the Fourier series of <span class="math inline">\(f(x).\)</span><br />
The graph of this function is shown in Figure <a href="#fig-fourierx" data-reference-type="ref" data-reference="fig-fourierx">24</a>. Note that the function is not continuous at the points <span class="math inline">\(x=(2p+1)\pi,
\ \ p\in\mathbb{Z},\)</span> where there are jump discontinuities.</p>
<figure>
<img src="new_fourierx.png" id="fig-fourierx" style="width:5cm" alt="" /><figcaption>The graph of <span class="math inline">\(f(x)=x\)</span> for <span class="math inline">\(-\pi&lt;x&lt;\pi,\)</span> with period <span class="math inline">\(2\pi.\)</span></figcaption>
</figure>
<p>We apply the earlier formulae with <span class="math inline">\(L=\pi.\)</span> For <span class="math inline">\(n\ge 0\)</span> <span class="math display">\[a_n=\frac{1}{\pi}\int _{-\pi}^{\pi} x\cos(n x)\,dx=0\]</span> because this is the integral of an odd function over a symmetric interval.<br />
This demonstrates a general point that if <span class="math inline">\(f(x)\)</span> is an odd function on the interval <span class="math inline">\((-L,L)\)</span> then all <span class="math inline">\(a_n=0\)</span> and the Fourier series contains only sine functions. This is called a sine series.<br />
For <span class="math inline">\(n&gt;0\)</span> <span class="math display">\[b_n=\frac{1}{\pi}\int _{-\pi}^{\pi} x\sin(n x)\,dx
=\frac{1}{\pi}\bigg\{\bigg[-\frac{x}{n}\cos(nx)\bigg]^\pi_{-\pi}
+\int _{-\pi}^{\pi}\frac{1}{n}\cos(nx)\,dx
\bigg\}\]</span> <span class="math display">\[=\frac{1}{\pi}\bigg\{-\frac{2\pi}{n}\cos(n\pi)
+\bigg[\frac{1}{n^2}\sin(nx)\bigg]^\pi_{-\pi}
\bigg\}
=-\frac{2}{n}\cos(n\pi)=-\frac{2}{n}(-1)^n=\frac{2}{n}(-1)^{n+1}.\]</span> Putting all this together we have the Fourier (sine) series <span class="math display">\[f(x)=\sum_{n=1}^\infty \frac{2}{n}(-1)^{n+1}\sin(nx)
=2\bigg(
\sin x-\frac{1}{2}\sin(2x)+\frac{1}{3}\sin(3x)-\frac{1}{4}\sin(4x)+\cdots
\bigg)\]</span></p>
<p><img src="new_fourier01.png" title="fig:" id="fig-fourierm" style="width:5cm" alt="The graph of f(x)=x for -\pi&lt;x&lt;\pi, together with the graphs of the partial sums S_1(x),S_6(x),S_{50}(x)." /> <img src="new_fourier06.png" title="fig:" id="fig-fourierm" style="width:5cm" alt="The graph of f(x)=x for -\pi&lt;x&lt;\pi, together with the graphs of the partial sums S_1(x),S_6(x),S_{50}(x)." /> <img src="new_fourier50.png" title="fig:" id="fig-fourierm" style="width:5cm" alt="The graph of f(x)=x for -\pi&lt;x&lt;\pi, together with the graphs of the partial sums S_1(x),S_6(x),S_{50}(x)." /></p>
<p>In Figure <a href="#fig-fourierm" data-reference-type="ref" data-reference="fig-fourierm">27</a> we plot the graph of <span class="math inline">\(f(x)=x\)</span> for <span class="math inline">\(-\pi&lt;x&lt;\pi,\)</span> together with the graphs of the partial sums <span class="math inline">\(S_1(x),S_6(x),S_{50}(x).\)</span></p>
<p>These graphs demonstrate that as more terms of the Fourier series are included it becomes an increasingly accurate approximation to <span class="math inline">\(f(x)\)</span> inside the interval <span class="math inline">\(x\in(-\pi,\pi).\)</span> However, notice what happens at the points <span class="math inline">\(x=\pm \pi,\)</span> where <span class="math inline">\(f(x)\)</span> is not continuous. At these points the Fourier series converges to 0, which is the midpoint of the jump. Note the oscillations around the point of discontinuity, where the Fourier series under/overshoots. This is called the Gibbs phenomenon and the amount of under/overshoot tends to a constant (in fact about <span class="math inline">\(9\%\)</span>) rather than dying away as more terms are included, but the under/overshoot region becomes more localized. In the limit of an infinite number of terms the undershoot and overshoot occur at exactly the same point and cancel each other out.<br />
In general, we would like to know what happens to the <span>partial sum</span> <span class="math display">\[S_m(x)=\frac{a_0}{2}+\sum_{n=1}^m \bigg(
a_n \cos \frac{n\pi x}{L}
+b_n \sin \frac{n\pi x}{L}\bigg)\]</span> for all values of <span class="math inline">\(x\)</span> in the limit as <span class="math inline">\(m\rightarrow\infty,\)</span> and how this is related to <span class="math inline">\(f(x).\)</span> The following theorem provides an answer.<br />
<span><strong>Dirichlet’s theorem</strong></span></p>
<p>Let <span class="math inline">\(f(x)\)</span> be a periodic function, with period <span class="math inline">\(2L,\)</span> such that on the interval <span class="math inline">\((-L,L)\)</span> it has a finite number of extreme values, a finite number of jump discontinuities and <span class="math inline">\(|f(x)|\)</span> is integrable on <span class="math inline">\((-L,L).\)</span> Then its Fourier series converges for all values of <span class="math inline">\(x.\)</span> Furthermore, it converges to <span class="math inline">\(f(x)\)</span> at all points where <span class="math inline">\(f(x)\)</span> is continuous and if <span class="math inline">\(x=a\)</span> is a jump discontinuity then it converges to <span class="math inline">\(\frac{1}{2}\lim_{x\rightarrow a^-}f(x)+\frac{1}{2}\lim_{x\rightarrow a^+}f(x).\)</span><br />
</p>
</section>
<section id="parsevals-theorem" class="level2" data-number="9.3">
<h2 data-number="9.3"><span class="header-section-number">9.3</span> Parseval’s theorem</h2>
<p>We shall now derive a relation between the average of the square of a function and its Fourier coefficients.<br />
<span><strong>Parseval’s theorem</strong></span></p>
<p>If <span class="math inline">\(f(x)\)</span> is a function of period <span class="math inline">\(2L\)</span> with Fourier coefficients <span class="math inline">\(a_n,b_n\)</span> then <span class="math display">\[\frac{1}{2L}\int_{-L}^L(f(x))^2\,dx=\frac{1}{4}a_0^2+
\frac{1}{2}\sum_{n=1}^\infty (a_n^2+b_n^2).\]</span></p>
<p>Proof: <span class="math display">\[\frac{1}{L}\int_{-L}^L(f(x))^2\,dx=\]</span> <span class="math display">\[\frac{1}{L}\int_{-L}^L\bigg\{\bigg[
\frac{a_0}{2}+\sum_{n=1}^\infty \bigg(
a_n \cos \frac{n\pi x}{L}
+b_n \sin \frac{n\pi x}{L}\bigg)\bigg]
\bigg[
\frac{a_0}{2}+\sum_{m=1}^\infty \bigg(
a_m \cos \frac{m\pi x}{L}
+b_m \sin \frac{m\pi x}{L}\bigg)\bigg]\bigg\}\,dx\]</span> <span class="math display">\[=\frac{a_0^2}{2}+\sum_{n=1}^\infty\sum_{m=1}^\infty(a_na_m\delta_{mn}+b_nb_m\delta_{mn})
=\frac{a_0^2}{2}+\sum_{n=1}^\infty(a_n^2+b_n^2).\]</span><br />
<span>Parseval’s theorem</span> is useful in several contexts. One application is in finding the sum of certain infinite series.<br />
Eg. Calculate <span class="math inline">\(\sum_{n=1}^\infty \frac{1}{n^2}\)</span> by applying Parseval’s theorem to the Fourier series of <span class="math inline">\(f(x)=x\)</span> for <span class="math inline">\(-\pi&lt;x&lt;\pi.\)</span></p>
<p>From earlier we calculated that the Fourier coefficients are given by <span class="math inline">\(a_n=0\)</span> and <span class="math inline">\(b_n=\frac{2}{n}(-1)^{n+1}.\)</span> Hence by Parseval’s theorem <span class="math display">\[\frac{1}{2\pi}\int_{-\pi}^\pi x^2\,dx
=\frac{1}{2\pi}\bigg[\frac{x^3}{3}\bigg]^\pi_{-\pi}
=\frac{\pi^2}{3}
=\frac{1}{2}\sum_{n=1}^\infty \frac{4}{n^2}.
\quad\mbox{Thus}\quad
\sum_{n=1}^\infty \frac{1}{n^2}=\frac{\pi^2}{6}.\]</span></p>
<p>Certain infinite sums can also be obtained by evaluating a Fourier series at a particular value of <span class="math inline">\(x.\)</span><br />
Eg. Calculate <span class="math inline">\(\sum_{n=1}^\infty \frac{1}{(2n-1)^2}\)</span> by evaluating the Fourier series of <span class="math inline">\(f(x)=|x|\)</span> for <span class="math inline">\(-1&lt;x&lt;1,\)</span> at the value <span class="math inline">\(x=0.\)</span></p>
<p>From earlier we calculated the Fourier (cosine) series to be <span class="math display">\[f(x)=\frac{1}{2}-\frac{4}{\pi^2}\sum_{n=1}^\infty 
\frac{\cos((2n-1)\pi x)}{(2n-1)^2}.\]</span> As <span class="math inline">\(f(x)=|x|\)</span> satisfies the conditions of Dirichlet’s theorem and is continuous at <span class="math inline">\(x=0\)</span> then, by Dirichlet’s theorem, evaluating the Fourier series at <span class="math inline">\(x=0\)</span> gives <span class="math inline">\(f(0)=0.\)</span> Hence <span class="math display">\[0=\frac{1}{2}-\frac{4}{\pi^2}\sum_{n=1}^\infty 
\frac{1}{(2n-1)^2}.
\quad\quad\mbox{Thus \ }
\sum_{n=1}^\infty \frac{1}{(2n-1)^2}=\frac{\pi^2}{8}.\]</span></p>
</section>
<section id="half-range-fourier-series" class="level2" data-number="9.4">
<h2 data-number="9.4"><span class="header-section-number">9.4</span> Half range Fourier series</h2>
<p>A half range Fourier series is a Fourier series defined on an interval <span class="math inline">\((0,L)\)</span> rather than the interval <span class="math inline">\((-L,L).\)</span><br />
Given a function <span class="math inline">\(f(x),\)</span> defined on the interval <span class="math inline">\((0,L),\)</span> we obtain its <span><strong>half range sine series</strong></span> by calculating the Fourier sine series of its <span><strong>odd extension</strong></span> <span class="math display">\[f_o(x)=\begin{cases}
f(x) &amp; \text{if \ } 0&lt;x&lt;L\\ 
-f(-x) &amp; \text{if \ } -L&lt;x&lt;0\\ 
\end{cases}\]</span> The Fourier coefficients of <span class="math inline">\(f_o(x)\)</span> are <span class="math inline">\(a_n=0\)</span> and <span class="math display">\[b_n=\frac{1}{L}\int_{-L}^L f_o(x)\sin\frac{n\pi x}{L}\,dx
=\frac{2}{L}\int_{0}^L f(x)\sin\frac{n\pi x}{L}\,dx.\]</span> This gives the half range sine series for <span class="math inline">\(f(x)\)</span> on <span class="math inline">\((0,L)\)</span> as <span class="math inline">\(f(x)=\sum_{n=1}^\infty b_n \sin \frac{n\pi x}{L}.\)</span><br />
Given a function <span class="math inline">\(f(x),\)</span> defined on the interval <span class="math inline">\((0,L),\)</span> we obtain its <span><strong>half range cosine series</strong></span> by calculating the Fourier cosine series of its <span><strong>even extension</strong></span> <span class="math display">\[f_e(x)=\begin{cases}
f(x) &amp; \text{if \ } 0&lt;x&lt;L\\ 
f(-x) &amp; \text{if \ } -L&lt;x&lt;0\\ 
\end{cases}\]</span> The Fourier coefficients of <span class="math inline">\(f_e(x)\)</span> are <span class="math inline">\(b_n=0\)</span> and <span class="math display">\[a_n=\frac{1}{L}\int_{-L}^L f_e(x)\cos\frac{n\pi x}{L}\,dx
=\frac{2}{L}\int_{0}^L f(x)\cos\frac{n\pi x}{L}\,dx.\]</span> This gives the half range cosine series for <span class="math inline">\(f(x)\)</span> on <span class="math inline">\((0,L)\)</span> as <span class="math inline">\(f(x)=\frac{a_0}{2}+\sum_{n=1}^\infty a_n \cos \frac{n\pi x}{L}.\)</span></p>
<p> </p>
<p>For a given (physical) problem on an interval <span class="math inline">\((0,L)\)</span> it is usually the boundary conditions that determine whether an odd extension and a half sine Fourier series or an even extension and a half cosine Fourier series is more appropriate.<br />
</p>
</section>
<section id="fourier-series-in-complex-form" class="level2" data-number="9.5">
<h2 data-number="9.5"><span class="header-section-number">9.5</span> Fourier series in complex form</h2>
<p>Fourier series take a simpler form if written in terms of complex variables. Starting with the Fourier series <span class="math display">\[f(x)=\frac{a_0}{2}+\sum_{n=1}^\infty \bigg(
a_n \cos \frac{n\pi x}{L}
+b_n \sin \frac{n\pi x}{L}\bigg)\]</span> we use the relations <span class="math inline">\(\cos \frac{n\pi x}{L}=\frac{1}{2}(e^\frac{in\pi x}{L}+e^{-\frac{in\pi x}{L}})\)</span> and <span class="math inline">\(\sin \frac{n\pi x}{L}=-\frac{i}{2}(e^\frac{in\pi x}{L}-e^{-\frac{in\pi x}{L}})\)</span> to rewrite this as <span class="math display">\[f(x)=\frac{a_0}{2}+\frac{1}{2}\sum_{n=1}^\infty \bigg(
(a_n-ib_n)e^\frac{in\pi x}{L}+(a_n+ib_n)e^{-\frac{in\pi x}{L}}\bigg)
=\sum_{n=-\infty}^\infty c_ne^\frac{in\pi x}{L}\]</span> where we have defined <span class="math display">\[c_0=\frac{a_0}{2}=\frac{1}{2L}\int_{-L}^L f(x)\,dx\]</span> for <span class="math inline">\(n&gt;0\)</span> <span class="math display">\[c_n=\frac{1}{2}(a_n-ib_n)=\frac{1}{2L}\int_{-L}^L f(x)
(\cos \frac{n\pi x}{L}-i\sin \frac{n\pi x}{L})\,dx
=\frac{1}{2L}\int_{-L}^L f(x)e^{-\frac{in\pi x}{L}}\,dx\]</span> and for <span class="math inline">\(n&lt;0\)</span> <span class="math display">\[c_n=\frac{1}{2}(a_{-n}+ib_{-n})=\frac{1}{2L}\int_{-L}^L f(x)
(\cos \frac{-n\pi x}{L}+i\sin \frac{-n\pi x}{L})\,dx
=\frac{1}{2L}\int_{-L}^L f(x)e^{-\frac{in\pi x}{L}}\,dx.\]</span> Note that <span class="math inline">\(c_{-n}=\overline{c_n}.\)</span></p>
<p>All 3 cases (<span class="math inline">\(n=0,n&gt;0,n&lt;0\)</span>) can be written as a single compact formula <span class="math display">\[c_n=\frac{1}{2L}\int_{-L}^L f(x)e^{-\frac{in\pi x}{L}}\,dx,
\quad\quad\mbox{with the Fourier series \ }
f(x)=\sum_{n=-\infty}^\infty c_ne^\frac{in\pi x}{L}\]</span></p>
<p>Eg. The function <span class="math inline">\(f(x)\)</span> has period <span class="math inline">\(2\pi\)</span> and is given by <span class="math display">\[f(x)=\begin{cases}
-1 &amp; \mbox{ if }\  -\pi&lt;x&lt;0 \\
\ \ 1 &amp; \mbox{ if }\ \quad  0\le x&lt;\pi\end{cases}\]</span> Obtain the complex form of the Fourier series for <span class="math inline">\(f(x).\)</span><br />
<span class="math display">\[c_n=\frac{1}{2\pi}\int_{-\pi}^\pi f(x)e^{-inx}\,dx
=\frac{1}{2\pi}\int_{-\pi}^0 -e^{-inx}\,dx+\frac{1}{2\pi}\int_{0}^\pi e^{-inx}\,dx\]</span> For <span class="math inline">\(n=0\)</span> <span class="math display">\[c_0=-\frac{1}{2\pi}\int_{-\pi}^0 \,dx+\frac{1}{2\pi}\int_{0}^\pi \,dx
=-\frac{1}{2}+\frac{1}{2}=0\]</span> For <span class="math inline">\(n\ne 0\)</span> <span class="math display">\[c_n=\bigg[\frac{e^{-inx}}{2\pi i n}\bigg]_{-\pi}^0
-\bigg[\frac{e^{-inx}}{2\pi i n}\bigg]_{0}^\pi
=\frac{1}{2\pi in}(1-e^{in\pi}-e^{-in\pi}+1)
=\frac{i}{\pi n}((-1)^n-1)\]</span> Hence <span class="math inline">\(c_{2m}=0\)</span> and <span class="math inline">\(c_{2m+1}=\frac{-2i}{\pi(2m+1)}\)</span> giving the complex form of the Fourier series <span class="math display">\[f(x)=\sum_{m=-\infty}^\infty \frac{-2i}{\pi(2m+1)}e^{i(2m+1)x}\]</span></p>
<p>This complex form can be converted back to the usual real form as follows.<br />
Using <span class="math inline">\(f(x)=\overline{f(x)}\)</span> we have that <span class="math display">\[2f(x)=\sum_{m=-\infty}^\infty \frac{-2i}{\pi(2m+1)}e^{i(2m+1)x}
+\sum_{m=-\infty}^\infty \frac{2i}{\pi(2m+1)}e^{-i(2m+1)x}\]</span> hence <span class="math display">\[f(x)=\sum_{m=-\infty}^\infty \frac{-i}{\pi(2m+1)}(e^{i(2m+1)x}-e^{-i(2m+1)x})
=\sum_{m=-\infty}^\infty \frac{-i}{\pi(2m+1)}2i\sin((2m+1)x)\]</span> <span class="math display">\[=\sum_{m=-\infty}^\infty \frac{2\sin((2m+1)x)}{{\pi(2m+1)}}
=\sum_{m=0}^\infty \frac{4\sin((2m+1)x)}{{\pi(2m+1)}}\]</span></p>
</section>
<section id="summary-fourier-series" class="level2" data-number="9.6">
<h2 data-number="9.6"><span class="header-section-number">9.6</span> Summary: Fourier Series</h2>
<p>Fourier series attempt to represent periodic functions as linear combinations of sines and cosines. You should know how to calculate Fourier coefficients so you can construct Fourier series (or Fourier partial sums). You should understand the interpretation of Fourier series as (infinite-dimensional) vectors where the orthogonal basis functions are the sines and cosines, and the components are the Fourier coefficients. Here are some key points:</p>
<ul>
<li><p>If <span class="math inline">\(f(x)\)</span> is a function of period <span class="math inline">\(2L\)</span>, its (full-range) <span><em>Fourier series</em></span> is the infinite series <span class="math inline">\(\frac{a_0}{2} + \sum_{n=1}^{\infty} \left( a_n \cos(n\pi x/L) + b_n \sin(n\pi x/L) \right)\)</span> where the Fourier coefficients are given by <span class="math inline">\(a_n = \frac{1}{L} \int_{-L}^L \cos(n\pi x/L) f(x) dx\)</span> (including <span class="math inline">\(n=0\)</span>) and <span class="math inline">\(b_n = \frac{1}{L} \int_{-L}^L \sin(n\pi x/L) f(x) dx\)</span>. This arises for the vector interpretation with scalar product of <span class="math inline">\(\phi(x)\)</span> and <span class="math inline">\(\psi(x)\)</span> being <span class="math inline">\(\frac{1}{L} \int_{-L}^L \phi \psi dx\)</span>, noting that the sines and cosines are orthonormal using this scalar product.</p></li>
<li><p>If we include only the first <span class="math inline">\(N\)</span> sines and cosines (i.e. have <span class="math inline">\(\sum_{n=1}^N\)</span> rather than <span class="math inline">\(\sum_{n=1}^{\infty}\)</span>) we have a <span><em>Fourier partial sum</em></span>. The Fourier series is then given by the limit as <span class="math inline">\(N \to \infty\)</span>.</p></li>
<li><p>An odd function has a <span><em>sine Fourier series</em></span> (all <span class="math inline">\(a_n = 0\)</span>) while an even function has a <span><em>cosine Fourier series</em></span> (all <span class="math inline">\(b_n = 0\)</span>).</p></li>
<li><p><span><em>Dirichlet’s theorem</em></span> says that if <span class="math inline">\(f(x)\)</span> is a periodic function with a finite number of extreme values and jump discontinuities in each period, and with <span class="math inline">\(|f(x)|\)</span> integrable over a period then the Fourier series converges (to some real number) for all <span class="math inline">\(x\)</span>. It converges to <span class="math inline">\(f(x)\)</span> at all points where <span class="math inline">\(f\)</span> is continuous, and at jump discontinuities it converges to the midpoint of the jump.</p></li>
<li><p>The <span><em>Gibbs phenomenon</em></span> is the fact that at a jump discontinuity the Fourier series overshoots at the upper end and undershoots at the lower end by approximately <span class="math inline">\(9\%\)</span> of the jump. This is visible in the Fourier partial sums with the peaks becoming both narrower and closer to the location of the jump as <span class="math inline">\(N \to \infty\)</span>, but not reducing in height.</p></li>
<li><p>Given any function <span class="math inline">\(f(x)\)</span> on <span class="math inline">\((-L, L]\)</span> we can define its <span><em>periodic extension</em></span> to be the function of period <span class="math inline">\(2L\)</span> which equals <span class="math inline">\(f(x)\)</span> on <span class="math inline">\((-L, L]\)</span>. We can also define the <span><em>odd periodic extension</em></span> of <span class="math inline">\(f(x)\)</span> on <span class="math inline">\((0,L)\)</span> to be the periodic extension of <span class="math inline">\(f_o(x) = \left\{ \begin{array}{ll} f(x) &amp; \mathrm{if} x \in (0,L) \\ 0 &amp; \mathrm{if} x \in \{0, L\} \\ -f(-x) &amp; \mathrm{if} x \in (-L,0) \end{array} \right .\)</span>. Similarly the <span><em>even periodic extension</em></span> is the periodic extension of <span class="math inline">\(f_e(x) = \left\{ \begin{array}{ll} f(x) &amp; \mathrm{if} x \in [0,L] \\ f(-x) &amp; \mathrm{if} x \in (-L,0) \end{array} \right .\)</span>. We call the Fourier series for these odd/even periodic extensions <span><em>half-range sine/cosine series</em></span>.</p></li>
<li><p><span><em>Parseval’s theorem</em></span> says that <span class="math inline">\(\frac{1}{L} \int_{-L}^L (f(x))^2 dx = \frac{1}{2}a_0^2 + \sum_{n=1}^{\infty} (a_n^2 + b_n^2)\)</span>. It is the Fourier series equivalent of the fact that the magnitude squared of a vector is the sum of the squares of its components. Parseval’s theorem can be used to evaluate infinite series if we can realise the series in terms of squares of Fourier coefficients for some function and we can calculate the integral of the function squared.</p></li>
<li><p>We can also evaluate infinite series if we have a Fourier series which we know converges to a specific value at some point – e.g. at a point where the function is continuous and Dirichlet’s theorem guarantees the Fourier series converges to the value of the function at that point.</p></li>
<li><p>Using the orthonormal basis functions <span class="math inline">\(e^{i n \pi x/L}\)</span> with scalar product of <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\psi\)</span> defined by <span class="math inline">\(\frac{1}{2L} \int_{-L}^L \overline{\phi} \psi dx\)</span>, we can write the <span><em>Fourier series in complex form</em></span> <span class="math inline">\(\sum_{-\infty}^{\infty} c_n e^{i n \pi x/L}\)</span>. The Fourier coefficients are given by <span class="math inline">\(c_n = \frac{1}{2L} \int_{-L}^L e^{-i n \pi x/L} f(x) dx\)</span>. If <span class="math inline">\(f\)</span> is a real-valued function then <span class="math inline">\(c_{-n} = \overline{c}_n\)</span>. Note that the complex form of the Fourier series is just a different way to express the usual real Fourier series using Euler’s formula <span class="math inline">\(e^{i\theta} = \cos \theta + i \sin \theta\)</span>.</p></li>
</ul>
</section>
</section>
<script>
function doNumbering() {
	// The syntax to read the structured data from the yaml is horrible, template literals fix the problem but probably aren't widely supported enough. Escaping line breaks is browser dependant. I don't know if there's a better way?
	// Note that the data from the yaml file is manipulated into an array, and then parsed back into strings later, but I didn't want to deal with the pandoc templating syntax longer than necessary.
	var supportedEnvsArrayString = ' .definition;;; .theorem;;; .lemma;;; .example;;; .exampleqed;;; .proposition;;; .remark;;; .corollary;;; .exercise;;; .question';
	var supportedEnvsArray = supportedEnvsArrayString.split("|||");
	supportedEnvsArray = supportedEnvsArray.map(inner => inner.split(";;;"));
	var numberWithin = '1';
	var counterOffset = '';
	var subcounterOffset = '';
	var problemCounter = '';
	const partLabels = 'abcdefghijklmnopqrstuvwxyz'.split('');
	
	// counterOffset may be negative, and by default if specified on the command line this gets string concatenated with the default given in the yaml config and this then causes a problem. Can be fixed by removing the default in the config file and converting to an int, but this causes a NaN error if no value is suplied on the command line, so if NaN set to 0.
	counterOffset = parseInt(counterOffset);
	if (isNaN(counterOffset)) {
		counterOffset = 0;
	}
	
	subcounterOffset = parseInt(subcounterOffset);
	if (isNaN(subcounterOffset)) {
		subcounterOffset = 0;
	}
	
	problemCounter = parseInt(problemCounter);
	if (isNaN(problemCounter)) {
		problemCounter = 1;
	}
	
	function sanitiseSelector(selector) {
		// tex labels often have colons in which need escaping. There may be other escaping needed here. Unfortunately neither encodeURI nor encodeURIComponent do what I need, so use regex to do the escaping manually.
		var sanitised = selector.replace(/\:/g,"\\\:");
		sanitised = sanitised.replace(/(^[\d])/,"\\3$1 ");
		sanitised = sanitised.replace(/\//g,"\\\/");
		return sanitised
	}
	
	function labelLinks() {
		var refs = document.querySelectorAll("a[data-reference-type=ref]")
		for (ref of refs) {
			// Escape colons (or other) from the link title.
			var ref_label = sanitiseSelector(ref.getAttribute("data-reference"));
			// Hopefully ref is a reference to a div or a section, which should have the associated id. If so, we just need the data-number from the relevant DOM item.
			var ref_to = document.querySelector("#"+ref_label);
			if (ref_to !== null) {
				var ref_number = ref_to.getAttribute("data-number");
			} else {
				// If ref is being used for an equation, then we need to try to parse the mathjax divs. This is fragile, but try to find the span which corresponds to the equation number we need.
				try {
					var mathjax_ref = "#mjx-eqn-"+ref_label;
					ref_to = document.querySelector(mathjax_ref);
					// Since this is a ref, we don't want the parens to be returned, so find the equation number and strip the parens.
					var ref_number = ref_to.querySelector(".mjx-char").innerHTML.replace(/[()]/g,"");
					ref.setAttribute("href",mathjax_ref);
				}
				// If we can't find a place to link to, just indicate a missing link.
				catch (err){
					var ref_number = "???"
				}
			}
			ref.innerHTML = ref_number;
		};
	}
	
	function numberEnvs() {
		for (var levelSpec = 0; levelSpec <= numberWithin; levelSpec++) {
			var reqLevels = document.querySelectorAll(".level"+levelSpec);
			for (var level of reqLevels) {
				levelCount = level.getAttribute("data-number");
				levelCount = String(parseFloat(levelCount)+(counterOffset));
				levelCount = levelCount+(("."+subcounterOffset).repeat(numberWithin-levelSpec));
				for (var counter of supportedEnvsArray) {
					var envCount = 1;
					var envs = level.querySelectorAll(counter.join(", "));
					for (var env of envs) {
						env.setAttribute("data-number",levelCount+"."+envCount);
						envCount += 1;
					}
				}
			}
		}
	}
	
	function numberFigs() {
		// Figures should either be in a figure environment, or a table with image class imageTable thanks to the tableCaps filter.
		figs = document.querySelectorAll("figure, .imageTable");
		var fig_no = 1
		for (var fig of figs) {
			var cap
			// For figures, we want to move the id to the figure, and set the data-number on both the figure and the figcaption
			if (fig.nodeName == "FIGURE") {
				cap = fig.querySelector("figcaption");
				var img = fig.querySelector("img, embed")
				if (img) {
					var img_id = img.getAttribute("id");
					fig.setAttribute("id",img_id);
					img.removeAttribute("id");
				}
			// for tables (which must be .imageTable due to the querySelector above), we want to set the data-number on the table and the caption
			} else if (fig.nodeName == "TABLE") {
				cap = fig.querySelector("caption");
			}
			cap.setAttribute("data-number",fig_no);
			fig.setAttribute("data-number",fig_no);
			fig_no += 1;
		}
	}
	
	function numberGlobals() {
		// This function numbers any environments that just use a global counter, such as a problem number on a problems sheet, where there are no sections to number with respect to.
		probsols = document.querySelectorAll(".problem, .solution");
		var prob_no = problemCounter;
		var partNo = 0;
		for (var probsol of probsols) {
			if (probsol.className == "problem"){
				prob_no +=1;
				partNo = 0;
				probsol.setAttribute("data-number",prob_no);
			}
			else {
				if (probsol.parentNode.nodeName == "LI") {
					var partLabel = partLabels[partNo];
					probsol.setAttribute("data-number",prob_no.toString()+partLabel);
					partNo +=1;
				}
				else{
					probsol.setAttribute("data-number",prob_no);
				}
			}
			
		}
		// sols = document.querySelectorAll(".solution");
// 		var sol_no = problemCounter;
// 		for (var sol of sols) {
// 			sol.setAttribute("data-number",sol_no);
// 			sol_no +=1
// 		}
	}
	
	// labelLinks() should occur last, so that the data-numbers have been correctly set first.
	numberEnvs();
	numberFigs();
	numberGlobals();
	labelLinks();
}
</script><script>
	var imageDir = './Images/'
	imgs = document.querySelectorAll("img");
	for (var img of imgs) {
		imgsrc = img.getAttribute("src");
		img.setAttribute("src",imageDir.concat(imgsrc));
	}
</script></body>
</html>
